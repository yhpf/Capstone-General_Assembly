{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Good Model for the mood of the song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document I need to work more with NLP of the track lyrics and use columns that I discarded in the MVP.\n",
    "\n",
    "Good model = more NLP on the Track Lyrics<BR />\n",
    "Better model = countries <BR />\n",
    "Best model = also looking at number of streams and position, also looking at time on top list<BR />\n",
    "\n",
    "Then when we have the best model we can use our predictions and decide the mood of a country and the mood of an artist. Then we can say what artist is suitable for what country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data_top10c_more_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Position</th>\n",
       "      <th>Streams</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>40381</td>\n",
       "      <td>Bye Bye Bye</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>4r8lRYnoOGdEi6YyI5OC1o</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>gb</td>\n",
       "      <td>eu</td>\n",
       "      <td>hey, hey bye bye bye, bye bye bye bye  i'm doi...</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.00104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.656</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>24132</td>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>2017-12-23</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>it</td>\n",
       "      <td>eu</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>49766</td>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>2017-12-24</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>it</td>\n",
       "      <td>eu</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Position  Streams                       Track Name  Artist  \\\n",
       "0           0       177    40381                      Bye Bye Bye  *NSYNC   \n",
       "1           1       151    24132  Merry Christmas, Happy Holidays  *NSYNC   \n",
       "2           2        78    49766  Merry Christmas, Happy Holidays  *NSYNC   \n",
       "\n",
       "                       ID        Date  Year  Month  Day Country Region  \\\n",
       "0  4r8lRYnoOGdEi6YyI5OC1o  2017-10-05  2017     10    5      gb     eu   \n",
       "1  15coTBAzEN1bOeipoNDZAR  2017-12-23  2017     12   23      it     eu   \n",
       "2  15coTBAzEN1bOeipoNDZAR  2017-12-24  2017     12   24      it     eu   \n",
       "\n",
       "                                              Lyrics  Acousticness  Energy  \\\n",
       "0  hey, hey bye bye bye, bye bye bye bye  i'm doi...        0.0408   0.928   \n",
       "1  merry christmas and happy holidays merry chris...        0.1030   0.939   \n",
       "2  merry christmas and happy holidays merry chris...        0.1030   0.939   \n",
       "\n",
       "   Instrumentalness  Mode    Tempo  Valence  \n",
       "0           0.00104   0.0  172.656    0.879  \n",
       "1           0.00000   1.0  105.003    0.756  \n",
       "2           0.00000   1.0  105.003    0.756  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix a little bit with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop rows that are duplicates and keep only one row for each song**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_per_song = data.drop_duplicates(subset=['Track Name'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop all columns that might change per song**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ID</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bye Bye Bye</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>4r8lRYnoOGdEi6YyI5OC1o</td>\n",
       "      <td>hey, hey bye bye bye, bye bye bye bye  i'm doi...</td>\n",
       "      <td>0.04080</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.656</td>\n",
       "      <td>0.8790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.10300</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.7560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Douce Nuit</td>\n",
       "      <td>-M-</td>\n",
       "      <td>4EOJWkvkVDpkZrhC8iTDsI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.91400</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.887</td>\n",
       "      <td>0.0498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Zomersessie</td>\n",
       "      <td>101Barz</td>\n",
       "      <td>3ypzzvHUfgwyqxhL9ym4fH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00818</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>155.748</td>\n",
       "      <td>0.3650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Zomersessie (feat. 3robi)</td>\n",
       "      <td>101Barz</td>\n",
       "      <td>2re4cLViiQw0NZZx5KUpV8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00818</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>155.748</td>\n",
       "      <td>0.3650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Track Name   Artist                      ID  \\\n",
       "0                       Bye Bye Bye   *NSYNC  4r8lRYnoOGdEi6YyI5OC1o   \n",
       "1   Merry Christmas, Happy Holidays   *NSYNC  15coTBAzEN1bOeipoNDZAR   \n",
       "43                       Douce Nuit      -M-  4EOJWkvkVDpkZrhC8iTDsI   \n",
       "44                      Zomersessie  101Barz  3ypzzvHUfgwyqxhL9ym4fH   \n",
       "47        Zomersessie (feat. 3robi)  101Barz  2re4cLViiQw0NZZx5KUpV8   \n",
       "\n",
       "                                               Lyrics  Acousticness  Energy  \\\n",
       "0   hey, hey bye bye bye, bye bye bye bye  i'm doi...       0.04080   0.928   \n",
       "1   merry christmas and happy holidays merry chris...       0.10300   0.939   \n",
       "43                                                NaN       0.91400   0.227   \n",
       "44                                                NaN       0.00818   0.403   \n",
       "47                                                NaN       0.00818   0.403   \n",
       "\n",
       "    Instrumentalness  Mode    Tempo  Valence  \n",
       "0           0.001040   0.0  172.656   0.8790  \n",
       "1           0.000000   1.0  105.003   0.7560  \n",
       "43          0.163000   1.0   81.887   0.0498  \n",
       "44          0.000021   1.0  155.748   0.3650  \n",
       "47          0.000021   1.0  155.748   0.3650  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_data = data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                               'Region'], axis=1)\n",
    "\n",
    "nlp_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6919 entries, 0 to 578929\n",
      "Data columns (total 10 columns):\n",
      "Track Name          6919 non-null object\n",
      "Artist              6919 non-null object\n",
      "ID                  6919 non-null object\n",
      "Lyrics              4190 non-null object\n",
      "Acousticness        6918 non-null float64\n",
      "Energy              6918 non-null float64\n",
      "Instrumentalness    6918 non-null float64\n",
      "Mode                6918 non-null float64\n",
      "Tempo               6918 non-null float64\n",
      "Valence             6918 non-null float64\n",
      "dtypes: float64(6), object(4)\n",
      "memory usage: 594.6+ KB\n"
     ]
    }
   ],
   "source": [
    "nlp_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop rows that have missing values in the Lyrics column**<BR />\n",
    "We can use dropna to drop all rows that has missing values (should mostly be the Lyrics column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ID</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bye Bye Bye</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>4r8lRYnoOGdEi6YyI5OC1o</td>\n",
       "      <td>hey, hey bye bye bye, bye bye bye bye  i'm doi...</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.656</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Somme</td>\n",
       "      <td>13 Block</td>\n",
       "      <td>2xkxBVJHf9jQsq7g46UtQx</td>\n",
       "      <td>J'ai fait l'aller, j'suis sur le retour\\nLa ma...</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.979</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Vide</td>\n",
       "      <td>13 Block</td>\n",
       "      <td>69RclklKbEelwfQJCBzh0m</td>\n",
       "      <td>13 Blo' gang, tu sais d'jà comment on opère mo...</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.063</td>\n",
       "      <td>0.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>10 Dinger</td>\n",
       "      <td>187 Strassenbande</td>\n",
       "      <td>3ruUVcomUKxPlX8srBfMua</td>\n",
       "      <td>Ich schwör' dir, wenn ich mal Kohle mache, dan...</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.540</td>\n",
       "      <td>0.642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Track Name             Artist  \\\n",
       "0                       Bye Bye Bye             *NSYNC   \n",
       "1   Merry Christmas, Happy Holidays             *NSYNC   \n",
       "48                            Somme           13 Block   \n",
       "50                             Vide           13 Block   \n",
       "71                        10 Dinger  187 Strassenbande   \n",
       "\n",
       "                        ID                                             Lyrics  \\\n",
       "0   4r8lRYnoOGdEi6YyI5OC1o  hey, hey bye bye bye, bye bye bye bye  i'm doi...   \n",
       "1   15coTBAzEN1bOeipoNDZAR  merry christmas and happy holidays merry chris...   \n",
       "48  2xkxBVJHf9jQsq7g46UtQx  J'ai fait l'aller, j'suis sur le retour\\nLa ma...   \n",
       "50  69RclklKbEelwfQJCBzh0m  13 Blo' gang, tu sais d'jà comment on opère mo...   \n",
       "71  3ruUVcomUKxPlX8srBfMua  Ich schwör' dir, wenn ich mal Kohle mache, dan...   \n",
       "\n",
       "    Acousticness  Energy  Instrumentalness  Mode    Tempo  Valence  \n",
       "0         0.0408   0.928          0.001040   0.0  172.656    0.879  \n",
       "1         0.1030   0.939          0.000000   1.0  105.003    0.756  \n",
       "48        0.4940   0.678          0.001510   0.0   79.979    0.528  \n",
       "50        0.5050   0.682          0.000006   0.0  112.063    0.514  \n",
       "71        0.0182   0.673          0.000000   1.0   94.540    0.642  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_data_clean = nlp_data.dropna(axis=0, how='any')\n",
    "\n",
    "nlp_data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4190 entries, 0 to 578929\n",
      "Data columns (total 10 columns):\n",
      "Track Name          4190 non-null object\n",
      "Artist              4190 non-null object\n",
      "ID                  4190 non-null object\n",
      "Lyrics              4190 non-null object\n",
      "Acousticness        4190 non-null float64\n",
      "Energy              4190 non-null float64\n",
      "Instrumentalness    4190 non-null float64\n",
      "Mode                4190 non-null float64\n",
      "Tempo               4190 non-null float64\n",
      "Valence             4190 non-null float64\n",
      "dtypes: float64(6), object(4)\n",
      "memory usage: 360.1+ KB\n"
     ]
    }
   ],
   "source": [
    "nlp_data_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Turn the lyrics in the Lyrics column into string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "nlp_data_clean['Lyrics'] = nlp_data_clean['Lyrics'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make and run function for TextBlob on the Lyrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def sentiment_func(lyrics):\n",
    "    try:\n",
    "        return TextBlob(lyrics).sentiment\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "nlp_data_clean['pol_sub'] = nlp_data_clean['Lyrics'].apply(sentiment_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the pol_sub column into 2 new columns (Polarity, Subjectivity)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ID</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "      <th>pol_sub</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bye Bye Bye</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>4r8lRYnoOGdEi6YyI5OC1o</td>\n",
       "      <td>hey, hey bye bye bye, bye bye bye bye  i'm doi...</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.00104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.656</td>\n",
       "      <td>0.879</td>\n",
       "      <td>(-0.044454619454619454, 0.5908017908017905)</td>\n",
       "      <td>-0.044455</td>\n",
       "      <td>0.590802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "      <td>(0.5831501831501833, 0.6706959706959708)</td>\n",
       "      <td>0.583150</td>\n",
       "      <td>0.670696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Somme</td>\n",
       "      <td>13 Block</td>\n",
       "      <td>2xkxBVJHf9jQsq7g46UtQx</td>\n",
       "      <td>J'ai fait l'aller, j'suis sur le retour\\nLa ma...</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.00151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.979</td>\n",
       "      <td>0.528</td>\n",
       "      <td>(0.1738095238095238, 0.5416666666666666)</td>\n",
       "      <td>0.173810</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Track Name    Artist                      ID  \\\n",
       "0                       Bye Bye Bye    *NSYNC  4r8lRYnoOGdEi6YyI5OC1o   \n",
       "1   Merry Christmas, Happy Holidays    *NSYNC  15coTBAzEN1bOeipoNDZAR   \n",
       "48                            Somme  13 Block  2xkxBVJHf9jQsq7g46UtQx   \n",
       "\n",
       "                                               Lyrics  Acousticness  Energy  \\\n",
       "0   hey, hey bye bye bye, bye bye bye bye  i'm doi...        0.0408   0.928   \n",
       "1   merry christmas and happy holidays merry chris...        0.1030   0.939   \n",
       "48  J'ai fait l'aller, j'suis sur le retour\\nLa ma...        0.4940   0.678   \n",
       "\n",
       "    Instrumentalness  Mode    Tempo  Valence  \\\n",
       "0            0.00104   0.0  172.656    0.879   \n",
       "1            0.00000   1.0  105.003    0.756   \n",
       "48           0.00151   0.0   79.979    0.528   \n",
       "\n",
       "                                        pol_sub  Polarity  Subjectivity  \n",
       "0   (-0.044454619454619454, 0.5908017908017905) -0.044455      0.590802  \n",
       "1      (0.5831501831501833, 0.6706959706959708)  0.583150      0.670696  \n",
       "48     (0.1738095238095238, 0.5416666666666666)  0.173810      0.541667  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_data_clean['pol_sub'][0][0]\n",
    "\n",
    "nlp_data_clean['Polarity'] = nlp_data_clean['pol_sub'].apply(lambda x: x[0])\n",
    "nlp_data_clean['Subjectivity'] = nlp_data_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "nlp_data_clean.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop the pol_sub column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ID</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bye Bye Bye</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>4r8lRYnoOGdEi6YyI5OC1o</td>\n",
       "      <td>hey, hey bye bye bye, bye bye bye bye  i'm doi...</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.00104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.656</td>\n",
       "      <td>0.879</td>\n",
       "      <td>-0.044455</td>\n",
       "      <td>0.590802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.583150</td>\n",
       "      <td>0.670696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Somme</td>\n",
       "      <td>13 Block</td>\n",
       "      <td>2xkxBVJHf9jQsq7g46UtQx</td>\n",
       "      <td>J'ai fait l'aller, j'suis sur le retour\\nLa ma...</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.00151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.979</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.173810</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Track Name    Artist                      ID  \\\n",
       "0                       Bye Bye Bye    *NSYNC  4r8lRYnoOGdEi6YyI5OC1o   \n",
       "1   Merry Christmas, Happy Holidays    *NSYNC  15coTBAzEN1bOeipoNDZAR   \n",
       "48                            Somme  13 Block  2xkxBVJHf9jQsq7g46UtQx   \n",
       "\n",
       "                                               Lyrics  Acousticness  Energy  \\\n",
       "0   hey, hey bye bye bye, bye bye bye bye  i'm doi...        0.0408   0.928   \n",
       "1   merry christmas and happy holidays merry chris...        0.1030   0.939   \n",
       "48  J'ai fait l'aller, j'suis sur le retour\\nLa ma...        0.4940   0.678   \n",
       "\n",
       "    Instrumentalness  Mode    Tempo  Valence  Polarity  Subjectivity  \n",
       "0            0.00104   0.0  172.656    0.879 -0.044455      0.590802  \n",
       "1            0.00000   1.0  105.003    0.756  0.583150      0.670696  \n",
       "48           0.00151   0.0   79.979    0.528  0.173810      0.541667  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_data_clean = nlp_data_clean.drop(['pol_sub'], axis=1)\n",
    "\n",
    "nlp_data_clean.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a quick check of the entire data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4190 entries, 0 to 578929\n",
      "Data columns (total 12 columns):\n",
      "Track Name          4190 non-null object\n",
      "Artist              4190 non-null object\n",
      "ID                  4190 non-null object\n",
      "Lyrics              4190 non-null object\n",
      "Acousticness        4190 non-null float64\n",
      "Energy              4190 non-null float64\n",
      "Instrumentalness    4190 non-null float64\n",
      "Mode                4190 non-null float64\n",
      "Tempo               4190 non-null float64\n",
      "Valence             4190 non-null float64\n",
      "Polarity            4190 non-null float64\n",
      "Subjectivity        4190 non-null float64\n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 585.5+ KB\n"
     ]
    }
   ],
   "source": [
    "nlp_data_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4190.000000</td>\n",
       "      <td>4190.000000</td>\n",
       "      <td>4190.000000</td>\n",
       "      <td>4190.000000</td>\n",
       "      <td>4190.000000</td>\n",
       "      <td>4190.000000</td>\n",
       "      <td>4190.000000</td>\n",
       "      <td>4190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.238886</td>\n",
       "      <td>0.660887</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.541050</td>\n",
       "      <td>120.254388</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.071806</td>\n",
       "      <td>0.453405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.234458</td>\n",
       "      <td>0.165181</td>\n",
       "      <td>0.065771</td>\n",
       "      <td>0.498372</td>\n",
       "      <td>26.560422</td>\n",
       "      <td>0.221104</td>\n",
       "      <td>0.225631</td>\n",
       "      <td>0.228036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.082000</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.051525</td>\n",
       "      <td>0.562000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.984250</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>-0.033272</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.159000</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.004000</td>\n",
       "      <td>0.473000</td>\n",
       "      <td>0.046612</td>\n",
       "      <td>0.487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.784750</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>136.044750</td>\n",
       "      <td>0.654000</td>\n",
       "      <td>0.189943</td>\n",
       "      <td>0.591449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>232.690000</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Acousticness       Energy  Instrumentalness         Mode        Tempo  \\\n",
       "count   4190.000000  4190.000000       4190.000000  4190.000000  4190.000000   \n",
       "mean       0.238886     0.660887          0.009918     0.541050   120.254388   \n",
       "std        0.234458     0.165181          0.065771     0.498372    26.560422   \n",
       "min        0.000003     0.027900          0.000000     0.000000    54.082000   \n",
       "25%        0.051525     0.562000          0.000000     0.000000    99.984250   \n",
       "50%        0.159000     0.676000          0.000000     1.000000   120.004000   \n",
       "75%        0.368000     0.784750          0.000038     1.000000   136.044750   \n",
       "max        0.988000     0.995000          0.890000     1.000000   232.690000   \n",
       "\n",
       "           Valence     Polarity  Subjectivity  \n",
       "count  4190.000000  4190.000000   4190.000000  \n",
       "mean      0.482520     0.071806      0.453405  \n",
       "std       0.221104     0.225631      0.228036  \n",
       "min       0.037100    -1.000000      0.000000  \n",
       "25%       0.310000    -0.033272      0.350000  \n",
       "50%       0.473000     0.046612      0.487500  \n",
       "75%       0.654000     0.189943      0.591449  \n",
       "max       0.982000     1.000000      1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_data_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the data into a train and a test set (with a test set of 25%, which is also default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dep   = nlp_data_clean['Valence']\n",
    "indep = nlp_data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indep_train, indep_test, dep_train, dep_test = train_test_split(indep, dep, test_size = 0.25, random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make list with more stopwords (bring in other languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "French , German and Spanish stopwords from here https://www.ranks.nl/stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENGLISH_STOP_WORDS = [\n",
    "    'a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against',\n",
    "    'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always',\n",
    "    'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another',\n",
    "    'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are',\n",
    "    'around', 'as', 'at', 'back', 'be', 'became', 'because', 'become',\n",
    "    'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being',\n",
    "    'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both',\n",
    "    'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'con',\n",
    "    'could', 'couldnt', 'cry', 'de', 'describe', 'detail', 'do', 'done',\n",
    "    'down', 'due', 'during', 'each', 'eg', 'eight', 'either', 'eleven', 'else',\n",
    "    'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone',\n",
    "    'everything', 'everywhere', 'except', 'few', 'fifteen', 'fifty', 'fill',\n",
    "    'find', 'fire', 'first', 'five', 'for', 'former', 'formerly', 'forty',\n",
    "    'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go',\n",
    "    'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her', 'here', 'hereafter',\n",
    "    'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his',\n",
    "    'how', 'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed',\n",
    "    'interest', 'into', 'is', 'it', 'its', 'itself', 'keep', 'last', 'latter',\n",
    "    'latterly', 'least', 'less', 'ltd', 'made', 'many', 'may', 'me',\n",
    "    'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly',\n",
    "    'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither',\n",
    "    'never', 'nevertheless', 'next', 'nine', 'no', 'nobody', 'none', 'noone',\n",
    "    'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on',\n",
    "    'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our',\n",
    "    'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps',\n",
    "    'please', 'put', 'rather', 're', 'same', 'see', 'seem', 'seemed',\n",
    "    'seeming', 'seems', 'serious', 'several', 'she', 'should', 'show', 'side',\n",
    "    'since', 'sincere', 'six', 'sixty', 'so', 'some', 'somehow', 'someone',\n",
    "    'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such',\n",
    "    'system', 'take', 'ten', 'than', 'that', 'the', 'their', 'them',\n",
    "    'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby',\n",
    "    'therefore', 'therein', 'thereupon', 'these', 'they', 'thick', 'thin',\n",
    "    'third', 'this', 'those', 'though', 'three', 'through', 'throughout',\n",
    "    'thru', 'thus', 'to', 'together', 'too', 'top', 'toward', 'towards',\n",
    "    'twelve', 'twenty', 'two', 'un', 'under', 'until', 'up', 'upon', 'us',\n",
    "    'very', 'via', 'was', 'we', 'well', 'were', 'what', 'whatever', 'when',\n",
    "    'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby',\n",
    "    'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither',\n",
    "    'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with',\n",
    "    'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself',\n",
    "    'yourselves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# French\n",
    "with open('french') as file:\n",
    "    lines = file.readlines()\n",
    "FRENCH_STOP_WORDS = []\n",
    "for line in lines:\n",
    "    FRENCH_STOP_WORDS += [line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove the line break (\\n) from each row in FRENCH_STOP_WORDS\n",
    "FRENCH_STOP_WORDS = [s.replace('\\n', '') for s in FRENCH_STOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# German\n",
    "with open('german') as file:\n",
    "    lines = file.readlines()\n",
    "GERMAN_STOP_WORDS = []\n",
    "for line in lines:\n",
    "    GERMAN_STOP_WORDS += [line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove the line break (\\n) from each row in GERMAN_STOP_WORDS\n",
    "GERMAN_STOP_WORDS = [s.replace('\\n', '') for s in GERMAN_STOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Spanish\n",
    "with open('spanish') as file:\n",
    "    lines = file.readlines()\n",
    "SPANISH_STOP_WORDS = []\n",
    "for line in lines:\n",
    "    SPANISH_STOP_WORDS += [line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove the line break (\\n) from each row in SPANISH_STOP_WORDS\n",
    "SPANISH_STOP_WORDS = [s.replace('\\n', '') for s in SPANISH_STOP_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put all 4 stop-word lists into one list\n",
    "STOP_WORDS = ENGLISH_STOP_WORDS + FRENCH_STOP_WORDS + GERMAN_STOP_WORDS + SPANISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amoungst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'bill',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'co',\n",
       " 'con',\n",
       " 'could',\n",
       " 'couldnt',\n",
       " 'cry',\n",
       " 'de',\n",
       " 'describe',\n",
       " 'detail',\n",
       " 'do',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'fill',\n",
       " 'find',\n",
       " 'fire',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'found',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'had',\n",
       " 'has',\n",
       " 'hasnt',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'ie',\n",
       " 'if',\n",
       " 'in',\n",
       " 'inc',\n",
       " 'indeed',\n",
       " 'interest',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'keep',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'ltd',\n",
       " 'made',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mill',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'rather',\n",
       " 're',\n",
       " 'same',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'sincere',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'system',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'thick',\n",
       " 'thin',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'un',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'alors',\n",
       " 'au',\n",
       " 'aucuns',\n",
       " 'aussi',\n",
       " 'autre',\n",
       " 'avant',\n",
       " 'avec',\n",
       " 'avoir',\n",
       " 'bon',\n",
       " 'car',\n",
       " 'ce',\n",
       " 'cela',\n",
       " 'ces',\n",
       " 'ceux',\n",
       " 'chaque',\n",
       " 'ci',\n",
       " 'comme',\n",
       " 'comment',\n",
       " 'dans',\n",
       " 'des',\n",
       " 'du',\n",
       " 'dedans',\n",
       " 'dehors',\n",
       " 'depuis',\n",
       " 'devrait',\n",
       " 'doit',\n",
       " 'donc',\n",
       " 'dos',\n",
       " 'début',\n",
       " 'elle',\n",
       " 'elles',\n",
       " 'en',\n",
       " 'encore',\n",
       " 'essai',\n",
       " 'est',\n",
       " 'et',\n",
       " 'eu',\n",
       " 'fait',\n",
       " 'faites',\n",
       " 'fois',\n",
       " 'font',\n",
       " 'hors',\n",
       " 'ici',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je\\t',\n",
       " 'juste',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'là',\n",
       " 'ma',\n",
       " 'maintenant',\n",
       " 'mais',\n",
       " 'mes',\n",
       " 'mine',\n",
       " 'moins',\n",
       " 'mon',\n",
       " 'mot',\n",
       " 'même',\n",
       " 'ni',\n",
       " 'nommés',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'ou',\n",
       " 'où',\n",
       " 'par',\n",
       " 'parce',\n",
       " 'pas',\n",
       " 'peut',\n",
       " 'peu',\n",
       " 'plupart',\n",
       " 'pour',\n",
       " 'pourquoi',\n",
       " 'quand',\n",
       " 'que',\n",
       " 'quel',\n",
       " 'quelle',\n",
       " 'quelles',\n",
       " 'quels',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'sans',\n",
       " 'ses',\n",
       " 'seulement',\n",
       " 'si',\n",
       " 'sien',\n",
       " 'son',\n",
       " 'sont',\n",
       " 'sous',\n",
       " 'soyez\\t',\n",
       " 'sujet',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'tandis',\n",
       " 'tellement',\n",
       " 'tels',\n",
       " 'tes',\n",
       " 'ton',\n",
       " 'tous',\n",
       " 'tout',\n",
       " 'trop',\n",
       " 'très',\n",
       " 'tu',\n",
       " 'voient',\n",
       " 'vont',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'vu',\n",
       " 'ça',\n",
       " 'étaient',\n",
       " 'état',\n",
       " 'étions',\n",
       " 'été',\n",
       " 'être',\n",
       " 'aber',\n",
       " 'als',\n",
       " 'am',\n",
       " 'an',\n",
       " 'auch',\n",
       " 'auf',\n",
       " 'aus',\n",
       " 'bei',\n",
       " 'bin',\n",
       " 'bis',\n",
       " 'bist',\n",
       " 'da',\n",
       " 'dadurch',\n",
       " 'daher',\n",
       " 'darum',\n",
       " 'das',\n",
       " 'daß',\n",
       " 'dass',\n",
       " 'dein',\n",
       " 'deine',\n",
       " 'dem',\n",
       " 'den',\n",
       " 'der',\n",
       " 'des',\n",
       " 'dessen',\n",
       " 'deshalb',\n",
       " 'die',\n",
       " 'dies',\n",
       " 'dieser',\n",
       " 'dieses',\n",
       " 'doch',\n",
       " 'dort',\n",
       " 'du',\n",
       " 'durch',\n",
       " 'ein',\n",
       " 'eine',\n",
       " 'einem',\n",
       " 'einen',\n",
       " 'einer',\n",
       " 'eines',\n",
       " 'er',\n",
       " 'es',\n",
       " 'euer',\n",
       " 'eure',\n",
       " 'für',\n",
       " 'hatte',\n",
       " 'hatten',\n",
       " 'hattest',\n",
       " 'hattet',\n",
       " 'hier\\t',\n",
       " 'hinter',\n",
       " 'ich',\n",
       " 'ihr',\n",
       " 'ihre',\n",
       " 'im',\n",
       " 'in',\n",
       " 'ist',\n",
       " 'ja',\n",
       " 'jede',\n",
       " 'jedem',\n",
       " 'jeden',\n",
       " 'jeder',\n",
       " 'jedes',\n",
       " 'jener',\n",
       " 'jenes',\n",
       " 'jetzt',\n",
       " 'kann',\n",
       " 'kannst',\n",
       " 'können',\n",
       " 'könnt',\n",
       " 'machen',\n",
       " 'mein',\n",
       " 'meine',\n",
       " 'mit',\n",
       " 'muß',\n",
       " 'mußt',\n",
       " 'musst',\n",
       " 'müssen',\n",
       " 'müßt',\n",
       " 'nach',\n",
       " 'nachdem',\n",
       " 'nein',\n",
       " 'nicht',\n",
       " 'nun',\n",
       " 'oder',\n",
       " 'seid',\n",
       " 'sein',\n",
       " 'seine',\n",
       " 'sich',\n",
       " 'sie',\n",
       " 'sind',\n",
       " 'soll',\n",
       " 'sollen',\n",
       " 'sollst',\n",
       " 'sollt',\n",
       " 'sonst',\n",
       " 'soweit',\n",
       " 'sowie',\n",
       " 'und',\n",
       " 'unser\\t',\n",
       " 'unsere',\n",
       " 'unter',\n",
       " 'vom',\n",
       " 'von',\n",
       " 'vor',\n",
       " 'wann',\n",
       " 'warum',\n",
       " 'was',\n",
       " 'weiter',\n",
       " 'weitere',\n",
       " 'wenn',\n",
       " 'wer',\n",
       " 'werde',\n",
       " 'werden',\n",
       " 'werdet',\n",
       " 'weshalb',\n",
       " 'wie',\n",
       " 'wieder',\n",
       " 'wieso',\n",
       " 'wir',\n",
       " 'wird',\n",
       " 'wirst',\n",
       " 'wo',\n",
       " 'woher',\n",
       " 'wohin',\n",
       " 'zu',\n",
       " 'zum',\n",
       " 'zur',\n",
       " 'über',\n",
       " 'un',\n",
       " 'una',\n",
       " 'unas',\n",
       " 'unos',\n",
       " 'uno',\n",
       " 'sobre',\n",
       " 'todo',\n",
       " 'también',\n",
       " 'tras',\n",
       " 'otro',\n",
       " 'algún',\n",
       " 'alguno',\n",
       " 'alguna',\n",
       " 'algunos',\n",
       " 'algunas',\n",
       " 'ser',\n",
       " 'es',\n",
       " 'soy',\n",
       " 'eres',\n",
       " 'somos',\n",
       " 'sois',\n",
       " 'estoy',\n",
       " 'esta',\n",
       " 'estamos',\n",
       " 'estais',\n",
       " 'estan',\n",
       " 'como',\n",
       " 'en',\n",
       " 'para',\n",
       " 'atras',\n",
       " 'porque',\n",
       " 'por qué',\n",
       " 'estado',\n",
       " 'estaba',\n",
       " 'ante',\n",
       " 'antes',\n",
       " 'siendo',\n",
       " 'ambos',\n",
       " 'pero',\n",
       " 'por',\n",
       " 'poder',\n",
       " 'puede',\n",
       " 'puedo',\n",
       " 'podemos',\n",
       " 'podeis',\n",
       " 'pueden',\n",
       " 'fui',\n",
       " 'fue',\n",
       " 'fuimos',\n",
       " 'fueron',\n",
       " 'hacer',\n",
       " 'hago',\n",
       " 'hace',\n",
       " 'hacemos',\n",
       " 'haceis',\n",
       " 'hacen',\n",
       " 'cada',\n",
       " 'fin',\n",
       " 'incluso',\n",
       " 'primero\\t',\n",
       " 'desde',\n",
       " 'conseguir',\n",
       " 'consigo',\n",
       " 'consigue',\n",
       " 'consigues',\n",
       " 'conseguimos',\n",
       " 'consiguen',\n",
       " 'ir',\n",
       " 'voy',\n",
       " 'va',\n",
       " 'vamos',\n",
       " 'vais',\n",
       " 'van',\n",
       " 'vaya',\n",
       " 'gueno',\n",
       " 'ha',\n",
       " 'tener',\n",
       " 'tengo',\n",
       " 'tiene',\n",
       " 'tenemos',\n",
       " 'teneis',\n",
       " 'tienen',\n",
       " 'el',\n",
       " 'la',\n",
       " 'lo',\n",
       " 'las',\n",
       " 'los',\n",
       " 'su',\n",
       " 'aqui',\n",
       " 'mio',\n",
       " 'tuyo',\n",
       " 'ellos',\n",
       " 'ellas',\n",
       " 'nos',\n",
       " 'nosotros',\n",
       " 'vosotros',\n",
       " 'vosotras',\n",
       " 'si',\n",
       " 'dentro',\n",
       " 'solo',\n",
       " 'solamente',\n",
       " 'saber',\n",
       " 'sabes',\n",
       " 'sabe',\n",
       " 'sabemos',\n",
       " 'sabeis',\n",
       " 'saben',\n",
       " 'ultimo',\n",
       " 'largo',\n",
       " 'bastante',\n",
       " 'haces',\n",
       " 'muchos',\n",
       " 'aquellos',\n",
       " 'aquellas',\n",
       " 'sus',\n",
       " 'entonces',\n",
       " 'tiempo',\n",
       " 'verdad',\n",
       " 'verdadero',\n",
       " 'verdadera\\t',\n",
       " 'cierto',\n",
       " 'ciertos',\n",
       " 'cierta',\n",
       " 'ciertas',\n",
       " 'intentar',\n",
       " 'intento',\n",
       " 'intenta',\n",
       " 'intentas',\n",
       " 'intentamos',\n",
       " 'intentais',\n",
       " 'intentan',\n",
       " 'dos',\n",
       " 'bajo',\n",
       " 'arriba',\n",
       " 'encima',\n",
       " 'usar',\n",
       " 'uso',\n",
       " 'usas',\n",
       " 'usa',\n",
       " 'usamos',\n",
       " 'usais',\n",
       " 'usan',\n",
       " 'emplear',\n",
       " 'empleo',\n",
       " 'empleas',\n",
       " 'emplean',\n",
       " 'ampleamos',\n",
       " 'empleais',\n",
       " 'valor',\n",
       " 'muy',\n",
       " 'era',\n",
       " 'eras',\n",
       " 'eramos',\n",
       " 'eran',\n",
       " 'modo',\n",
       " 'bien',\n",
       " 'cual',\n",
       " 'cuando',\n",
       " 'donde',\n",
       " 'mientras',\n",
       " 'quien',\n",
       " 'con',\n",
       " 'entre',\n",
       " 'sin',\n",
       " 'trabajo',\n",
       " 'trabajar',\n",
       " 'trabajas',\n",
       " 'trabaja',\n",
       " 'trabajamos',\n",
       " 'trabajais',\n",
       " 'trabajan',\n",
       " 'podria',\n",
       " 'podrias',\n",
       " 'podriamos',\n",
       " 'podrian',\n",
       " 'podriais',\n",
       " 'yo',\n",
       " 'aquel']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the list of the stop words for the 4 different languages\n",
    "STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn the list to a df to be able to save as csv\n",
    "stop_words = pd.DataFrame(STOP_WORDS, columns=[\"colummn\"])\n",
    "stop_words.to_csv('stop_words.csv', index=False)\n",
    "# when you read in the csv, you will have to make it to a list again...\n",
    "# you can use df['colummn'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer (use in model 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "cvec = CountVectorizer(stop_words = STOP_WORDS, max_features = 1000) \n",
    "# eliminate stop words (that are in the list) and use max_features since there will be more than 60,000 if iI do not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'ar...s', 'trabajais', 'trabajan', 'podria', 'podrias', 'podriamos', 'podrian', 'podriais', 'yo', 'aquel'],\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(indep_train['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform X_train\n",
    "cvec_data = cvec.transform(indep_train['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>aan</th>\n",
       "      <th>ab</th>\n",
       "      <th>act</th>\n",
       "      <th>ad</th>\n",
       "      <th>adesso</th>\n",
       "      <th>ah</th>\n",
       "      <th>ahh</th>\n",
       "      <th>ai</th>\n",
       "      <th>...</th>\n",
       "      <th>zij</th>\n",
       "      <th>zijn</th>\n",
       "      <th>zit</th>\n",
       "      <th>zo</th>\n",
       "      <th>zonder</th>\n",
       "      <th>zwei</th>\n",
       "      <th>écoute</th>\n",
       "      <th>équipe</th>\n",
       "      <th>étais</th>\n",
       "      <th>était</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  100  aan  ab  act  ad  adesso  ah  ahh  ai  ...    zij  zijn  zit  zo  \\\n",
       "0   0    0    0   0    0   0       0   0    0   0  ...      0     0    0   0   \n",
       "1   0    0    0   0    0   1       0   0    0   0  ...      0     0    0   0   \n",
       "2   0    0    0   0    0   0       0   0    0   0  ...      0     0    0   0   \n",
       "\n",
       "   zonder  zwei  écoute  équipe  étais  était  \n",
       "0       0     3       0       0      0      0  \n",
       "1       0     0       0       0      0      0  \n",
       "2       0     0       0       0      0      0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the features into a data frame\n",
    "df  = pd.DataFrame(cvec_data.todense(),columns=cvec.get_feature_names())\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3142"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indep_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3142"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ID</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "      <th>...</th>\n",
       "      <th>zij</th>\n",
       "      <th>zijn</th>\n",
       "      <th>zit</th>\n",
       "      <th>zo</th>\n",
       "      <th>zonder</th>\n",
       "      <th>zwei</th>\n",
       "      <th>écoute</th>\n",
       "      <th>équipe</th>\n",
       "      <th>étais</th>\n",
       "      <th>était</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atemlos durch die Nacht</td>\n",
       "      <td>Helene Fischer</td>\n",
       "      <td>5fPGpdC4tmcVMmTuJV2HRg</td>\n",
       "      <td>Wir ziehen durch die Straßen und die Clubs die...</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.041</td>\n",
       "      <td>0.866</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La vita liquida</td>\n",
       "      <td>Brunori Sas</td>\n",
       "      <td>7ctWJ718cdHHqINJlRTuxF</td>\n",
       "      <td>Liquido è il mio corpo che si piega ad ogni co...</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.065</td>\n",
       "      <td>0.585</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zum ersten Mal Nintendo</td>\n",
       "      <td>Philipp Poisel</td>\n",
       "      <td>2UcgmsztMXVyPo3VgqD5Bu</td>\n",
       "      <td>wie oft wollt' ich weg von hier? anders als di...</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.983</td>\n",
       "      <td>0.503</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1012 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Track Name          Artist                      ID  \\\n",
       "0  Atemlos durch die Nacht  Helene Fischer  5fPGpdC4tmcVMmTuJV2HRg   \n",
       "1          La vita liquida     Brunori Sas  7ctWJ718cdHHqINJlRTuxF   \n",
       "2  Zum ersten Mal Nintendo  Philipp Poisel  2UcgmsztMXVyPo3VgqD5Bu   \n",
       "\n",
       "                                              Lyrics  Acousticness  Energy  \\\n",
       "0  Wir ziehen durch die Straßen und die Clubs die...         0.049   0.730   \n",
       "1  Liquido è il mio corpo che si piega ad ogni co...         0.558   0.621   \n",
       "2  wie oft wollt' ich weg von hier? anders als di...         0.543   0.481   \n",
       "\n",
       "   Instrumentalness  Mode    Tempo  Valence  ...    zij  zijn  zit  zo  \\\n",
       "0          0.000002   1.0  128.041    0.866  ...      0     0    0   0   \n",
       "1          0.000026   0.0   88.065    0.585  ...      0     0    0   0   \n",
       "2          0.000299   1.0   98.983    0.503  ...      0     0    0   0   \n",
       "\n",
       "   zonder  zwei  écoute  équipe  étais  était  \n",
       "0       0     3       0       0      0      0  \n",
       "1       0     0       0       0      0      0  \n",
       "2       0     0       0       0      0      0  \n",
       "\n",
       "[3 rows x 1012 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat with big data frame and use for fitting the model\n",
    "indep_train_cvec = pd.concat([indep_train.reset_index(drop=True), df], axis=1)\n",
    "\n",
    "indep_train_cvec.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3142"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indep_train_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform X_test\n",
    "cvec_data2 = cvec.transform(indep_test['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>aan</th>\n",
       "      <th>ab</th>\n",
       "      <th>act</th>\n",
       "      <th>ad</th>\n",
       "      <th>adesso</th>\n",
       "      <th>ah</th>\n",
       "      <th>ahh</th>\n",
       "      <th>ai</th>\n",
       "      <th>...</th>\n",
       "      <th>zij</th>\n",
       "      <th>zijn</th>\n",
       "      <th>zit</th>\n",
       "      <th>zo</th>\n",
       "      <th>zonder</th>\n",
       "      <th>zwei</th>\n",
       "      <th>écoute</th>\n",
       "      <th>équipe</th>\n",
       "      <th>étais</th>\n",
       "      <th>était</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  100  aan  ab  act  ad  adesso  ah  ahh  ai  ...    zij  zijn  zit  zo  \\\n",
       "0   2    0    0   0    0   0       0   0    0   0  ...      0     0    0   0   \n",
       "1   0    0    0   0    0   0       0   0    0   0  ...      0     0    0   0   \n",
       "2   0    0    0   0    0   0       4   0    0   0  ...      0     0    0   0   \n",
       "\n",
       "   zonder  zwei  écoute  équipe  étais  était  \n",
       "0       0     0       0       0      0      0  \n",
       "1       0     0       0       0      0      0  \n",
       "2       0     0       0       0      0      0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the features into a data frame\n",
    "df2  = pd.DataFrame(cvec_data2.todense(),columns=cvec.get_feature_names())\n",
    "\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ID</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "      <th>...</th>\n",
       "      <th>zij</th>\n",
       "      <th>zijn</th>\n",
       "      <th>zit</th>\n",
       "      <th>zo</th>\n",
       "      <th>zonder</th>\n",
       "      <th>zwei</th>\n",
       "      <th>écoute</th>\n",
       "      <th>équipe</th>\n",
       "      <th>étais</th>\n",
       "      <th>était</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>King Of The North</td>\n",
       "      <td>Bugzy Malone</td>\n",
       "      <td>4DixkYsZqImKOmjaIaYnCi</td>\n",
       "      <td>King! King! King! King! King! King!\\nI'm King ...</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.886</td>\n",
       "      <td>0.376</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Back On</td>\n",
       "      <td>Gucci Mane</td>\n",
       "      <td>0KA5Cc68h9qitLwTadHBpa</td>\n",
       "      <td>Zaytoven\\nHah\\nWop\\nYeah\\nIt's Gucci\\nZay\\nZig...</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.055</td>\n",
       "      <td>0.427</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magazine</td>\n",
       "      <td>Dark Polo Gang</td>\n",
       "      <td>71MGHgauMD6aapixtV6Chd</td>\n",
       "      <td>Hey, hey\\nSick Luke, Sick Luke\\n\\nLa mia facci...</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136.111</td>\n",
       "      <td>0.525</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1012 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Track Name          Artist                      ID  \\\n",
       "0  King Of The North    Bugzy Malone  4DixkYsZqImKOmjaIaYnCi   \n",
       "1            Back On      Gucci Mane  0KA5Cc68h9qitLwTadHBpa   \n",
       "2           Magazine  Dark Polo Gang  71MGHgauMD6aapixtV6Chd   \n",
       "\n",
       "                                              Lyrics  Acousticness  Energy  \\\n",
       "0  King! King! King! King! King! King!\\nI'm King ...        0.0778   0.772   \n",
       "1  Zaytoven\\nHah\\nWop\\nYeah\\nIt's Gucci\\nZay\\nZig...        0.0087   0.639   \n",
       "2  Hey, hey\\nSick Luke, Sick Luke\\n\\nLa mia facci...        0.3960   0.437   \n",
       "\n",
       "   Instrumentalness  Mode    Tempo  Valence  ...    zij  zijn  zit  zo  \\\n",
       "0          0.000044   0.0  139.886    0.376  ...      0     0    0   0   \n",
       "1          0.000004   1.0  156.055    0.427  ...      0     0    0   0   \n",
       "2          0.000000   1.0  136.111    0.525  ...      0     0    0   0   \n",
       "\n",
       "   zonder  zwei  écoute  équipe  étais  était  \n",
       "0       0     0       0       0      0      0  \n",
       "1       0     0       0       0      0      0  \n",
       "2       0     0       0       0      0      0  \n",
       "\n",
       "[3 rows x 1012 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat with big data frame and use for scoring the model\n",
    "indep_test_cvec = pd.concat([indep_test.reset_index(drop=True), df2], axis=1)\n",
    "\n",
    "indep_test_cvec.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indep_test_cvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If there are time in the future consider stemming or lemming* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (use in model 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "tvec = TfidfVectorizer(stop_words = STOP_WORDS, max_features = 1000) \n",
    "# eliminate stop words (that are in the list) and use max_features since there will be more than 60,000 if iI do not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'ar...s', 'trabajais', 'trabajan', 'podria', 'podrias', 'podriamos', 'podrian', 'podriais', 'yo', 'aquel'],\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(indep_train['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform X_train\n",
    "tvec_data3 = tvec.transform(indep_train['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>aan</th>\n",
       "      <th>ab</th>\n",
       "      <th>act</th>\n",
       "      <th>ad</th>\n",
       "      <th>adesso</th>\n",
       "      <th>ah</th>\n",
       "      <th>ahh</th>\n",
       "      <th>ai</th>\n",
       "      <th>...</th>\n",
       "      <th>zij</th>\n",
       "      <th>zijn</th>\n",
       "      <th>zit</th>\n",
       "      <th>zo</th>\n",
       "      <th>zonder</th>\n",
       "      <th>zwei</th>\n",
       "      <th>écoute</th>\n",
       "      <th>équipe</th>\n",
       "      <th>étais</th>\n",
       "      <th>était</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  100  aan   ab  act        ad  adesso   ah  ahh   ai  ...    zij  zijn  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.000000     0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.118221     0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.000000     0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "\n",
       "   zit   zo  zonder     zwei  écoute  équipe  étais  était  \n",
       "0  0.0  0.0     0.0  0.19568     0.0     0.0    0.0    0.0  \n",
       "1  0.0  0.0     0.0  0.00000     0.0     0.0    0.0    0.0  \n",
       "2  0.0  0.0     0.0  0.00000     0.0     0.0    0.0    0.0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the features into a data frame\n",
    "df3  = pd.DataFrame(tvec_data3.todense(), columns=tvec.get_feature_names())\n",
    "\n",
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3142"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indep_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3142"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ID</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "      <th>...</th>\n",
       "      <th>zij</th>\n",
       "      <th>zijn</th>\n",
       "      <th>zit</th>\n",
       "      <th>zo</th>\n",
       "      <th>zonder</th>\n",
       "      <th>zwei</th>\n",
       "      <th>écoute</th>\n",
       "      <th>équipe</th>\n",
       "      <th>étais</th>\n",
       "      <th>était</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atemlos durch die Nacht</td>\n",
       "      <td>Helene Fischer</td>\n",
       "      <td>5fPGpdC4tmcVMmTuJV2HRg</td>\n",
       "      <td>Wir ziehen durch die Straßen und die Clubs die...</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.041</td>\n",
       "      <td>0.866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La vita liquida</td>\n",
       "      <td>Brunori Sas</td>\n",
       "      <td>7ctWJ718cdHHqINJlRTuxF</td>\n",
       "      <td>Liquido è il mio corpo che si piega ad ogni co...</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.065</td>\n",
       "      <td>0.585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zum ersten Mal Nintendo</td>\n",
       "      <td>Philipp Poisel</td>\n",
       "      <td>2UcgmsztMXVyPo3VgqD5Bu</td>\n",
       "      <td>wie oft wollt' ich weg von hier? anders als di...</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.983</td>\n",
       "      <td>0.503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1012 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Track Name          Artist                      ID  \\\n",
       "0  Atemlos durch die Nacht  Helene Fischer  5fPGpdC4tmcVMmTuJV2HRg   \n",
       "1          La vita liquida     Brunori Sas  7ctWJ718cdHHqINJlRTuxF   \n",
       "2  Zum ersten Mal Nintendo  Philipp Poisel  2UcgmsztMXVyPo3VgqD5Bu   \n",
       "\n",
       "                                              Lyrics  Acousticness  Energy  \\\n",
       "0  Wir ziehen durch die Straßen und die Clubs die...         0.049   0.730   \n",
       "1  Liquido è il mio corpo che si piega ad ogni co...         0.558   0.621   \n",
       "2  wie oft wollt' ich weg von hier? anders als di...         0.543   0.481   \n",
       "\n",
       "   Instrumentalness  Mode    Tempo  Valence  ...    zij  zijn  zit   zo  \\\n",
       "0          0.000002   1.0  128.041    0.866  ...    0.0   0.0  0.0  0.0   \n",
       "1          0.000026   0.0   88.065    0.585  ...    0.0   0.0  0.0  0.0   \n",
       "2          0.000299   1.0   98.983    0.503  ...    0.0   0.0  0.0  0.0   \n",
       "\n",
       "   zonder     zwei  écoute  équipe  étais  était  \n",
       "0     0.0  0.19568     0.0     0.0    0.0    0.0  \n",
       "1     0.0  0.00000     0.0     0.0    0.0    0.0  \n",
       "2     0.0  0.00000     0.0     0.0    0.0    0.0  \n",
       "\n",
       "[3 rows x 1012 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat with big data frame and use for fitting the model\n",
    "indep_train_tvec = pd.concat([indep_train.reset_index(drop=True), df3], axis=1)\n",
    "\n",
    "indep_train_tvec.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3142"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indep_train_tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform X_test\n",
    "tvec_data4 = tvec.transform(indep_test['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>aan</th>\n",
       "      <th>ab</th>\n",
       "      <th>act</th>\n",
       "      <th>ad</th>\n",
       "      <th>adesso</th>\n",
       "      <th>ah</th>\n",
       "      <th>ahh</th>\n",
       "      <th>ai</th>\n",
       "      <th>...</th>\n",
       "      <th>zij</th>\n",
       "      <th>zijn</th>\n",
       "      <th>zit</th>\n",
       "      <th>zo</th>\n",
       "      <th>zonder</th>\n",
       "      <th>zwei</th>\n",
       "      <th>écoute</th>\n",
       "      <th>équipe</th>\n",
       "      <th>étais</th>\n",
       "      <th>était</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         10  100  aan   ab  act   ad    adesso   ah  ahh   ai  ...    zij  \\\n",
       "0  0.039411  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...    0.0   \n",
       "1  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...    0.0   \n",
       "2  0.000000  0.0  0.0  0.0  0.0  0.0  0.214023  0.0  0.0  0.0  ...    0.0   \n",
       "\n",
       "   zijn  zit   zo  zonder  zwei  écoute  équipe  étais  était  \n",
       "0   0.0  0.0  0.0     0.0   0.0     0.0     0.0    0.0    0.0  \n",
       "1   0.0  0.0  0.0     0.0   0.0     0.0     0.0    0.0    0.0  \n",
       "2   0.0  0.0  0.0     0.0   0.0     0.0     0.0    0.0    0.0  \n",
       "\n",
       "[3 rows x 1000 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the features into a data frame\n",
    "df4  = pd.DataFrame(tvec_data4.todense(),columns=cvec.get_feature_names())\n",
    "\n",
    "df4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ID</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "      <th>...</th>\n",
       "      <th>zij</th>\n",
       "      <th>zijn</th>\n",
       "      <th>zit</th>\n",
       "      <th>zo</th>\n",
       "      <th>zonder</th>\n",
       "      <th>zwei</th>\n",
       "      <th>écoute</th>\n",
       "      <th>équipe</th>\n",
       "      <th>étais</th>\n",
       "      <th>était</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>King Of The North</td>\n",
       "      <td>Bugzy Malone</td>\n",
       "      <td>4DixkYsZqImKOmjaIaYnCi</td>\n",
       "      <td>King! King! King! King! King! King!\\nI'm King ...</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.886</td>\n",
       "      <td>0.376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Back On</td>\n",
       "      <td>Gucci Mane</td>\n",
       "      <td>0KA5Cc68h9qitLwTadHBpa</td>\n",
       "      <td>Zaytoven\\nHah\\nWop\\nYeah\\nIt's Gucci\\nZay\\nZig...</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.055</td>\n",
       "      <td>0.427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magazine</td>\n",
       "      <td>Dark Polo Gang</td>\n",
       "      <td>71MGHgauMD6aapixtV6Chd</td>\n",
       "      <td>Hey, hey\\nSick Luke, Sick Luke\\n\\nLa mia facci...</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136.111</td>\n",
       "      <td>0.525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1012 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Track Name          Artist                      ID  \\\n",
       "0  King Of The North    Bugzy Malone  4DixkYsZqImKOmjaIaYnCi   \n",
       "1            Back On      Gucci Mane  0KA5Cc68h9qitLwTadHBpa   \n",
       "2           Magazine  Dark Polo Gang  71MGHgauMD6aapixtV6Chd   \n",
       "\n",
       "                                              Lyrics  Acousticness  Energy  \\\n",
       "0  King! King! King! King! King! King!\\nI'm King ...        0.0778   0.772   \n",
       "1  Zaytoven\\nHah\\nWop\\nYeah\\nIt's Gucci\\nZay\\nZig...        0.0087   0.639   \n",
       "2  Hey, hey\\nSick Luke, Sick Luke\\n\\nLa mia facci...        0.3960   0.437   \n",
       "\n",
       "   Instrumentalness  Mode    Tempo  Valence  ...    zij  zijn  zit   zo  \\\n",
       "0          0.000044   0.0  139.886    0.376  ...    0.0   0.0  0.0  0.0   \n",
       "1          0.000004   1.0  156.055    0.427  ...    0.0   0.0  0.0  0.0   \n",
       "2          0.000000   1.0  136.111    0.525  ...    0.0   0.0  0.0  0.0   \n",
       "\n",
       "   zonder  zwei  écoute  équipe  étais  était  \n",
       "0     0.0   0.0     0.0     0.0    0.0    0.0  \n",
       "1     0.0   0.0     0.0     0.0    0.0    0.0  \n",
       "2     0.0   0.0     0.0     0.0    0.0    0.0  \n",
       "\n",
       "[3 rows x 1012 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat with big data frame and use for scoring the model\n",
    "indep_test_tvec = pd.concat([indep_test.reset_index(drop=True), df4], axis=1)\n",
    "\n",
    "indep_test_tvec.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indep_test_tvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models (LinReg, Lasso and RF) - CountVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # standardize the predictors\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train)\n",
    "    X_train_s = ss.transform(X_train)\n",
    "    X_test_s = ss.transform(X_test)\n",
    "    \n",
    "    # fit\n",
    "    model.fit(X_train_s, y_train)\n",
    "    \n",
    "    # Evaluate: predict and score\n",
    "    y_pred = model.predict(X_test_s)\n",
    "    y_true = y_test\n",
    "    \n",
    "    mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Evaluate: score\n",
    "    score = model.score(X_test_s, y_test)\n",
    "    \n",
    "    return {'Score (R^2)': score.mean(), 'MSE': mean_square_error}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LinReg #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2587134551086917, 'Score (R^2)': -0.3099817028424565}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train = indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train = indep_train['Valence'] \n",
    "X_test = indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test = indep_test['Valence']\n",
    "\n",
    "# chose model \n",
    "model = LinearRegression()\n",
    "\n",
    "# call function\n",
    "evaluate_model(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importance of the coefficients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy          0.093047\n",
       "Acousticness    0.028629\n",
       "guardo          0.017458\n",
       "geht            0.017209\n",
       "nog             0.016786\n",
       "quando          0.016268\n",
       "long            0.015991\n",
       "di              0.015467\n",
       "baby            0.015285\n",
       "Mode            0.014997\n",
       "dtype: float64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train.columns,model.coef_))).abs().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LinReg #2 - CountrVec + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2076809645710392, 'Score (R^2)': 0.155848139254102}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train2 = indep_train_cvec[['Energy', 'Acousticness', 'guardo']]\n",
    "y_train2 = indep_train['Valence']\n",
    "X_test2 = indep_test_cvec[['Energy', 'Acousticness', 'guardo']]\n",
    "y_test2 = indep_test['Valence']\n",
    "\n",
    "# chose model \n",
    "model2 = LinearRegression()\n",
    "\n",
    "# call function\n",
    "evaluate_model(model2, X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LinReg #3 - CountrVec + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2071522032148789, 'Score (R^2)': 0.16014113421210033}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train3 = indep_train_cvec[['Energy', 'Acousticness', 'guardo', 'geht', 'nog', 'quando', 'long', 'di', 'baby',\n",
    "                             'Mode']]\n",
    "y_train3 = indep_train['Valence']\n",
    "X_test3 = indep_test_cvec[['Energy', 'Acousticness', 'guardo', 'geht', 'nog', 'quando', 'long', 'di', 'baby',\n",
    "                             'Mode']]\n",
    "y_test3 = indep_test['Valence']\n",
    "\n",
    "# chose model \n",
    "model3 = LinearRegression()\n",
    "\n",
    "# call function\n",
    "evaluate_model(model3, X_train3, X_test3, y_train3, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*COMMENT: The best LinReg is nr 3*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very unefficient way to find the best number of independent variables. I will run a Lasso model instead to get help with varables.<BR />\n",
    "An alternative could have been going with the Transformers 'select k-best' (will pick best nr of estimators, where I choose the number of estimaters) or RFE (eliminates varables not to use)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X_train4 = indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train4 = indep_train['Valence']\n",
    "X_test4 = indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test4 = indep_test['Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize the predictors\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train4)\n",
    "X_train4_s = ss.transform(X_train4)\n",
    "X_test4_s = ss.transform(X_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.18210361592445343\n",
      "best_params: {'selection': 'cyclic', 'alpha': 0.004641588833612782}\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearch (best hyperparams) \n",
    "params = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "# we want intercept, we do not want to normalize here, since we already have scaled with the StandardScaler\n",
    "# precompute=auto the computer decides\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "# Best Hyperparameters and fit\n",
    "rs = RandomizedSearchCV(lassoreg, params, n_iter=40)\n",
    "rs.fit(X_train4_s, y_train4)\n",
    "\n",
    "print(f'best_score: {rs.best_score_}')\n",
    "print(f'best_params: {rs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.18357351049177206\n",
      "best_params: {'alpha': 0.005336699231206312, 'selection': 'cyclic'}\n"
     ]
    }
   ],
   "source": [
    "# GridSearch (best hyperparams) \n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "# we want intercept, we do not want to normalize here, since we already have scaled with the StandardScaler\n",
    "# precompute=auto the computer decides\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "# Best Hyperparameters and fit\n",
    "gs = GridSearchCV(lassoreg, grid)\n",
    "gs.fit(X_train4_s, y_train4)\n",
    "    \n",
    "print(f'best_score: {gs.best_score_}')\n",
    "print(f'best_params: {gs.best_params_}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (R^2): 0.1821078591179739\n",
      "MSE: 0.20442519405238987\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression (best hyper params: input alpha and selection from above)\n",
    "model4 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0053, selection='cyclic')              \n",
    "\n",
    "# fit\n",
    "model4.fit(X_train4_s, y_train4)\n",
    "\n",
    "# Evaluate: predict\n",
    "y_pred = model4.predict(X_test4_s)\n",
    "y_true = y_test4\n",
    "    \n",
    "mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "# Evaluate: score \n",
    "score = model4.score(X_test4_s, y_test4)\n",
    "    \n",
    "print(f'Score (R^2): {score.mean()}')\n",
    "print(f'MSE: {mean_square_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.082843\n",
       "Acousticness        0.017023\n",
       "baby                0.011144\n",
       "x2                  0.010904\n",
       "Mode                0.009772\n",
       "girl                0.008657\n",
       "niggas              0.006985\n",
       "little              0.005442\n",
       "geht                0.005153\n",
       "Instrumentalness    0.005133\n",
       "fast                0.005067\n",
       "bro                 0.005027\n",
       "viel                0.005011\n",
       "putain              0.004989\n",
       "ville               0.004974\n",
       "dtype: float64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train4.columns,model4.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do not use x2, that is from the lyrics text and only showing if something is repeating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - CountVec + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X_train5 = indep_train_cvec[['Energy', 'Acousticness', 'baby', 'Mode', 'girl', 'niggas', 'little', 'geht',\n",
    "                             'Instrumentalness', 'fast']]\n",
    "y_train5 = indep_train['Valence']\n",
    "X_test5 = indep_test_cvec[['Energy', 'Acousticness', 'baby', 'Mode', 'girl', 'niggas', 'little', 'geht',\n",
    "                             'Instrumentalness', 'fast']]\n",
    "y_test5 = indep_test['Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize the predictors\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train5)\n",
    "X_train5_s = ss.transform(X_train5)\n",
    "X_test5_s = ss.transform(X_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.17670844764498583\n",
      "best_params: {'selection': 'cyclic', 'alpha': 0.0011497569953977356}\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearch (best hyperparams) \n",
    "params = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "# we want intercept, we do not want to normalize here, since we already have scaled with the StandardScaler\n",
    "# precompute=auto the computer decides\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "# Best Hyperparameters and fit\n",
    "rs = RandomizedSearchCV(lassoreg, params, n_iter=40)\n",
    "rs.fit(X_train5_s, y_train5)\n",
    "\n",
    "print(f'best_score: {rs.best_score_}')\n",
    "print(f'best_params: {rs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.17681591962374835\n",
      "best_params: {'alpha': 0.001, 'selection': 'random'}\n"
     ]
    }
   ],
   "source": [
    "# GridSearch (best hyperparams) \n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "# we want intercept, we do not want to normalize here, since we already have scaled with the StandardScaler\n",
    "# precompute=auto the computer decides\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "# Best Hyperparameters and fit\n",
    "gs = GridSearchCV(lassoreg, grid)\n",
    "gs.fit(X_train5_s, y_train5)\n",
    "    \n",
    "print(f'best_score: {gs.best_score_}')\n",
    "print(f'best_params: {gs.best_params_}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (R^2): 0.1676580825613684\n",
      "MSE: 0.2062230873941988\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression (best hyper params: input alpha and selection from above)\n",
    "model5 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, selection='random')              \n",
    "\n",
    "# fit\n",
    "model5.fit(X_train5_s, y_train5)\n",
    "\n",
    "# Evaluate: predict \n",
    "y_pred = model5.predict(X_test5_s)\n",
    "y_true = y_test5\n",
    "    \n",
    "mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "# Evaluate: score \n",
    "score = model5.score(X_test5_s, y_test5)\n",
    "    \n",
    "print(f'Score (R^2): {score.mean()}')\n",
    "print(f'MSE: {mean_square_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - CountVec + top 5 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X_train6 = indep_train_cvec[['Energy', 'Acousticness', 'baby', 'Mode', 'girl']]\n",
    "y_train6 = indep_train['Valence']\n",
    "X_test6 = indep_test_cvec[['Energy', 'Acousticness', 'baby', 'Mode', 'girl']]\n",
    "y_test6 = indep_test['Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize the predictors\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train6)\n",
    "X_train6_s = ss.transform(X_train6)\n",
    "X_test6_s = ss.transform(X_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.16526677632466533\n",
      "best_params: {'selection': 'random', 'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearch (best hyperparams) \n",
    "params = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "# we want intercept, we do not want to normalize here, since we already have scaled with the StandardScaler\n",
    "# precompute=auto the computer decides\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "# Best Hyperparameters and fit\n",
    "rs = RandomizedSearchCV(lassoreg, params, n_iter=40)\n",
    "rs.fit(X_train6_s, y_train6)\n",
    "\n",
    "print(f'best_score: {rs.best_score_}')\n",
    "print(f'best_params: {rs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.16526677632466533\n",
      "best_params: {'alpha': 0.001, 'selection': 'random'}\n"
     ]
    }
   ],
   "source": [
    "# GridSearch (best hyperparams) \n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "# we want intercept, we do not want to normalize here, since we already have scaled with the StandardScaler\n",
    "# precompute=auto the computer decides\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "# Best Hyperparameters and fit\n",
    "gs = GridSearchCV(lassoreg, grid)\n",
    "gs.fit(X_train6_s, y_train6)\n",
    "    \n",
    "print(f'best_score: {gs.best_score_}')\n",
    "print(f'best_params: {gs.best_params_}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (R^2): 0.16772687310510903\n",
      "MSE: 0.20621456536068097\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression (best hyper params: input alpha and selection from above)\n",
    "model6 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, selection='random')              \n",
    "\n",
    "# fit\n",
    "model6.fit(X_train6_s, y_train6)\n",
    "\n",
    "# Evaluate: predict \n",
    "y_pred = model6.predict(X_test6_s)\n",
    "y_true = y_test6\n",
    "    \n",
    "mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "# Evaluate: score \n",
    "score = model6.score(X_test6_s, y_test6)\n",
    "    \n",
    "print(f'Score (R^2): {score.mean()}')\n",
    "print(f'MSE: {mean_square_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*COMMENT: The best Lasso is nr 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not have to scale a Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_hype(model, params, X_train, y_train):  \n",
    "    # Best Hyperparameters\n",
    "    rs = RandomizedSearchCV(model, params, n_iter=40)\n",
    "    \n",
    "    # fit\n",
    "    rs.fit(X_train, y_train)\n",
    "     \n",
    "    return {'best_score': rs.best_score_,'best_params': rs.best_params_} \n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # fit\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate: predict\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Evaluate: score\n",
    "    score = model.score(X_test, y_test)\n",
    "    \n",
    "    return {'Score (R^2)': score.mean(), 'MSE': mean_square_error}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17154829518939638}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train7 = indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train7 = indep_train['Valence']\n",
    "X_test7 = indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test7 = indep_test['Valence']\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train7, y_train7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20472005307235316, 'Score (R^2)': 0.17974673332238125}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "model7 = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(model7, X_train7, X_test7, y_train7, y_test7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.244485\n",
       "Acousticness        0.043630\n",
       "Instrumentalness    0.019697\n",
       "Tempo               0.019308\n",
       "Subjectivity        0.017889\n",
       "Polarity            0.016202\n",
       "baby                0.014102\n",
       "oh                  0.009026\n",
       "je                  0.008125\n",
       "Mode                0.006135\n",
       "girl                0.006093\n",
       "che                 0.005309\n",
       "ben                 0.004927\n",
       "x2                  0.004863\n",
       "floor               0.004749\n",
       "dtype: float64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train7.columns,model7.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do not use x2, that is from the lyrics text and only showing if something is repeating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Random Forest #2 - CountVec + top 7 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.14664531102380435}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train8 = indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'Subjectivity', 'Polarity',\n",
    "                             'baby']]\n",
    "y_train8 = indep_train['Valence']\n",
    "X_test8 = indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'Subjectivity', 'Polarity',\n",
    "                             'baby']]\n",
    "y_test8 = indep_test['Valence']\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train8, y_train8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20702112538034922, 'Score (R^2)': 0.16120365780960677}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "model8 = RandomForestRegressor(max_depth=5, max_features='auto', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(model8, X_train8, X_test8, y_train8, y_test8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest #3 - CountVec + top 3 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.13757342917216644}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train9 = indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train9 = indep_train['Valence']\n",
    "X_test9 = indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test9 = indep_test['Valence']\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train9, y_train9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20845478597045353, 'Score (R^2)': 0.1495457828207792}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "model9 = RandomForestRegressor(max_depth=5, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(model9, X_train9, X_test9, y_train9, y_test9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*COMMENT: The best RF is nr 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The over all best model was Random Forest nr 1 with a R2-score of 0.17974673332238125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models (LinReg, Lasso and RF) - TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # standardize the predictors\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train)\n",
    "    X_train_s = ss.transform(X_train)\n",
    "    X_test_s = ss.transform(X_test)\n",
    "    \n",
    "    # fit\n",
    "    model.fit(X_train_s, y_train)\n",
    "    \n",
    "    # Evaluate: predict and score\n",
    "    y_pred = model.predict(X_test_s)\n",
    "    y_true = y_test\n",
    "    \n",
    "    mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Evaluate: score\n",
    "    score = model.score(X_test_s, y_test)\n",
    "    \n",
    "    return {'Score (R^2)': score.mean(), 'MSE': mean_square_error}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LinReg #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.24485816941821856, 'Score (R^2)': -0.17342785785246928}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train10 = indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train10 = indep_train['Valence'] \n",
    "X_test10 = indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test10 = indep_test['Valence']\n",
    "\n",
    "# chose model \n",
    "model10 = LinearRegression()\n",
    "\n",
    "# call function\n",
    "evaluate_model(model10, X_train10, X_test10, y_train10, y_test10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importance of the coefficients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy          0.093520\n",
       "Acousticness    0.030678\n",
       "baby            0.014869\n",
       "faire           0.014618\n",
       "Mode            0.014488\n",
       "x2              0.013533\n",
       "bro             0.013386\n",
       "sagt            0.013151\n",
       "zit             0.012580\n",
       "haben           0.012317\n",
       "geht            0.012192\n",
       "zonder          0.012138\n",
       "damn            0.011880\n",
       "hai             0.011576\n",
       "girl            0.011395\n",
       "dtype: float64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train10.columns,model10.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do not use x2, that is from the lyrics text and only showing if something is repeating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LinReg #2 - TF-IDF + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20589582744539472, 'Score (R^2)': 0.17029770981324463}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train11 = indep_train_tvec[['Energy', 'Acousticness', 'baby']]\n",
    "y_train11 = indep_train['Valence']\n",
    "X_test11 = indep_test_tvec[['Energy', 'Acousticness', 'baby']]\n",
    "y_test11 = indep_test['Valence']\n",
    "\n",
    "# chose model \n",
    "model11 = LinearRegression()\n",
    "\n",
    "# call function\n",
    "evaluate_model(model11, X_train11, X_test11, y_train11, y_test11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LinReg #3 - TF-IDF + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20766685282589525, 'Score (R^2)': 0.15596285416045497}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train12 = indep_train_tvec[['Energy', 'Acousticness', 'baby', 'faire', 'Mode', 'bro', 'sagt', 'zit',\n",
    "                             'haben', 'geht']]\n",
    "y_train12 = indep_train['Valence']\n",
    "X_test12 = indep_test_tvec[['Energy', 'Acousticness', 'baby', 'faire', 'Mode', 'bro', 'sagt', 'zit',\n",
    "                             'haben', 'geht']]\n",
    "y_test12 = indep_test['Valence']\n",
    "\n",
    "# chose model \n",
    "model12 = LinearRegression()\n",
    "\n",
    "# call function\n",
    "evaluate_model(model12, X_train12, X_test12, y_train12, y_test12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best LinReg is nr 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - TF-IDF  + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X_train13 = indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train13 = indep_train['Valence']\n",
    "X_test13 = indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test13 = indep_test['Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize the predictors\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train13)\n",
    "X_train13_s = ss.transform(X_train13)\n",
    "X_test13_s = ss.transform(X_test13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.18246974042157804\n",
      "best_params: {'selection': 'random', 'alpha': 0.006135907273413176}\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearch (best hyperparams) \n",
    "params = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "# we want intercept, we do not want to normalize here, since we already have scaled with the StandardScaler\n",
    "# precompute=auto the computer decides\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "# Best Hyperparameters and fit\n",
    "rs = RandomizedSearchCV(lassoreg, params, n_iter=40)\n",
    "rs.fit(X_train13_s, y_train13)\n",
    "\n",
    "print(f'best_score: {rs.best_score_}')\n",
    "print(f'best_params: {rs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.18247129724569322\n",
      "best_params: {'alpha': 0.006135907273413176, 'selection': 'cyclic'}\n"
     ]
    }
   ],
   "source": [
    "# GridSearch (best hyperparams) \n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "# we want intercept, we do not want to normalize here, since we already have scaled with the StandardScaler\n",
    "# precompute=auto the computer decides\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "# Best Hyperparameters and fit\n",
    "gs = GridSearchCV(lassoreg, grid)\n",
    "gs.fit(X_train13_s, y_train13)\n",
    "    \n",
    "print(f'best_score: {gs.best_score_}')\n",
    "print(f'best_params: {gs.best_params_}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (R^2): 0.1798104941720825\n",
      "MSE: 0.2047120961529845\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression (best hyper params: input alpha and selection from above)\n",
    "model13 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0061, selection='cyclic')              \n",
    "\n",
    "# fit\n",
    "model13.fit(X_train13_s, y_train13)\n",
    "\n",
    "# Evaluate: predict\n",
    "y_pred = model13.predict(X_test13_s)\n",
    "y_true = y_test13\n",
    "    \n",
    "mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "# Evaluate: score \n",
    "score = model13.score(X_test13_s, y_test13)\n",
    "    \n",
    "print(f'Score (R^2): {score.mean()}')\n",
    "print(f'MSE: {mean_square_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.081902\n",
       "Acousticness        0.015608\n",
       "baby                0.012307\n",
       "x2                  0.011009\n",
       "girl                0.009532\n",
       "Mode                0.008984\n",
       "niggas              0.006917\n",
       "fun                 0.005355\n",
       "Instrumentalness    0.005026\n",
       "bitch               0.004998\n",
       "sexy                0.004667\n",
       "long                0.004602\n",
       "track               0.004530\n",
       "quartier            0.004406\n",
       "bro                 0.004137\n",
       "dtype: float64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train13.columns,model13.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do not use x2, that is from the lyrics text and only showing if something is repeating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - TF-IDF  + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X_train14 = indep_train_tvec[['Energy', 'Acousticness', 'baby', 'girl', 'Mode', 'niggas', 'fun', 'Instrumentalness',\n",
    "                              'bitch', 'sexy']]\n",
    "y_train14 = indep_train['Valence']\n",
    "X_test14 = indep_test_tvec[['Energy', 'Acousticness', 'baby', 'girl', 'Mode', 'niggas', 'fun', 'Instrumentalness',\n",
    "                            'bitch', 'sexy']]\n",
    "y_test14 = indep_test['Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize the predictors\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train14)\n",
    "X_train14_s = ss.transform(X_train14)\n",
    "X_test14_s = ss.transform(X_test14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.17993339012403026\n",
      "best_params: {'selection': 'random', 'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearch (best hyperparams) \n",
    "params = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "# we want intercept, we do not want to normalize here, since we already have scaled with the StandardScaler\n",
    "# precompute=auto the computer decides\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "# Best Hyperparameters and fit\n",
    "rs = RandomizedSearchCV(lassoreg, params, n_iter=40)\n",
    "rs.fit(X_train14_s, y_train14)\n",
    "\n",
    "print(f'best_score: {rs.best_score_}')\n",
    "print(f'best_params: {rs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.17993339012403026\n",
      "best_params: {'alpha': 0.001, 'selection': 'random'}\n"
     ]
    }
   ],
   "source": [
    "# GridSearch (best hyperparams) \n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "# we want intercept, we do not want to normalize here, since we already have scaled with the StandardScaler\n",
    "# precompute=auto the computer decides\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "# Best Hyperparameters and fit\n",
    "gs = GridSearchCV(lassoreg, grid)\n",
    "gs.fit(X_train14_s, y_train14)\n",
    "    \n",
    "print(f'best_score: {gs.best_score_}')\n",
    "print(f'best_params: {gs.best_params_}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (R^2): 0.16848620764547673\n",
      "MSE: 0.20612047270696127\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression (best hyper params: input alpha and selection from above)\n",
    "model14 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, selection='random')              \n",
    "\n",
    "# fit\n",
    "model14.fit(X_train14_s, y_train14)\n",
    "\n",
    "# Evaluate: predict \n",
    "y_pred = model14.predict(X_test14_s)\n",
    "y_true = y_test14\n",
    "    \n",
    "mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "# Evaluate: score \n",
    "score = model14.score(X_test14_s, y_test14)\n",
    "    \n",
    "print(f'Score (R^2): {score.mean()}')\n",
    "print(f'MSE: {mean_square_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - TF-IDF  + top 5 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X_train15 = indep_train_tvec[['Energy', 'Acousticness', 'baby', 'girl', 'Mode']]\n",
    "y_train15 = indep_train['Valence']\n",
    "X_test15 = indep_test_tvec[['Energy', 'Acousticness', 'baby', 'girl', 'Mode']]\n",
    "y_test15 = indep_test['Valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize the predictors\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train15)\n",
    "X_train15_s = ss.transform(X_train15)\n",
    "X_test15_s = ss.transform(X_test15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.16727253217087912\n",
      "best_params: {'selection': 'cyclic', 'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# RandomizedSearch (best hyperparams) \n",
    "params = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "# we want intercept, we do not want to normalize here, since we already have scaled with the StandardScaler\n",
    "# precompute=auto the computer decides\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "# Best Hyperparameters and fit\n",
    "rs = RandomizedSearchCV(lassoreg, params, n_iter=40)\n",
    "rs.fit(X_train15_s, y_train15)\n",
    "\n",
    "print(f'best_score: {rs.best_score_}')\n",
    "print(f'best_params: {rs.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.16727315161904804\n",
      "best_params: {'alpha': 0.001, 'selection': 'random'}\n"
     ]
    }
   ],
   "source": [
    "# GridSearch (best hyperparams) \n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "# we want intercept, we do not want to normalize here, since we already have scaled with the StandardScaler\n",
    "# precompute=auto the computer decides\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "# Best Hyperparameters and fit\n",
    "gs = GridSearchCV(lassoreg, grid)\n",
    "gs.fit(X_train15_s, y_train15)\n",
    "    \n",
    "print(f'best_score: {gs.best_score_}')\n",
    "print(f'best_params: {gs.best_params_}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (R^2): 0.1687700698821054\n",
      "MSE: 0.2060852869930804\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression (best hyper params: input alpha and selection from above)\n",
    "model15 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, selection='random')              \n",
    "\n",
    "# fit\n",
    "model15.fit(X_train15_s, y_train15)\n",
    "\n",
    "# Evaluate: predict \n",
    "y_pred = model15.predict(X_test15_s)\n",
    "y_true = y_test15\n",
    "    \n",
    "mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "# Evaluate: score \n",
    "score = model15.score(X_test15_s, y_test15)\n",
    "    \n",
    "print(f'Score (R^2): {score.mean()}')\n",
    "print(f'MSE: {mean_square_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*COMMENT: The best Lasso is nr 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not have to scale a Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_hype(model, params, X_train, y_train):  \n",
    "    # Best Hyperparameters\n",
    "    rs = RandomizedSearchCV(model, params, n_iter=40)\n",
    "    \n",
    "    # fit\n",
    "    rs.fit(X_train, y_train)\n",
    "     \n",
    "    return {'best_score': rs.best_score_,'best_params': rs.best_params_} \n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # fit\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate: predict\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Evaluate: score\n",
    "    score = model.score(X_test, y_test)\n",
    "    \n",
    "    return {'Score (R^2)': score.mean(), 'MSE': mean_square_error}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17423560058157853}"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train16 = indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train16 = indep_train['Valence']\n",
    "X_test16 = indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test16 = indep_test['Valence']\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train16, y_train16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20620783195905815, 'Score (R^2)': 0.1677812236571271}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "model16 = RandomForestRegressor(max_depth=11, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(model16, X_train16, X_test16, y_train16, y_test16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.279480\n",
       "Acousticness        0.034036\n",
       "Instrumentalness    0.015717\n",
       "baby                0.014794\n",
       "Subjectivity        0.012901\n",
       "Polarity            0.011307\n",
       "Tempo               0.010349\n",
       "girl                0.008337\n",
       "che                 0.007418\n",
       "oh                  0.006701\n",
       "ogni                0.006645\n",
       "ben                 0.006076\n",
       "je                  0.005815\n",
       "mich                0.005648\n",
       "Mode                0.005332\n",
       "dtype: float64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train16.columns,model16.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Random Forest #2 - TF-IDF + top 7 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.147190529747752}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train17 = indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'baby', 'Subjectivity', 'Polarity',\n",
    "                              'Tempo']]\n",
    "y_train17 = indep_train['Valence']\n",
    "X_test17 = indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'baby', 'Subjectivity', 'Polarity',\n",
    "                            'Tempo']]\n",
    "y_test17 = indep_test['Valence']\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train17, y_train17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2067073825659824, 'Score (R^2)': 0.16374414162595438}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "model17 = RandomForestRegressor(max_depth=5, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(model17, X_train17, X_test17, y_train17, y_test17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest #3 - TF_IDF + top 3 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 60,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.13714638717866467}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train18 = indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train18 = indep_train['Valence']\n",
    "X_test18 = indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test18 = indep_test['Valence']\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train18, y_train18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.208516295100657, 'Score (R^2)': 0.1490438186500912}"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "model18 = RandomForestRegressor(max_depth=5, max_features='auto', n_estimators=60, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(model18, X_train18, X_test18, y_train18, y_test18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*COMMENT: The best RF is nr 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The over all best model was Lasso nr 1 with a R2-score of 0.1798104941720825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF, Lasso regressor all variables is the model in this notebook that scores the best.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
