{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Good Model for the mood of the song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document I need to work more with NLP of the track lyrics and use columns that I discarded in the MVP and I also need to do  some feature engineering.\n",
    "\n",
    "Better model = countries<BR />\n",
    "Best model = also looking at number of streams and position, also looking at time on top list<BR />\n",
    "\n",
    "Then when we have the best model we can use our predictions and decide the mood of a country and the mood of an artist. Then we can say what artist is suitable for what country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Position</th>\n",
       "      <th>Streams</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>40381</td>\n",
       "      <td>Bye Bye Bye</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>4r8lRYnoOGdEi6YyI5OC1o</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>gb</td>\n",
       "      <td>eu</td>\n",
       "      <td>hey, hey bye bye bye, bye bye bye bye  i'm doi...</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.00104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.656</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>24132</td>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>2017-12-23</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>it</td>\n",
       "      <td>eu</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>49766</td>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>2017-12-24</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>it</td>\n",
       "      <td>eu</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>40725</td>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>2017-12-25</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>it</td>\n",
       "      <td>eu</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>197</td>\n",
       "      <td>215739</td>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>us</td>\n",
       "      <td>na</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Position  Streams                       Track Name  Artist  \\\n",
       "0           0       177    40381                      Bye Bye Bye  *NSYNC   \n",
       "1           1       151    24132  Merry Christmas, Happy Holidays  *NSYNC   \n",
       "2           2        78    49766  Merry Christmas, Happy Holidays  *NSYNC   \n",
       "3           3        65    40725  Merry Christmas, Happy Holidays  *NSYNC   \n",
       "4           4       197   215739  Merry Christmas, Happy Holidays  *NSYNC   \n",
       "\n",
       "                       ID        Date  Year  Month  Day Country Region  \\\n",
       "0  4r8lRYnoOGdEi6YyI5OC1o  2017-10-05  2017     10    5      gb     eu   \n",
       "1  15coTBAzEN1bOeipoNDZAR  2017-12-23  2017     12   23      it     eu   \n",
       "2  15coTBAzEN1bOeipoNDZAR  2017-12-24  2017     12   24      it     eu   \n",
       "3  15coTBAzEN1bOeipoNDZAR  2017-12-25  2017     12   25      it     eu   \n",
       "4  15coTBAzEN1bOeipoNDZAR  2017-12-22  2017     12   22      us     na   \n",
       "\n",
       "                                              Lyrics  Acousticness  Energy  \\\n",
       "0  hey, hey bye bye bye, bye bye bye bye  i'm doi...        0.0408   0.928   \n",
       "1  merry christmas and happy holidays merry chris...        0.1030   0.939   \n",
       "2  merry christmas and happy holidays merry chris...        0.1030   0.939   \n",
       "3  merry christmas and happy holidays merry chris...        0.1030   0.939   \n",
       "4  merry christmas and happy holidays merry chris...        0.1030   0.939   \n",
       "\n",
       "   Instrumentalness  Mode    Tempo  Valence  \n",
       "0           0.00104   0.0  172.656    0.879  \n",
       "1           0.00000   1.0  105.003    0.756  \n",
       "2           0.00000   1.0  105.003    0.756  \n",
       "3           0.00000   1.0  105.003    0.756  \n",
       "4           0.00000   1.0  105.003    0.756  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data_top10c_more_lyrics.csv')\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix a little bit with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at each country individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gb', 'it', 'us', 'de', 'ca', 'nl', 'au', 'fr'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by country and make 8 new data frames\n",
    "gb_data = data[data['Country'] == 'gb']\n",
    "it_data = data[data['Country'] == 'it']\n",
    "us_data = data[data['Country'] == 'us']\n",
    "de_data = data[data['Country'] == 'de']\n",
    "ca_data = data[data['Country'] == 'ca']\n",
    "nl_data = data[data['Country'] == 'nl']\n",
    "au_data = data[data['Country'] == 'au']\n",
    "fr_data = data[data['Country'] == 'fr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop rows that are duplicates and keep only one row for each song**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_data_per_song = gb_data.drop_duplicates(subset=['Track Name'], keep='first')\n",
    "it_data_per_song = it_data.drop_duplicates(subset=['Track Name'], keep='first')\n",
    "us_data_per_song = us_data.drop_duplicates(subset=['Track Name'], keep='first')\n",
    "de_data_per_song = de_data.drop_duplicates(subset=['Track Name'], keep='first')\n",
    "ca_data_per_song = ca_data.drop_duplicates(subset=['Track Name'], keep='first')\n",
    "nl_data_per_song = nl_data.drop_duplicates(subset=['Track Name'], keep='first')\n",
    "au_data_per_song = au_data.drop_duplicates(subset=['Track Name'], keep='first')\n",
    "fr_data_per_song = fr_data.drop_duplicates(subset=['Track Name'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop all columns that might change per song**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_nlp_data = gb_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "it_nlp_data = it_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "us_nlp_data = us_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "de_nlp_data = de_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "ca_nlp_data = ca_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "nl_nlp_data = nl_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "au_nlp_data = au_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "fr_nlp_data = fr_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop rows that have missing values in the Lyrics column**<BR />\n",
    "We can use dropna to drop all rows that has missing values (should mostly be the Lyrics column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_clean = gb_nlp_data.dropna(axis=0, how='any')\n",
    "it_clean = it_nlp_data.dropna(axis=0, how='any')\n",
    "us_clean = us_nlp_data.dropna(axis=0, how='any')\n",
    "de_clean = de_nlp_data.dropna(axis=0, how='any')\n",
    "ca_clean = ca_nlp_data.dropna(axis=0, how='any')\n",
    "nl_clean = nl_nlp_data.dropna(axis=0, how='any')\n",
    "au_clean = au_nlp_data.dropna(axis=0, how='any')\n",
    "fr_clean = fr_nlp_data.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Turn the lyrics in the Lyrics column into string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "gb_clean['Lyrics'] = gb_clean['Lyrics'].astype(str)\n",
    "it_clean['Lyrics'] = it_clean['Lyrics'].astype(str)\n",
    "us_clean['Lyrics'] = us_clean['Lyrics'].astype(str)\n",
    "de_clean['Lyrics'] = de_clean['Lyrics'].astype(str)\n",
    "ca_clean['Lyrics'] = ca_clean['Lyrics'].astype(str)\n",
    "nl_clean['Lyrics'] = nl_clean['Lyrics'].astype(str)\n",
    "au_clean['Lyrics'] = au_clean['Lyrics'].astype(str)\n",
    "fr_clean['Lyrics'] = fr_clean['Lyrics'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make and run function for TextBlob on the Lyrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_func(lyrics):\n",
    "    try:\n",
    "        return TextBlob(lyrics).sentiment\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "gb_clean['pol_sub'] = gb_clean['Lyrics'].apply(sentiment_func)\n",
    "it_clean['pol_sub'] = it_clean['Lyrics'].apply(sentiment_func)\n",
    "us_clean['pol_sub'] = us_clean['Lyrics'].apply(sentiment_func)\n",
    "de_clean['pol_sub'] = de_clean['Lyrics'].apply(sentiment_func)\n",
    "ca_clean['pol_sub'] = ca_clean['Lyrics'].apply(sentiment_func)\n",
    "nl_clean['pol_sub'] = nl_clean['Lyrics'].apply(sentiment_func)\n",
    "au_clean['pol_sub'] = au_clean['Lyrics'].apply(sentiment_func)\n",
    "fr_clean['pol_sub'] = fr_clean['Lyrics'].apply(sentiment_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the pol_sub column into 2 new columns (Polarity, Subjectivity)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "gb_clean['Polarity'] = gb_clean['pol_sub'].apply(lambda x: x[0])\n",
    "gb_clean['Subjectivity'] = gb_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "it_clean['Polarity'] = it_clean['pol_sub'].apply(lambda x: x[0])\n",
    "it_clean['Subjectivity'] = it_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "us_clean['Polarity'] = us_clean['pol_sub'].apply(lambda x: x[0])\n",
    "us_clean['Subjectivity'] = us_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "de_clean['Polarity'] = de_clean['pol_sub'].apply(lambda x: x[0])\n",
    "de_clean['Subjectivity'] = de_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "ca_clean['Polarity'] = ca_clean['pol_sub'].apply(lambda x: x[0])\n",
    "ca_clean['Subjectivity'] = ca_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "nl_clean['Polarity'] = nl_clean['pol_sub'].apply(lambda x: x[0])\n",
    "nl_clean['Subjectivity'] = nl_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "au_clean['Polarity'] = au_clean['pol_sub'].apply(lambda x: x[0])\n",
    "au_clean['Subjectivity'] = au_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "fr_clean['Polarity'] = fr_clean['pol_sub'].apply(lambda x: x[0])\n",
    "fr_clean['Subjectivity'] = fr_clean['pol_sub'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop the pol_sub column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_clean = gb_clean.drop(['pol_sub'], axis=1)\n",
    "it_clean = it_clean.drop(['pol_sub'], axis=1)\n",
    "us_clean = us_clean.drop(['pol_sub'], axis=1)\n",
    "de_clean = de_clean.drop(['pol_sub'], axis=1)\n",
    "ca_clean = ca_clean.drop(['pol_sub'], axis=1)\n",
    "nl_clean = nl_clean.drop(['pol_sub'], axis=1)\n",
    "au_clean = au_clean.drop(['pol_sub'], axis=1)\n",
    "fr_clean = fr_clean.drop(['pol_sub'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a quick check of the entire data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1041 entries, 0 to 578617\n",
      "Data columns (total 12 columns):\n",
      "Track Name          1041 non-null object\n",
      "Artist              1041 non-null object\n",
      "ID                  1041 non-null object\n",
      "Lyrics              1041 non-null object\n",
      "Acousticness        1041 non-null float64\n",
      "Energy              1041 non-null float64\n",
      "Instrumentalness    1041 non-null float64\n",
      "Mode                1041 non-null float64\n",
      "Tempo               1041 non-null float64\n",
      "Valence             1041 non-null float64\n",
      "Polarity            1041 non-null float64\n",
      "Subjectivity        1041 non-null float64\n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 145.7+ KB\n"
     ]
    }
   ],
   "source": [
    "gb_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 952 entries, 1 to 578920\n",
      "Data columns (total 12 columns):\n",
      "Track Name          952 non-null object\n",
      "Artist              952 non-null object\n",
      "ID                  952 non-null object\n",
      "Lyrics              952 non-null object\n",
      "Acousticness        952 non-null float64\n",
      "Energy              952 non-null float64\n",
      "Instrumentalness    952 non-null float64\n",
      "Mode                952 non-null float64\n",
      "Tempo               952 non-null float64\n",
      "Valence             952 non-null float64\n",
      "Polarity            952 non-null float64\n",
      "Subjectivity        952 non-null float64\n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 136.7+ KB\n"
     ]
    }
   ],
   "source": [
    "it_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 908 entries, 4 to 578926\n",
      "Data columns (total 12 columns):\n",
      "Track Name          908 non-null object\n",
      "Artist              908 non-null object\n",
      "ID                  908 non-null object\n",
      "Lyrics              908 non-null object\n",
      "Acousticness        908 non-null float64\n",
      "Energy              908 non-null float64\n",
      "Instrumentalness    908 non-null float64\n",
      "Mode                908 non-null float64\n",
      "Tempo               908 non-null float64\n",
      "Valence             908 non-null float64\n",
      "Polarity            908 non-null float64\n",
      "Subjectivity        908 non-null float64\n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 92.2+ KB\n"
     ]
    }
   ],
   "source": [
    "us_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1020 entries, 8 to 577856\n",
      "Data columns (total 12 columns):\n",
      "Track Name          1020 non-null object\n",
      "Artist              1020 non-null object\n",
      "ID                  1020 non-null object\n",
      "Lyrics              1020 non-null object\n",
      "Acousticness        1020 non-null float64\n",
      "Energy              1020 non-null float64\n",
      "Instrumentalness    1020 non-null float64\n",
      "Mode                1020 non-null float64\n",
      "Tempo               1020 non-null float64\n",
      "Valence             1020 non-null float64\n",
      "Polarity            1020 non-null float64\n",
      "Subjectivity        1020 non-null float64\n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 103.6+ KB\n"
     ]
    }
   ],
   "source": [
    "de_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 801 entries, 32 to 578615\n",
      "Data columns (total 12 columns):\n",
      "Track Name          801 non-null object\n",
      "Artist              801 non-null object\n",
      "ID                  801 non-null object\n",
      "Lyrics              801 non-null object\n",
      "Acousticness        801 non-null float64\n",
      "Energy              801 non-null float64\n",
      "Instrumentalness    801 non-null float64\n",
      "Mode                801 non-null float64\n",
      "Tempo               801 non-null float64\n",
      "Valence             801 non-null float64\n",
      "Polarity            801 non-null float64\n",
      "Subjectivity        801 non-null float64\n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 81.4+ KB\n"
     ]
    }
   ],
   "source": [
    "ca_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 887 entries, 36 to 575613\n",
      "Data columns (total 12 columns):\n",
      "Track Name          887 non-null object\n",
      "Artist              887 non-null object\n",
      "ID                  887 non-null object\n",
      "Lyrics              887 non-null object\n",
      "Acousticness        887 non-null float64\n",
      "Energy              887 non-null float64\n",
      "Instrumentalness    887 non-null float64\n",
      "Mode                887 non-null float64\n",
      "Tempo               887 non-null float64\n",
      "Valence             887 non-null float64\n",
      "Polarity            887 non-null float64\n",
      "Subjectivity        887 non-null float64\n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 90.1+ KB\n"
     ]
    }
   ],
   "source": [
    "nl_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 646 entries, 41 to 578619\n",
      "Data columns (total 12 columns):\n",
      "Track Name          646 non-null object\n",
      "Artist              646 non-null object\n",
      "ID                  646 non-null object\n",
      "Lyrics              646 non-null object\n",
      "Acousticness        646 non-null float64\n",
      "Energy              646 non-null float64\n",
      "Instrumentalness    646 non-null float64\n",
      "Mode                646 non-null float64\n",
      "Tempo               646 non-null float64\n",
      "Valence             646 non-null float64\n",
      "Polarity            646 non-null float64\n",
      "Subjectivity        646 non-null float64\n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 65.6+ KB\n"
     ]
    }
   ],
   "source": [
    "au_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1238 entries, 48 to 578929\n",
      "Data columns (total 12 columns):\n",
      "Track Name          1238 non-null object\n",
      "Artist              1238 non-null object\n",
      "ID                  1238 non-null object\n",
      "Lyrics              1238 non-null object\n",
      "Acousticness        1238 non-null float64\n",
      "Energy              1238 non-null float64\n",
      "Instrumentalness    1238 non-null float64\n",
      "Mode                1238 non-null float64\n",
      "Tempo               1238 non-null float64\n",
      "Valence             1238 non-null float64\n",
      "Polarity            1238 non-null float64\n",
      "Subjectivity        1238 non-null float64\n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 125.7+ KB\n"
     ]
    }
   ],
   "source": [
    "fr_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the data into a train and a test set (with a test set of 25%, which is also default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_dep   = gb_clean['Valence']\n",
    "gb_indep = gb_clean\n",
    "gb_indep_train, gb_indep_test, gb_dep_train, gb_dep_test = train_test_split(gb_indep, gb_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "it_dep   = it_clean['Valence']\n",
    "it_indep = it_clean\n",
    "it_indep_train, it_indep_test, it_dep_train, it_dep_test = train_test_split(it_indep, it_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "us_dep   = us_clean['Valence']\n",
    "us_indep = us_clean\n",
    "us_indep_train, us_indep_test, us_dep_train, us_dep_test = train_test_split(us_indep, us_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "de_dep   = de_clean['Valence']\n",
    "de_indep = de_clean\n",
    "de_indep_train, de_indep_test, de_dep_train, de_dep_test = train_test_split(de_indep, de_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "ca_dep   = ca_clean['Valence']\n",
    "ca_indep = ca_clean\n",
    "ca_indep_train, ca_indep_test, ca_dep_train, ca_dep_test = train_test_split(ca_indep, ca_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "nl_dep   = nl_clean['Valence']\n",
    "nl_indep = nl_clean\n",
    "nl_indep_train, nl_indep_test, nl_dep_train, nl_dep_test = train_test_split(nl_indep, nl_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "au_dep   = au_clean['Valence']\n",
    "au_indep = au_clean\n",
    "au_indep_train, au_indep_test, au_dep_train, au_dep_test = train_test_split(au_indep, au_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "fr_dep   = fr_clean['Valence']\n",
    "fr_indep = fr_clean\n",
    "fr_indep_train, fr_indep_test, fr_dep_train, fr_dep_test = train_test_split(fr_indep, fr_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv with stop words\n",
    "stop_words_df = pd.read_csv('./stop_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the df to list\n",
    "stop_words = stop_words_df['colummn'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer (use in model 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "cvec = CountVectorizer(stop_words = stop_words, max_features = 1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(gb_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "gb_cvec = cvec.transform(gb_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df  = pd.DataFrame(gb_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "gb_indep_train_cvec = pd.concat([gb_indep_train.reset_index(drop=True), gb_df], axis=1)\n",
    "# transform X_test\n",
    "gb_cvec2 = cvec.transform(gb_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df2  = pd.DataFrame(gb_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "gb_indep_test_cvec = pd.concat([gb_indep_test.reset_index(drop=True), gb_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(it_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "it_cvec = cvec.transform(it_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df  = pd.DataFrame(it_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "it_indep_train_cvec = pd.concat([it_indep_train.reset_index(drop=True), it_df], axis=1)\n",
    "# transform X_test\n",
    "it_cvec2 = cvec.transform(it_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df2  = pd.DataFrame(it_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "it_indep_test_cvec = pd.concat([it_indep_test.reset_index(drop=True), it_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(us_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "us_cvec = cvec.transform(us_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df  = pd.DataFrame(us_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "us_indep_train_cvec = pd.concat([us_indep_train.reset_index(drop=True), us_df], axis=1)\n",
    "# transform X_test\n",
    "us_cvec2 = cvec.transform(us_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df2  = pd.DataFrame(us_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "us_indep_test_cvec = pd.concat([us_indep_test.reset_index(drop=True), us_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(de_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "de_cvec = cvec.transform(de_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df  = pd.DataFrame(de_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "de_indep_train_cvec = pd.concat([de_indep_train.reset_index(drop=True), de_df], axis=1)\n",
    "# transform X_test\n",
    "de_cvec2 = cvec.transform(de_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df2  = pd.DataFrame(de_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "de_indep_test_cvec = pd.concat([de_indep_test.reset_index(drop=True), de_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(ca_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "ca_cvec = cvec.transform(ca_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df  = pd.DataFrame(ca_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "ca_indep_train_cvec = pd.concat([ca_indep_train.reset_index(drop=True), ca_df], axis=1)\n",
    "# transform X_test\n",
    "ca_cvec2 = cvec.transform(ca_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df2  = pd.DataFrame(ca_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "ca_indep_test_cvec = pd.concat([ca_indep_test.reset_index(drop=True), ca_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(nl_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "nl_cvec = cvec.transform(nl_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df  = pd.DataFrame(nl_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "nl_indep_train_cvec = pd.concat([nl_indep_train.reset_index(drop=True), nl_df], axis=1)\n",
    "# transform X_test\n",
    "nl_cvec2 = cvec.transform(nl_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df2  = pd.DataFrame(nl_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "nl_indep_test_cvec = pd.concat([nl_indep_test.reset_index(drop=True), nl_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(au_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "au_cvec = cvec.transform(au_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df  = pd.DataFrame(au_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "au_indep_train_cvec = pd.concat([au_indep_train.reset_index(drop=True), au_df], axis=1)\n",
    "# transform X_test\n",
    "au_cvec2 = cvec.transform(au_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df2  = pd.DataFrame(au_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "au_indep_test_cvec = pd.concat([au_indep_test.reset_index(drop=True), au_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(fr_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "fr_cvec = cvec.transform(fr_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df  = pd.DataFrame(fr_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "fr_indep_train_cvec = pd.concat([fr_indep_train.reset_index(drop=True), fr_df], axis=1)\n",
    "# transform X_test\n",
    "fr_cvec2 = cvec.transform(fr_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df2  = pd.DataFrame(fr_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "fr_indep_test_cvec = pd.concat([fr_indep_test.reset_index(drop=True), fr_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (use in model 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "tvec = TfidfVectorizer(stop_words = stop_words, max_features = 1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(gb_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "gb_tvec = tvec.transform(gb_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df  = pd.DataFrame(gb_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "gb_indep_train_tvec = pd.concat([gb_indep_train.reset_index(drop=True), gb_df], axis=1)\n",
    "# transform X_test\n",
    "gb_tvec2 = tvec.transform(gb_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df2  = pd.DataFrame(gb_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "gb_indep_test_tvec = pd.concat([gb_indep_test.reset_index(drop=True), gb_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(it_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "it_tvec = tvec.transform(it_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df  = pd.DataFrame(it_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "it_indep_train_tvec = pd.concat([it_indep_train.reset_index(drop=True), it_df], axis=1)\n",
    "# transform X_test\n",
    "it_tvec2 = tvec.transform(it_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df2  = pd.DataFrame(it_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "it_indep_test_tvec = pd.concat([it_indep_test.reset_index(drop=True), it_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(us_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "us_tvec = tvec.transform(us_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df  = pd.DataFrame(us_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "us_indep_train_tvec = pd.concat([us_indep_train.reset_index(drop=True), us_df], axis=1)\n",
    "# transform X_test\n",
    "us_tvec2 = tvec.transform(us_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df2  = pd.DataFrame(us_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "us_indep_test_tvec = pd.concat([us_indep_test.reset_index(drop=True), us_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(de_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "de_tvec = tvec.transform(de_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df  = pd.DataFrame(de_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "de_indep_train_tvec = pd.concat([de_indep_train.reset_index(drop=True), de_df], axis=1)\n",
    "# transform X_test\n",
    "de_tvec2 = tvec.transform(de_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df2  = pd.DataFrame(de_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "de_indep_test_tvec = pd.concat([de_indep_test.reset_index(drop=True), de_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(ca_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "ca_tvec = tvec.transform(ca_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df  = pd.DataFrame(ca_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "ca_indep_train_tvec = pd.concat([ca_indep_train.reset_index(drop=True), ca_df], axis=1)\n",
    "# transform X_test\n",
    "ca_tvec2 = tvec.transform(ca_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df2  = pd.DataFrame(ca_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "ca_indep_test_tvec = pd.concat([ca_indep_test.reset_index(drop=True), ca_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(nl_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "nl_tvec = tvec.transform(nl_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df  = pd.DataFrame(nl_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "nl_indep_train_tvec = pd.concat([nl_indep_train.reset_index(drop=True), nl_df], axis=1)\n",
    "# transform X_test\n",
    "nl_tvec2 = tvec.transform(nl_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df2  = pd.DataFrame(nl_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "nl_indep_test_tvec = pd.concat([nl_indep_test.reset_index(drop=True), nl_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(au_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "au_tvec = tvec.transform(au_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df  = pd.DataFrame(au_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "au_indep_train_tvec = pd.concat([au_indep_train.reset_index(drop=True), au_df], axis=1)\n",
    "# transform X_test\n",
    "au_tvec2 = tvec.transform(au_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df2  = pd.DataFrame(au_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "au_indep_test_tvec = pd.concat([au_indep_test.reset_index(drop=True), au_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(fr_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "fr_tvec = tvec.transform(fr_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df  = pd.DataFrame(fr_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "fr_indep_train_tvec = pd.concat([fr_indep_train.reset_index(drop=True), fr_df], axis=1)\n",
    "# transform X_test\n",
    "fr_tvec2 = tvec.transform(fr_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df2  = pd.DataFrame(fr_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "fr_indep_test_tvec = pd.concat([fr_indep_test.reset_index(drop=True), fr_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models (Lasso) - CountVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did choose Lasso bc that gave the best score when looking at all countries togehter.<BR />\n",
    "If the Lasso scores very well in one country (compared to the total score) then I might consider trying other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso function (best hyperparameters to use and evauation of the model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_hype(model, params, X_train, y_train):  \n",
    "    # standardize\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train)\n",
    "    X_train_s = ss.transform(X_train)\n",
    "    \n",
    "    # Best Hyperparameters\n",
    "    gs = GridSearchCV(model, grid) # cv default = 3\n",
    "    \n",
    "    # fit\n",
    "    gs.fit(X_train_s, y_train)\n",
    "     \n",
    "    return {'best_score': gs.best_score_,'best_params': gs.best_params_} \n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # standardize the predictors\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train)\n",
    "    X_train_s = ss.transform(X_train)\n",
    "    X_test_s = ss.transform(X_test)\n",
    "    \n",
    "    # fit\n",
    "    model.fit(X_train_s, y_train)\n",
    "    \n",
    "    # Evaluate: predict\n",
    "    \n",
    "    y_pred = model.predict(X_test_s)\n",
    "    y_true = y_test\n",
    "    \n",
    "    mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Evaluate: score\n",
    "    score = model.score(X_test_s, y_test)\n",
    "    \n",
    "    return {'Score (R^2)': score.mean(), 'MSE': mean_square_error}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Brittan / United Kingdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.014174741629268055, 'selection': 'cyclic'},\n",
       " 'best_score': 0.1683966517723151}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_gb = gb_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_gb = gb_dep_train\n",
    "X_test_gb = gb_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_gb = gb_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_gb, y_train_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.21918612906036872, 'Score (R^2)': 0.12372100674644926}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0142, selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_gb, X_test_gb, y_train_gb, y_test_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy    0.072306\n",
       "lies      0.011188\n",
       "yes       0.010698\n",
       "nigga     0.009808\n",
       "hot       0.009049\n",
       "wanted    0.007884\n",
       "little    0.007816\n",
       "kind      0.007759\n",
       "Mode      0.007620\n",
       "scared    0.007187\n",
       "sexy      0.006676\n",
       "honey     0.006455\n",
       "ring      0.006309\n",
       "niggas    0.005751\n",
       "lovers    0.005324\n",
       "dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_gb.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - CountVec + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.0013219411484660286, 'selection': 'cyclic'},\n",
       " 'best_score': 0.21745378864477283}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_gb2 = gb_indep_train_cvec[['Energy', 'lies', 'yes', 'nigga', 'hot', 'wanted', 'little', 'kind',\n",
    "                                'Mode', 'scared']]\n",
    "y_train_gb2 = gb_dep_train\n",
    "X_test_gb2 = gb_indep_test_cvec[['Energy', 'lies', 'yes', 'nigga', 'hot', 'wanted', 'little', 'kind',\n",
    "                                'Mode', 'scared']]\n",
    "y_test_gb2 = gb_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_gb2, y_train_gb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2797014595389332, 'Score (R^2)': -0.4269400652275712}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0013, \n",
    "                  selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_gb2, X_test_gb2, y_train_gb2, y_test_gb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - CountVec + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.0013219411484660286, 'selection': 'random'},\n",
       " 'best_score': 0.16102250768577955}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_gb3 = gb_indep_train_cvec[['Energy', 'lies', 'yes']]\n",
    "y_train_gb3 = gb_dep_train\n",
    "X_test_gb3 = gb_indep_test_cvec[['Energy', 'lies', 'yes']]\n",
    "y_test_gb3 = gb_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_gb3, y_train_gb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.21418328472846523, 'Score (R^2)': 0.16326600066483032}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0013, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_gb3, X_test_gb3, y_train_gb3, y_test_gb3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for GB is nr 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.016297508346206444, 'selection': 'cyclic'},\n",
       " 'best_score': 0.10361454849115626}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_it = it_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_it = it_dep_train\n",
    "X_test_it = it_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_it = it_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_it, y_train_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19770016544111002, 'Score (R^2)': 0.129795914234341}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0163, selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_it, X_test_it, y_train_it, y_test_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy       0.054747\n",
       "oh           0.012264\n",
       "pa           0.010187\n",
       "slow         0.008017\n",
       "ogni         0.007033\n",
       "yes          0.006925\n",
       "sing         0.005469\n",
       "heart        0.005298\n",
       "mistletoe    0.004306\n",
       "girl         0.004016\n",
       "domani       0.003997\n",
       "colpa        0.003705\n",
       "pretty       0.003625\n",
       "tú           0.003604\n",
       "davvero      0.003454\n",
       "dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_it.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - CountVec + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.001747528400007683, 'selection': 'random'},\n",
       " 'best_score': 0.19150410411859672}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_it2 = it_indep_train_cvec[['Energy', 'oh', 'pa', 'slow', 'ogni', 'yes', 'sing', 'heart', 'mistletoe', 'girl']]\n",
    "y_train_it2 = it_dep_train\n",
    "X_test_it2 = it_indep_test_cvec[['Energy', 'oh', 'pa', 'slow', 'ogni', 'yes', 'sing', 'heart', 'mistletoe', 'girl']]\n",
    "y_test_it2 = it_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_it2, y_train_it2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1983103291352571, 'Score (R^2)': 0.12441618880693563}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0017, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_it2, X_test_it2, y_train_it2, y_test_it2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - CountVec + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.001747528400007683, 'selection': 'cyclic'},\n",
       " 'best_score': 0.12924155327088646}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_it3 = it_indep_train_cvec[['Energy', 'oh', 'pa']]\n",
    "y_train_it3 = it_dep_train\n",
    "X_test_it3 = it_indep_test_cvec[['Energy', 'oh', 'pa']]\n",
    "y_test_it3 = it_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_it3, y_train_it3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20250334197393632, 'Score (R^2)': 0.0869986023385424}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0017, \n",
    "                  selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_it3, X_test_it3, y_train_it3, y_test_it3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for IT is nr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.012328467394420659, 'selection': 'cyclic'},\n",
       " 'best_score': 0.16815884107343257}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_us = us_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_us = us_dep_train\n",
    "X_test_us = us_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_us = us_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=10000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_us, y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.207156835957949, 'Score (R^2)': 0.1626550940687036}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=10000, alpha=0.0123, selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_us, X_test_us, y_train_us, y_test_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy     0.076635\n",
       "baby       0.020060\n",
       "rollie     0.012212\n",
       "cake       0.012170\n",
       "bitch      0.011404\n",
       "bells      0.010804\n",
       "ground     0.010176\n",
       "askin      0.008671\n",
       "sure       0.008383\n",
       "sing       0.007925\n",
       "sheets     0.007804\n",
       "worry      0.007282\n",
       "nick       0.006946\n",
       "bands      0.006844\n",
       "calling    0.006620\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_us.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - CountVec + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.005336699231206312, 'selection': 'random'},\n",
       " 'best_score': 0.23703559962807996}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_us2 = us_indep_train_cvec[['Energy', 'baby', 'rollie', 'cake', 'bitch', 'bells', 'ground', 'askin',\n",
    "                                'sure', 'sing']]\n",
    "y_train_us2 = us_dep_train\n",
    "X_test_us2 = us_indep_test_cvec[['Energy', 'baby', 'rollie', 'cake', 'bitch', 'bells', 'ground', 'askin',\n",
    "                                'sure', 'sing']]\n",
    "y_test_us2 = us_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_us2, y_train_us2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20746232941947448, 'Score (R^2)': 0.16018361386091773}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0053, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_us2, X_test_us2, y_train_us2, y_test_us2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - CountVec + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.001, 'selection': 'random'},\n",
       " 'best_score': 0.1869515895970676}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_us3 = us_indep_train_cvec[['Energy', 'baby', 'rollie']]\n",
    "y_train_us3 = us_dep_train\n",
    "X_test_us3 = us_indep_test_cvec[['Energy', 'baby', 'rollie']]\n",
    "y_test_us3 = us_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_us3, y_train_us3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20800162998603408, 'Score (R^2)': 0.15581171530153481}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_us3, X_test_us3, y_train_us3, y_test_us3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for US is nr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deutchland / Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.014174741629268055, 'selection': 'cyclic'},\n",
       " 'best_score': 0.08500697940732012}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_de = de_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_de = de_dep_train\n",
    "X_test_de = de_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_de = de_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_de, y_train_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19605402659952886, 'Score (R^2)': 0.14787882213504022}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0142, selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_de, X_test_de, y_train_de, y_test_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy    0.053430\n",
       "snow      0.012721\n",
       "ahh       0.009732\n",
       "bit       0.008868\n",
       "moment    0.005708\n",
       "erst      0.005485\n",
       "baby      0.005459\n",
       "viel      0.004376\n",
       "Mode      0.003797\n",
       "plan      0.003254\n",
       "fast      0.003224\n",
       "uh        0.003008\n",
       "dicka     0.002914\n",
       "seele     0.002586\n",
       "fresh     0.002390\n",
       "dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_de.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - CountVec + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.0013219411484660286, 'selection': 'random'},\n",
       " 'best_score': 0.17855719581864732}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_de2 = de_indep_train_cvec[['Energy', 'snow', 'ahh', 'bit', 'moment', 'erst', 'baby', 'viel',\n",
    "                                'Mode', 'plan']]\n",
    "y_train_de2 = de_dep_train\n",
    "X_test_de2 = de_indep_test_cvec[['Energy', 'snow', 'ahh', 'bit', 'moment', 'erst', 'baby', 'viel',\n",
    "                                'Mode', 'plan']]\n",
    "y_test_de2 = de_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_de2, y_train_de2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19376925752158428, 'Score (R^2)': 0.1676239483701173}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0013, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_de2, X_test_de2, y_train_de2, y_test_de2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - CountVec + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.001, 'selection': 'random'},\n",
       " 'best_score': 0.12061143715799284}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_de3 = de_indep_train_cvec[['Energy', 'snow', 'ahh']]\n",
    "y_train_de3 = de_dep_train\n",
    "X_test_de3 = de_indep_test_cvec[['Energy', 'snow', 'ahh']]\n",
    "y_test_de3 = de_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_de3, y_train_de3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19647908136332912, 'Score (R^2)': 0.1441799356190453}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_de3, X_test_de3, y_train_de3, y_test_de3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for DE is nr 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.014174741629268055, 'selection': 'cyclic'},\n",
       " 'best_score': 0.15930869073648657}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_ca = ca_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_ca = ca_dep_train\n",
    "X_test_ca = ca_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_ca = ca_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_ca, y_train_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.22657917601179678, 'Score (R^2)': 0.07276780488464796}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0142, selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_ca, X_test_ca, y_train_ca, y_test_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.067558\n",
       "sing                0.025703\n",
       "baby                0.013972\n",
       "Acousticness        0.013553\n",
       "oh                  0.010626\n",
       "rollie              0.010614\n",
       "fucked              0.008410\n",
       "Instrumentalness    0.007637\n",
       "year                0.007305\n",
       "remember            0.006855\n",
       "brand               0.006680\n",
       "slow                0.006604\n",
       "bit                 0.006290\n",
       "nick                0.005191\n",
       "snow                0.005035\n",
       "dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_ca.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - CountVec + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.0023101297000831605, 'selection': 'cyclic'},\n",
       " 'best_score': 0.26790626157168884}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_ca2 = ca_indep_train_cvec[['Energy', 'sing', 'baby', 'Acousticness', 'oh', 'rollie', 'fucked', \n",
    "                                   'Instrumentalness', 'year', 'remember']]\n",
    "y_train_ca2 = ca_dep_train\n",
    "X_test_ca2 = ca_indep_test_cvec[['Energy', 'sing', 'baby', 'Acousticness', 'oh', 'rollie', 'fucked', \n",
    "                                'Instrumentalness', 'year', 'remember']]\n",
    "y_test_ca2 = ca_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_ca2, y_train_ca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.23197827784145408, 'Score (R^2)': 0.02805171789476601}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0023, \n",
    "                  selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_ca2, X_test_ca2, y_train_ca2, y_test_ca2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - CountVec + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.0013219411484660286, 'selection': 'random'},\n",
       " 'best_score': 0.1833856494586246}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_ca3 = ca_indep_train_cvec[['Energy', 'sing', 'baby']]\n",
    "y_train_ca3 = ca_dep_train\n",
    "X_test_ca3 = ca_indep_test_cvec[['Energy', 'sing', 'baby']]\n",
    "y_test_ca3 = ca_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_ca3, y_train_ca3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2323572971552353, 'Score (R^2)': 0.024873074443244828}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0013, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_ca3, X_test_ca3, y_train_ca3, y_test_ca3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for CA is nr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netherlands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.016297508346206444, 'selection': 'cyclic'},\n",
       " 'best_score': 0.1847801802854809}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_nl = nl_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_nl = nl_dep_train\n",
    "X_test_nl = nl_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_nl = nl_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=10000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_nl, y_train_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20570261363696934, 'Score (R^2)': 0.08232260169784689}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=10000, alpha=0.0163, selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_nl, X_test_nl, y_train_nl, y_test_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy     0.078225\n",
       "Mode       0.011507\n",
       "bells      0.011294\n",
       "let        0.008211\n",
       "saaf       0.006024\n",
       "weg        0.005755\n",
       "baby       0.005137\n",
       "kan        0.004927\n",
       "life       0.004434\n",
       "apart      0.003696\n",
       "praten     0.003185\n",
       "light      0.003032\n",
       "sing       0.003026\n",
       "moest      0.002991\n",
       "feeling    0.002460\n",
       "dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_nl.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - CountVec + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.0026560877829466868, 'selection': 'random'},\n",
       " 'best_score': 0.2446037402505679}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_nl2 = nl_indep_train_cvec[['Energy', 'Mode', 'bells', 'let', 'saaf', 'weg', 'baby', 'kan',\n",
    "                                'life', 'apart']]\n",
    "y_train_nl2 = nl_dep_train\n",
    "X_test_nl2 = nl_indep_test_cvec[['Energy', 'Mode', 'bells', 'let', 'saaf', 'weg', 'baby', 'kan',\n",
    "                                'life', 'apart']]\n",
    "y_test_nl2 = nl_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_nl2, y_train_nl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.22999339070496982, 'Score (R^2)': -0.1472052549351377}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0027, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_nl2, X_test_nl2, y_train_nl2, y_test_nl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - CountVec + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.0030538555088334154, 'selection': 'random'},\n",
       " 'best_score': 0.21151890852905245}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_nl3 = nl_indep_train_cvec[['Energy', 'Mode', 'bells']]\n",
    "y_train_nl3 = nl_dep_train\n",
    "X_test_nl3 = nl_indep_test_cvec[['Energy', 'Mode', 'bells']]\n",
    "y_test_nl3 = nl_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_nl3, y_train_nl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.205671658747888, 'Score (R^2)': 0.08259877188557052}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0031, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_nl3, X_test_nl3, y_train_nl3, y_test_nl3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for NL is nr 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.021544346900318846, 'selection': 'cyclic'},\n",
       " 'best_score': 0.15196701824089573}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_au = au_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_au = au_dep_train\n",
    "X_test_au = au_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_au = au_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=10000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_au, y_train_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2032233116982194, 'Score (R^2)': 0.19147938948164733}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=10000, alpha=0.0215, selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_au, X_test_au, y_train_au, y_test_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy       0.063603\n",
       "sing         0.016007\n",
       "baby         0.008907\n",
       "sweat        0.006581\n",
       "ring         0.005776\n",
       "hey          0.005512\n",
       "year         0.005325\n",
       "road         0.004765\n",
       "attention    0.004345\n",
       "jump         0.003947\n",
       "alright      0.003563\n",
       "ride         0.003460\n",
       "sip          0.003339\n",
       "mess         0.003003\n",
       "says         0.001592\n",
       "dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_au.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - CountVec + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.005336699231206312, 'selection': 'random'},\n",
       " 'best_score': 0.23643307953613585}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_au2 = au_indep_train_cvec[['Energy', 'sing', 'baby', 'sweat', 'ring', 'hey', 'year', 'road',\n",
    "                                'attention', 'jump']]\n",
    "y_train_au2 = au_dep_train\n",
    "X_test_au2 = au_indep_test_cvec[['Energy', 'sing', 'baby', 'sweat', 'ring', 'hey', 'year', 'road',\n",
    "                                'attention', 'jump']]\n",
    "y_test_au2 = au_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_au2, y_train_au2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20500858588565368, 'Score (R^2)': 0.17721162577770821}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0053, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_au2, X_test_au2, y_train_au2, y_test_au2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - CountVec + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.001, 'selection': 'random'},\n",
       " 'best_score': 0.1880024050952279}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_au3 = au_indep_train_cvec[['Energy', 'sing', 'baby']]\n",
    "y_train_au3 = au_dep_train\n",
    "X_test_au3 = au_indep_test_cvec[['Energy', 'sing', 'baby']]\n",
    "y_test_au3 = au_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_au3, y_train_au3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20311970915467437, 'Score (R^2)': 0.19230354139175532}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_au3, X_test_au3, y_train_au3, y_test_au3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for AU is nr 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.016297508346206444, 'selection': 'cyclic'},\n",
       " 'best_score': 0.16762695430259927}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_fr = fr_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_fr = fr_dep_train\n",
    "X_test_fr = fr_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_fr = fr_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_fr, y_train_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1965943250668124, 'Score (R^2)': 0.17412071001770535}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0163, selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_fr, X_test_fr, y_train_fr, y_test_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy          0.072582\n",
       "x2              0.017689\n",
       "snow            0.009138\n",
       "fine            0.007774\n",
       "bout            0.006733\n",
       "sing            0.005494\n",
       "quartier        0.005459\n",
       "Acousticness    0.005119\n",
       "dancing         0.004101\n",
       "baby            0.004017\n",
       "sommet          0.002431\n",
       "pute            0.002318\n",
       "rend            0.002135\n",
       "jul             0.001950\n",
       "lumière         0.001632\n",
       "dtype: float64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_fr.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do not use x2, that is from the lyrics text and only showing if something is repeating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - CountVec + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.0026560877829466868, 'selection': 'cyclic'},\n",
       " 'best_score': 0.20654440096710708}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_fr2 = fr_indep_train_cvec[['Energy', 'snow', 'fine', 'bout', 'sing', 'quartier', 'Acousticness', 'dancing',\n",
    "                                'baby', 'sommet']]\n",
    "y_train_fr2 = fr_dep_train\n",
    "X_test_fr2 = fr_indep_test_cvec[['Energy', 'snow', 'fine', 'bout', 'sing', 'quartier', 'Acousticness', 'dancing',\n",
    "                                'baby', 'sommet']]\n",
    "y_test_fr2 = fr_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_fr2, y_train_fr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20890472878595792, 'Score (R^2)': 0.0674520689541851}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0027, \n",
    "                  selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_fr2, X_test_fr2, y_train_fr2, y_test_fr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - CountVec + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.001, 'selection': 'cyclic'},\n",
       " 'best_score': 0.17040468269503137}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_fr3 = fr_indep_train_cvec[['Energy', 'snow', 'fine']]\n",
    "y_train_fr3 = fr_dep_train\n",
    "X_test_fr3 = fr_indep_test_cvec[['Energy', 'snow', 'fine']]\n",
    "y_test_fr3 = fr_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_fr3, y_train_fr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19728395940514648, 'Score (R^2)': 0.16831633403080726}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0013, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_fr3, X_test_fr3, y_train_fr3, y_test_fr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for FR is nr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary CountVec - best model/score per country**<BR />\n",
    "gb - R2 = 0.16326600066483032 (top 3 coefs)<BR />\n",
    "it - R2 = 0.129795914234341 (all coefs)<BR />\n",
    "us - R2 = 0.1626550940687036 (all coefs)<BR />\n",
    "de - R2 = 0.1676239483701173 (top 10 coefs)<BR />\n",
    "ca - R2 = 0.07276780488464796 (all coefs)<BR />\n",
    "nl - R2 = 0.08259877188557052 (top 3 coefs)<BR />\n",
    "au - R2 = 0.19230354139175532 (top 3 coefs)<BR />\n",
    "fr - R2 = 0.17412071001770535 (all coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The score and how many varables to choose (and which ones) varies from country to country*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models (Lasso) - TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did choose Lasso bc that gave the best score when looking at all countries togehter.<BR />\n",
    "If the Lasso scores very well in one country (compared to the total score) then I might consider trying other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso function (best hyperparameters to use and evauation of the model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_hype(model, params, X_train, y_train):  \n",
    "    # standardize\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train)\n",
    "    X_train_s = ss.transform(X_train)\n",
    "    \n",
    "    # Best Hyperparameters\n",
    "    gs = GridSearchCV(model, grid) # cv default = 3\n",
    "    \n",
    "    # fit\n",
    "    gs.fit(X_train_s, y_train)\n",
    "     \n",
    "    return {'best_score': gs.best_score_,'best_params': gs.best_params_} \n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # standardize the predictors\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_train)\n",
    "    X_train_s = ss.transform(X_train)\n",
    "    X_test_s = ss.transform(X_test)\n",
    "    \n",
    "    # fit\n",
    "    model.fit(X_train_s, y_train)\n",
    "    \n",
    "    # Evaluate: predict\n",
    "    \n",
    "    y_pred = model.predict(X_test_s)\n",
    "    y_true = y_test\n",
    "    \n",
    "    mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Evaluate: score\n",
    "    score = model.score(X_test_s, y_test)\n",
    "    \n",
    "    return {'Score (R^2)': score.mean(), 'MSE': mean_square_error}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Brittan / United Kingdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.014174741629268055, 'selection': 'cyclic'},\n",
       " 'best_score': 0.15992337416126728}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_gb = gb_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_gb = gb_dep_train\n",
    "X_test_gb = gb_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_gb = gb_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_gb, y_train_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20965856308450798, 'Score (R^2)': 0.19824536945416926}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0142, selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_gb, X_test_gb, y_train_gb, y_test_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy    0.070752\n",
       "nigga     0.013034\n",
       "yes       0.011485\n",
       "niggas    0.009455\n",
       "lies      0.009167\n",
       "girl      0.008916\n",
       "little    0.008107\n",
       "sexy      0.007695\n",
       "til       0.007196\n",
       "Mode      0.006588\n",
       "wanted    0.006557\n",
       "piece     0.006490\n",
       "year      0.006062\n",
       "hot       0.005779\n",
       "scared    0.005671\n",
       "dtype: float64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_gb.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - TF-IDF + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.003511191734215131, 'selection': 'random'},\n",
       " 'best_score': 0.20992415971407796}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_gb2 = gb_indep_train_tvec[['Energy', 'nigga', 'yes', 'niggas', 'lies', 'girl', 'little', 'sexy',\n",
    "                                'til', 'Mode']]\n",
    "y_train_gb2 = gb_dep_train\n",
    "X_test_gb2 = gb_indep_test_tvec[['Energy', 'nigga', 'yes', 'niggas', 'lies', 'girl', 'little', 'sexy',\n",
    "                                'til', 'Mode']]\n",
    "y_test_gb2 = gb_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_gb2, y_train_gb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.21431902256172267, 'Score (R^2)': 0.16220511069342944}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0035, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_gb2, X_test_gb2, y_train_gb2, y_test_gb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - TF-IDF + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.003511191734215131, 'selection': 'random'},\n",
       " 'best_score': 0.1586682563987102}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_gb3 = gb_indep_train_tvec[['Energy', 'nigga', 'yes']]\n",
    "y_train_gb3 = gb_dep_train\n",
    "X_test_gb3 = gb_indep_test_tvec[['Energy', 'nigga', 'yes']]\n",
    "y_test_gb3 = gb_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_gb3, y_train_gb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.21739922648868718, 'Score (R^2)': 0.1379503974694909}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0035, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_gb3, X_test_gb3, y_train_gb3, y_test_gb3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for GB is nr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.016297508346206444, 'selection': 'cyclic'},\n",
       " 'best_score': 0.09839733718258148}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_it = it_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_it = it_dep_train\n",
    "X_test_it = it_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_it = it_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_it, y_train_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1963286403446403, 'Score (R^2)': 0.14182794084676598}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0163, selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_it, X_test_it, y_train_it, y_test_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy     0.055309\n",
       "oh         0.008944\n",
       "baby       0.007454\n",
       "yes        0.006948\n",
       "davvero    0.006784\n",
       "slow       0.006589\n",
       "ogni       0.006167\n",
       "girl       0.005481\n",
       "pa         0.004603\n",
       "hide       0.003974\n",
       "stesso     0.003801\n",
       "colpa      0.003487\n",
       "quello     0.003412\n",
       "domani     0.003121\n",
       "vuoto      0.003061\n",
       "dtype: float64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_it.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - TF-IDF + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.001, 'selection': 'cyclic'},\n",
       " 'best_score': 0.18054457208343117}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_it2 = it_indep_train_tvec[['Energy', 'oh', 'baby', 'yes', 'davvero', 'slow', 'ogni', 'girl', 'pa', 'hide']]\n",
    "y_train_it2 = it_dep_train\n",
    "X_test_it2 = it_indep_test_tvec[['Energy', 'oh', 'baby', 'yes', 'davvero', 'slow', 'ogni', 'girl', 'pa', 'hide']]\n",
    "y_test_it2 = it_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_it2, y_train_it2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19911841636100364, 'Score (R^2)': 0.11726588376323954}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, \n",
    "                  selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_it2, X_test_it2, y_train_it2, y_test_it2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - TF-IDF  + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.001, 'selection': 'random'},\n",
       " 'best_score': 0.11933989374598247}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_it3 = it_indep_train_tvec[['Energy', 'oh', 'baby']]\n",
    "y_train_it3 = it_dep_train\n",
    "X_test_it3 = it_indep_test_tvec[['Energy', 'oh', 'baby']]\n",
    "y_test_it3 = it_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_it3, y_train_it3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2000009103606321, 'Score (R^2)': 0.10942397884882317}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_it3, X_test_it3, y_train_it3, y_test_it3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for IT is nr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.016297508346206444, 'selection': 'cyclic'},\n",
       " 'best_score': 0.16685797058117727}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_us = us_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_us = us_dep_train\n",
    "X_test_us = us_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_us = us_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=10000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_us, y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2039263436348886, 'Score (R^2)': 0.18856729273094788}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=10000, alpha=0.0163, selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_us, X_test_us, y_train_us, y_test_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy     0.071159\n",
       "baby       0.017566\n",
       "bitch      0.016582\n",
       "rollie     0.009700\n",
       "cake       0.009664\n",
       "hey        0.006862\n",
       "snow       0.006845\n",
       "ground     0.006151\n",
       "fucking    0.004809\n",
       "askin      0.004478\n",
       "bells      0.003999\n",
       "sure       0.002857\n",
       "mom        0.002627\n",
       "shit       0.002469\n",
       "soul       0.002452\n",
       "dtype: float64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_us.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - TF-IDF + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.004037017258596553, 'selection': 'random'},\n",
       " 'best_score': 0.24548921646298186}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_us2 = us_indep_train_tvec[['Energy', 'baby', 'bitch', 'rollie', 'cake', 'hey', 'snow', 'ground',\n",
    "                                'fucking', 'askin']]\n",
    "y_train_us2 = us_dep_train\n",
    "X_test_us2 = us_indep_test_tvec[['Energy', 'baby', 'bitch', 'rollie', 'cake', 'hey', 'snow', 'ground',\n",
    "                                'fucking', 'askin']]\n",
    "y_test_us2 = us_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_us2, y_train_us2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.21311377758339578, 'Score (R^2)': 0.11380580892919079}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0040, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_us2, X_test_us2, y_train_us2, y_test_us2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - TF-IDF + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.001, 'selection': 'cyclic'},\n",
       " 'best_score': 0.1915458239435362}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_us3 = us_indep_train_tvec[['Energy', 'baby', 'bitch']]\n",
    "y_train_us3 = us_dep_train\n",
    "X_test_us3 = us_indep_test_tvec[['Energy', 'baby', 'bitch']]\n",
    "y_test_us3 = us_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_us3, y_train_us3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2062007590577543, 'Score (R^2)': 0.1703663406620386}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, \n",
    "                  selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_us3, X_test_us3, y_train_us3, y_test_us3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for US is nr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deutchland / Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.014174741629268055, 'selection': 'random'},\n",
       " 'best_score': 0.10260319639826802}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_de = de_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_de = de_dep_train\n",
    "X_test_de = de_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_de = de_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_de, y_train_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19702451654502356, 'Score (R^2)': 0.13942174669991036}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0142, selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_de, X_test_de, y_train_de, y_test_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy    0.053144\n",
       "snow      0.016295\n",
       "seele     0.006984\n",
       "hide      0.006081\n",
       "bit       0.006004\n",
       "baby      0.005770\n",
       "stop      0.005340\n",
       "mi        0.005261\n",
       "tryin     0.004331\n",
       "jahr      0.004280\n",
       "deep      0.004218\n",
       "schieß    0.004043\n",
       "alles     0.004039\n",
       "dicka     0.003946\n",
       "ne        0.003731\n",
       "dtype: float64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_de.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - TF-IDF + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.001, 'selection': 'cyclic'},\n",
       " 'best_score': 0.17605461654719518}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_de2 = de_indep_train_tvec[['Energy', 'snow', 'seele', 'hide', 'bit', 'baby', 'stop', 'mi',\n",
    "                                'tryin', 'jahr']]\n",
    "y_train_de2 = de_dep_train\n",
    "X_test_de2 = de_indep_test_tvec[['Energy', 'snow', 'seele', 'hide', 'bit', 'baby', 'stop', 'mi',\n",
    "                                'tryin', 'jahr']]\n",
    "y_test_de2 = de_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_de2, y_train_de2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2059957524275389, 'Score (R^2)': 0.05926704713528552}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, \n",
    "                  selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_de2, X_test_de2, y_train_de2, y_test_de2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - TF-IDF + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.001, 'selection': 'cyclic'},\n",
       " 'best_score': 0.12593917028658846}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_de3 = de_indep_train_tvec[['Energy', 'snow', 'seele']]\n",
    "y_train_de3 = de_dep_train\n",
    "X_test_de3 = de_indep_test_tvec[['Energy', 'snow', 'seele']]\n",
    "y_test_de3 = de_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_de3, y_train_de3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20209583173775286, 'Score (R^2)': 0.09454986315531066}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, \n",
    "                  selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_de3, X_test_de3, y_train_de3, y_test_de3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for DE is nr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.01873817422860384, 'selection': 'random'},\n",
       " 'best_score': 0.13539154870271772}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_ca = ca_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_ca = ca_dep_train\n",
    "X_test_ca = ca_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_ca = ca_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_ca, y_train_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2234710335512767, 'Score (R^2)': 0.09803228704669986}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0187, selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_ca, X_test_ca, y_train_ca, y_test_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.061516\n",
       "sing                0.016041\n",
       "baby                0.012496\n",
       "rollie              0.007170\n",
       "Acousticness        0.006309\n",
       "year                0.005700\n",
       "fucked              0.005159\n",
       "Instrumentalness    0.004609\n",
       "ye                  0.003095\n",
       "brand               0.003008\n",
       "picture             0.002939\n",
       "mistletoe           0.002397\n",
       "cake                0.002248\n",
       "real                0.001954\n",
       "nick                0.001210\n",
       "dtype: float64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_ca.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - TF-IDF + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.0015199110829529332, 'selection': 'random'},\n",
       " 'best_score': 0.24688227138352511}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_ca2 = ca_indep_train_tvec[['Energy', 'sing', 'baby', 'rollie', 'Acousticness', 'year', 'fucked', \n",
    "                                   'Instrumentalness', 'ye', 'brand']]\n",
    "y_train_ca2 = ca_dep_train\n",
    "X_test_ca2 = ca_indep_test_tvec[['Energy', 'sing', 'baby', 'rollie', 'Acousticness', 'year', 'fucked', \n",
    "                                   'Instrumentalness', 'ye', 'brand']]\n",
    "y_test_ca2 = ca_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_ca2, y_train_ca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.23511120386212514, 'Score (R^2)': 0.001621621693280506}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0015, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_ca2, X_test_ca2, y_train_ca2, y_test_ca2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - TF-IDF + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.001, 'selection': 'random'},\n",
       " 'best_score': 0.16892214749704096}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_ca3 = ca_indep_train_tvec[['Energy', 'sing', 'baby']]\n",
    "y_train_ca3 = ca_dep_train\n",
    "X_test_ca3 = ca_indep_test_tvec[['Energy', 'sing', 'baby']]\n",
    "y_test_ca3 = ca_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_ca3, y_train_ca3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.23812187229738607, 'Score (R^2)': -0.024111148255464124}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_ca3, X_test_ca3, y_train_ca3, y_test_ca3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for CA is nr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Netherlands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.016297508346206444, 'selection': 'random'},\n",
       " 'best_score': 0.17853784719484486}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_nl = nl_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_nl = nl_dep_train\n",
    "X_test_nl = nl_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_nl = nl_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=10000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_nl, y_train_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20337672125782755, 'Score (R^2)': 0.10295774896764186}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=10000, alpha=0.0163, selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_nl, X_test_nl, y_train_nl, y_test_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy     0.078235\n",
       "bells      0.012143\n",
       "Mode       0.010153\n",
       "baby       0.008322\n",
       "weg        0.006981\n",
       "let        0.006770\n",
       "town       0.006758\n",
       "apart      0.005094\n",
       "saaf       0.005025\n",
       "kan        0.004808\n",
       "moest      0.004233\n",
       "goes       0.004068\n",
       "forever    0.004048\n",
       "praten     0.003035\n",
       "drugs      0.002930\n",
       "dtype: float64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_nl.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - TF-IDF + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.002009233002565048, 'selection': 'random'},\n",
       " 'best_score': 0.264407184215115}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_nl2 = nl_indep_train_tvec[['Energy', 'bells', 'Mode', 'baby', 'weg', 'let', 'town', 'apart',\n",
    "                                'saaf', 'kan']]\n",
    "y_train_nl2 = nl_dep_train\n",
    "X_test_nl2 = nl_indep_test_tvec[['Energy', 'bells', 'Mode', 'baby', 'weg', 'let', 'town', 'apart',\n",
    "                                'saaf', 'kan']]\n",
    "y_test_nl2 = nl_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_nl2, y_train_nl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.21438045293241847, 'Score (R^2)': 0.003262531682686198}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0020, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_nl2, X_test_nl2, y_train_nl2, y_test_nl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - TF-IDF + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.0023101297000831605, 'selection': 'random'},\n",
       " 'best_score': 0.2123807188625051}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_nl3 = nl_indep_train_tvec[['Energy', 'bells', 'Mode']]\n",
    "y_train_nl3 = nl_dep_train\n",
    "X_test_nl3 = nl_indep_test_tvec[['Energy', 'bells', 'Mode']]\n",
    "y_test_nl3 = nl_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_nl3, y_train_nl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20593984235300059, 'Score (R^2)': 0.08020473883587276}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0023, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_nl3, X_test_nl3, y_train_nl3, y_test_nl3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for NL is nr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.021544346900318846, 'selection': 'random'},\n",
       " 'best_score': 0.14393660997144453}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_au = au_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_au = au_dep_train\n",
    "X_test_au = au_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_au = au_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=10000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_au, y_train_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2051367498577839, 'Score (R^2)': 0.17618254898908525}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=10000, alpha=0.0215, selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_au, X_test_au, y_train_au, y_test_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy       0.065373\n",
       "sing         0.010464\n",
       "alright      0.009373\n",
       "baby         0.007071\n",
       "ring         0.006150\n",
       "apart        0.005182\n",
       "attention    0.005085\n",
       "ride         0.002789\n",
       "grab         0.002744\n",
       "perfect      0.002039\n",
       "mess         0.001921\n",
       "hate         0.001779\n",
       "road         0.001352\n",
       "forget       0.001234\n",
       "chance       0.001023\n",
       "dtype: float64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_au.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - TF-IDF + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.001, 'selection': 'random'},\n",
       " 'best_score': 0.23711511623379708}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_au2 = au_indep_train_tvec[['Energy', 'sing', 'alright', 'baby', 'ring', 'apart', 'attention', 'ride',\n",
    "                                'grab', 'perfect']]\n",
    "y_train_au2 = au_dep_train\n",
    "X_test_au2 = au_indep_test_tvec[['Energy', 'sing', 'alright', 'baby', 'ring', 'apart', 'attention', 'ride',\n",
    "                                'grab', 'perfect']]\n",
    "y_test_au2 = au_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_au2, y_train_au2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.22352020510318546, 'Score (R^2)': 0.021912696811022148}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_au2, X_test_au2, y_train_au2, y_test_au2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - TF-IDF + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.0013219411484660286, 'selection': 'random'},\n",
       " 'best_score': 0.1792556638259798}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_au3 = au_indep_train_tvec[['Energy', 'sing', 'alright']]\n",
    "y_train_au3 = au_dep_train\n",
    "X_test_au3 = au_indep_test_tvec[['Energy', 'sing', 'alright']]\n",
    "y_test_au3 = au_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_au3, y_train_au3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.221388924490036, 'Score (R^2)': 0.040476031666445644}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0013, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_au3, X_test_au3, y_train_au3, y_test_au3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for AU is nr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.016297508346206444, 'selection': 'random'},\n",
       " 'best_score': 0.15445741364318494}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_fr = fr_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_fr = fr_dep_train\n",
    "X_test_fr = fr_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_fr = fr_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg, grid, X_train_fr, y_train_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1942837162484487, 'Score (R^2)': 0.19342004396947587}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0163, selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg, X_train_fr, X_test_fr, y_train_fr, y_test_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy          0.074359\n",
       "x2              0.016805\n",
       "snow            0.009685\n",
       "baby            0.006743\n",
       "quartier        0.006072\n",
       "Acousticness    0.005724\n",
       "putain          0.003758\n",
       "bout            0.003390\n",
       "chance          0.002723\n",
       "fine            0.002249\n",
       "uh              0.001386\n",
       "rêve            0.001292\n",
       "jean            0.001150\n",
       "arrive          0.000888\n",
       "vise            0.000811\n",
       "dtype: float64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the feature importance with coef_\n",
    "pd.Series(dict(zip(X_train_fr.columns,lassoreg.coef_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do not use x2, that is from the lyrics text and only showing if something is repeating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #2 - CountVec + top 10 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.0015199110829529332, 'selection': 'cyclic'},\n",
       " 'best_score': 0.21844452593278943}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_fr2 = fr_indep_train_tvec[['Energy', 'snow', 'baby', 'quartier', 'Acousticness', 'putain', 'bout', 'chance',\n",
    "                                'fine', 'uh']]\n",
    "y_train_fr2 = fr_dep_train\n",
    "X_test_fr2 = fr_indep_test_tvec[['Energy', 'snow', 'baby', 'quartier', 'Acousticness', 'putain', 'bout', 'chance',\n",
    "                                'fine', 'uh']]\n",
    "y_test_fr2 = fr_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg2, grid, X_train_fr2, y_train_fr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1949680203703617, 'Score (R^2)': 0.1877281823095921}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg2 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.0015, \n",
    "                  selection='cyclic')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg2, X_train_fr2, X_test_fr2, y_train_fr2, y_test_fr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso #3 - TF-IDF + top 3 coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'alpha': 0.001, 'selection': 'random'},\n",
       " 'best_score': 0.1682811115321798}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_fr3 = fr_indep_train_tvec[['Energy', 'snow', 'baby']]\n",
    "y_train_fr3 = fr_dep_train\n",
    "X_test_fr3 = fr_indep_test_tvec[['Energy', 'snow', 'baby']]\n",
    "y_test_fr3 = fr_dep_test\n",
    "\n",
    "# GridSearchCV\n",
    "grid = {'alpha': np.logspace(-3, 3, 100),\n",
    "        'selection' : ('cyclic', 'random')}\n",
    "\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000)\n",
    "\n",
    "get_best_hype(lassoreg3, grid, X_train_fr3, y_train_fr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19730490998031316, 'Score (R^2)': 0.16813968331479623}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "lassoreg3 = Lasso(random_state=24, fit_intercept=True, normalize=False, max_iter=1000, alpha=0.001, \n",
    "                  selection='random')\n",
    "\n",
    "# call function\n",
    "evaluate_model(lassoreg3, X_train_fr3, X_test_fr3, y_train_fr3, y_test_fr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: Best Lasso model for FR is nr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary TF-IDF - best model/score per country**<BR />\n",
    "gb - R2 = 0.19824536945416926 (all coefs)<BR />\n",
    "it - R2 = 0.14182794084676598 (all coefs)<BR />\n",
    "us - R2 = 0.18856729273094788 (all coefs)<BR />\n",
    "de - R2 = 0.13942174669991036 (all coefs)<BR />\n",
    "ca - R2 = 0.09803228704669986 (all coefs)<BR />\n",
    "nl - R2 = 0.10295774896764186 (all coefs)<BR />\n",
    "au - R2 = 0.17618254898908525 (all coefs)<BR />\n",
    "fr - R2 = 0.19342004396947587 (all coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The score and how many varables to choose (and which ones) varies from country to country*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary over CountVec and TF-IDF**<BR />\n",
    "The best model in total for every country:<BR />\n",
    "gb - TF-IDF: R2 = 0.19824536945416926 (all coefs)<BR />\n",
    "it - CountVec: R2 = 0.14182794084676598 (all coefs)<BR />\n",
    "us - TF-IDF: R2 = 0.18856729273094788 (all coefs)<BR />\n",
    "de - CountVec: R2 = 0.1676239483701173 (top 10 coefs)<BR />\n",
    "ca - TF-IDF: R2 = 0.09803228704669986 (all coefs)<BR />\n",
    "nl - TF-IDF: R2 = 0.10295774896764186 (all coefs)<BR />\n",
    "au - CountVec: R2 = 0.19230354139175532 (top 3 coefs)<BR />\n",
    "fr - TF-IDF: R2 = 0.19342004396947587 (all coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The score and how many varables to choose (and which ones) varies from country to country. Also the choice btw TF-IDF och CountVec seem to vary.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
