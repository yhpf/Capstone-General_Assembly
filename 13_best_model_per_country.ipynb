{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model per Coutry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end I might need to do everything per country.<BR />\n",
    "And only use the stong countries (if any) to look at what mood the country and the artists are and the try to combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-bright')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Position</th>\n",
       "      <th>Streams</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>40381</td>\n",
       "      <td>Bye Bye Bye</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>4r8lRYnoOGdEi6YyI5OC1o</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>gb</td>\n",
       "      <td>eu</td>\n",
       "      <td>hey, hey bye bye bye, bye bye bye bye  i'm doi...</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.00104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.656</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>24132</td>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>2017-12-23</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>it</td>\n",
       "      <td>eu</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>49766</td>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>2017-12-24</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>it</td>\n",
       "      <td>eu</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Position  Streams                       Track Name  Artist  \\\n",
       "0           0       177    40381                      Bye Bye Bye  *NSYNC   \n",
       "1           1       151    24132  Merry Christmas, Happy Holidays  *NSYNC   \n",
       "2           2        78    49766  Merry Christmas, Happy Holidays  *NSYNC   \n",
       "\n",
       "                       ID        Date  Year  Month  Day Country Region  \\\n",
       "0  4r8lRYnoOGdEi6YyI5OC1o  2017-10-05  2017     10    5      gb     eu   \n",
       "1  15coTBAzEN1bOeipoNDZAR  2017-12-23  2017     12   23      it     eu   \n",
       "2  15coTBAzEN1bOeipoNDZAR  2017-12-24  2017     12   24      it     eu   \n",
       "\n",
       "                                              Lyrics  Acousticness  Energy  \\\n",
       "0  hey, hey bye bye bye, bye bye bye bye  i'm doi...        0.0408   0.928   \n",
       "1  merry christmas and happy holidays merry chris...        0.1030   0.939   \n",
       "2  merry christmas and happy holidays merry chris...        0.1030   0.939   \n",
       "\n",
       "   Instrumentalness  Mode    Tempo  Valence  \n",
       "0           0.00104   0.0  172.656    0.879  \n",
       "1           0.00000   1.0  105.003    0.756  \n",
       "2           0.00000   1.0  105.003    0.756  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data_top10c_more_lyrics.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at each country individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gb', 'it', 'us', 'de', 'ca', 'nl', 'au', 'fr'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter by country and make 8 new data frames\n",
    "gb_data = data[data['Country'] == 'gb']\n",
    "it_data = data[data['Country'] == 'it']\n",
    "us_data = data[data['Country'] == 'us']\n",
    "de_data = data[data['Country'] == 'de']\n",
    "ca_data = data[data['Country'] == 'ca']\n",
    "nl_data = data[data['Country'] == 'nl']\n",
    "au_data = data[data['Country'] == 'au']\n",
    "fr_data = data[data['Country'] == 'fr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix a little bit with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group by ID, sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_data_groupbyID = gb_data.groupby('ID').sum()\n",
    "it_data_groupbyID = it_data.groupby('ID').sum()\n",
    "us_data_groupbyID = us_data.groupby('ID').sum()\n",
    "de_data_groupbyID = de_data.groupby('ID').sum()\n",
    "ca_data_groupbyID = ca_data.groupby('ID').sum()\n",
    "nl_data_groupbyID = nl_data.groupby('ID').sum()\n",
    "au_data_groupbyID = au_data.groupby('ID').sum()\n",
    "fr_data_groupbyID = fr_data.groupby('ID').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make 2 new columns for average Streams and average Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_data_groupbyID['avg_Streams'] = gb_data_groupbyID['Streams']/len(gb_data)\n",
    "gb_data_groupbyID['avg_Position'] = gb_data_groupbyID['Position']/len(gb_data)\n",
    "\n",
    "it_data_groupbyID['avg_Streams'] = it_data_groupbyID['Streams']/len(it_data)\n",
    "it_data_groupbyID['avg_Position'] = it_data_groupbyID['Position']/len(it_data)\n",
    "\n",
    "us_data_groupbyID['avg_Streams'] = us_data_groupbyID['Streams']/len(us_data)\n",
    "us_data_groupbyID['avg_Position'] = us_data_groupbyID['Position']/len(us_data)\n",
    "\n",
    "de_data_groupbyID['avg_Streams'] = de_data_groupbyID['Streams']/len(de_data)\n",
    "de_data_groupbyID['avg_Position'] = de_data_groupbyID['Position']/len(de_data)\n",
    "\n",
    "ca_data_groupbyID['avg_Streams'] = ca_data_groupbyID['Streams']/len(ca_data)\n",
    "ca_data_groupbyID['avg_Position'] = ca_data_groupbyID['Position']/len(ca_data)\n",
    "\n",
    "nl_data_groupbyID['avg_Streams'] = nl_data_groupbyID['Streams']/len(nl_data)\n",
    "nl_data_groupbyID['avg_Position'] = nl_data_groupbyID['Position']/len(nl_data)\n",
    "\n",
    "au_data_groupbyID['avg_Streams'] = au_data_groupbyID['Streams']/len(au_data)\n",
    "au_data_groupbyID['avg_Position'] = au_data_groupbyID['Position']/len(au_data)\n",
    "\n",
    "fr_data_groupbyID['avg_Streams'] = fr_data_groupbyID['Streams']/len(fr_data)\n",
    "fr_data_groupbyID['avg_Position'] = fr_data_groupbyID['Position']/len(fr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_data_sp = gb_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "it_data_sp = it_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "us_data_sp = us_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "de_data_sp = de_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "ca_data_sp = ca_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "nl_data_sp = nl_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "au_data_sp = au_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "fr_data_sp = fr_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a new column for ID so that I can merge on ID later\n",
    "gb_data_sp['ID'] = gb_data_sp.index\n",
    "it_data_sp['ID'] = it_data_sp.index\n",
    "us_data_sp['ID'] = us_data_sp.index\n",
    "de_data_sp['ID'] = de_data_sp.index\n",
    "ca_data_sp['ID'] = ca_data_sp.index\n",
    "nl_data_sp['ID'] = nl_data_sp.index\n",
    "au_data_sp['ID'] = au_data_sp.index\n",
    "fr_data_sp['ID'] = fr_data_sp.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop rows that are duplicates and keep only one row for each song (based on ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_data_per_song = gb_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "it_data_per_song = it_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "us_data_per_song = us_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "de_data_per_song = de_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "ca_data_per_song = ca_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "nl_data_per_song = nl_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "au_data_per_song = au_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "fr_data_per_song = fr_data.drop_duplicates(subset=['ID'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop all columns that might change per song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_data_per_song = gb_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "it_data_per_song = it_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "us_data_per_song = us_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "de_data_per_song = de_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "ca_data_per_song = ca_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "nl_data_per_song = nl_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "au_data_per_song = au_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "fr_data_per_song = fr_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the 2 data frames with columns that may and may not change per song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_big_song = gb_data_per_song.merge(gb_data_sp, how='inner', on='ID')\n",
    "it_big_song = it_data_per_song.merge(it_data_sp, how='inner', on='ID')\n",
    "us_big_song = us_data_per_song.merge(us_data_sp, how='inner', on='ID')\n",
    "de_big_song = de_data_per_song.merge(de_data_sp, how='inner', on='ID')\n",
    "ca_big_song = ca_data_per_song.merge(ca_data_sp, how='inner', on='ID')\n",
    "nl_big_song = nl_data_per_song.merge(nl_data_sp, how='inner', on='ID')\n",
    "au_big_song = au_data_per_song.merge(au_data_sp, how='inner', on='ID')\n",
    "fr_big_song = fr_data_per_song.merge(fr_data_sp, how='inner', on='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop rows that have missing values in the Lyrics column**<BR />\n",
    "We can use dropna to drop all rows that has missing values (should mostly be the Lyrics column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_clean = gb_big_song.dropna(axis=0, how='any')\n",
    "it_clean = it_big_song.dropna(axis=0, how='any')\n",
    "us_clean = us_big_song.dropna(axis=0, how='any')\n",
    "de_clean = de_big_song.dropna(axis=0, how='any')\n",
    "ca_clean = ca_big_song.dropna(axis=0, how='any')\n",
    "nl_clean = nl_big_song.dropna(axis=0, how='any')\n",
    "au_clean = au_big_song.dropna(axis=0, how='any')\n",
    "fr_clean = fr_big_song.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Turn the lyrics in the Lyrics column into string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "gb_clean['Lyrics'] = gb_clean['Lyrics'].astype(str)\n",
    "it_clean['Lyrics'] = it_clean['Lyrics'].astype(str)\n",
    "us_clean['Lyrics'] = us_clean['Lyrics'].astype(str)\n",
    "de_clean['Lyrics'] = de_clean['Lyrics'].astype(str)\n",
    "ca_clean['Lyrics'] = ca_clean['Lyrics'].astype(str)\n",
    "nl_clean['Lyrics'] = nl_clean['Lyrics'].astype(str)\n",
    "au_clean['Lyrics'] = au_clean['Lyrics'].astype(str)\n",
    "fr_clean['Lyrics'] = fr_clean['Lyrics'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make and run function for TextBlob on the Lyrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_func(lyrics):\n",
    "    try:\n",
    "        return TextBlob(lyrics).sentiment\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "gb_clean['pol_sub'] = gb_clean['Lyrics'].apply(sentiment_func)\n",
    "it_clean['pol_sub'] = it_clean['Lyrics'].apply(sentiment_func)\n",
    "us_clean['pol_sub'] = us_clean['Lyrics'].apply(sentiment_func)\n",
    "de_clean['pol_sub'] = de_clean['Lyrics'].apply(sentiment_func)\n",
    "ca_clean['pol_sub'] = ca_clean['Lyrics'].apply(sentiment_func)\n",
    "nl_clean['pol_sub'] = nl_clean['Lyrics'].apply(sentiment_func)\n",
    "au_clean['pol_sub'] = au_clean['Lyrics'].apply(sentiment_func)\n",
    "fr_clean['pol_sub'] = fr_clean['Lyrics'].apply(sentiment_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the pol_sub column into 2 new columns (Polarity, Subjectivity)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "gb_clean['Polarity'] = gb_clean['pol_sub'].apply(lambda x: x[0])\n",
    "gb_clean['Subjectivity'] = gb_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "it_clean['Polarity'] = it_clean['pol_sub'].apply(lambda x: x[0])\n",
    "it_clean['Subjectivity'] = it_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "us_clean['Polarity'] = us_clean['pol_sub'].apply(lambda x: x[0])\n",
    "us_clean['Subjectivity'] = us_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "de_clean['Polarity'] = de_clean['pol_sub'].apply(lambda x: x[0])\n",
    "de_clean['Subjectivity'] = de_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "ca_clean['Polarity'] = ca_clean['pol_sub'].apply(lambda x: x[0])\n",
    "ca_clean['Subjectivity'] = ca_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "nl_clean['Polarity'] = nl_clean['pol_sub'].apply(lambda x: x[0])\n",
    "nl_clean['Subjectivity'] = nl_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "au_clean['Polarity'] = au_clean['pol_sub'].apply(lambda x: x[0])\n",
    "au_clean['Subjectivity'] = au_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "fr_clean['Polarity'] = fr_clean['pol_sub'].apply(lambda x: x[0])\n",
    "fr_clean['Subjectivity'] = fr_clean['pol_sub'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop the pol_sub column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_clean = gb_clean.drop(['pol_sub'], axis=1)\n",
    "it_clean = it_clean.drop(['pol_sub'], axis=1)\n",
    "us_clean = us_clean.drop(['pol_sub'], axis=1)\n",
    "de_clean = de_clean.drop(['pol_sub'], axis=1)\n",
    "ca_clean = ca_clean.drop(['pol_sub'], axis=1)\n",
    "nl_clean = nl_clean.drop(['pol_sub'], axis=1)\n",
    "au_clean = au_clean.drop(['pol_sub'], axis=1)\n",
    "fr_clean = fr_clean.drop(['pol_sub'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a quick check of the entire data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1179 entries, 0 to 2381\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1179 non-null object\n",
      "Artist              1179 non-null object\n",
      "ID                  1179 non-null object\n",
      "Lyrics              1179 non-null object\n",
      "Acousticness        1179 non-null float64\n",
      "Energy              1179 non-null float64\n",
      "Instrumentalness    1179 non-null float64\n",
      "Mode                1179 non-null float64\n",
      "Tempo               1179 non-null float64\n",
      "Valence             1179 non-null float64\n",
      "avg_Streams         1179 non-null float64\n",
      "avg_Position        1179 non-null float64\n",
      "Polarity            1179 non-null float64\n",
      "Subjectivity        1179 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 138.2+ KB\n"
     ]
    }
   ],
   "source": [
    "gb_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1058 entries, 0 to 1694\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1058 non-null object\n",
      "Artist              1058 non-null object\n",
      "ID                  1058 non-null object\n",
      "Lyrics              1058 non-null object\n",
      "Acousticness        1058 non-null float64\n",
      "Energy              1058 non-null float64\n",
      "Instrumentalness    1058 non-null float64\n",
      "Mode                1058 non-null float64\n",
      "Tempo               1058 non-null float64\n",
      "Valence             1058 non-null float64\n",
      "avg_Streams         1058 non-null float64\n",
      "avg_Position        1058 non-null float64\n",
      "Polarity            1058 non-null float64\n",
      "Subjectivity        1058 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 124.0+ KB\n"
     ]
    }
   ],
   "source": [
    "it_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1073 entries, 0 to 1934\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1073 non-null object\n",
      "Artist              1073 non-null object\n",
      "ID                  1073 non-null object\n",
      "Lyrics              1073 non-null object\n",
      "Acousticness        1073 non-null float64\n",
      "Energy              1073 non-null float64\n",
      "Instrumentalness    1073 non-null float64\n",
      "Mode                1073 non-null float64\n",
      "Tempo               1073 non-null float64\n",
      "Valence             1073 non-null float64\n",
      "avg_Streams         1073 non-null float64\n",
      "avg_Position        1073 non-null float64\n",
      "Polarity            1073 non-null float64\n",
      "Subjectivity        1073 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 125.7+ KB\n"
     ]
    }
   ],
   "source": [
    "us_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1199 entries, 0 to 1984\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1199 non-null object\n",
      "Artist              1199 non-null object\n",
      "ID                  1199 non-null object\n",
      "Lyrics              1199 non-null object\n",
      "Acousticness        1199 non-null float64\n",
      "Energy              1199 non-null float64\n",
      "Instrumentalness    1199 non-null float64\n",
      "Mode                1199 non-null float64\n",
      "Tempo               1199 non-null float64\n",
      "Valence             1199 non-null float64\n",
      "avg_Streams         1199 non-null float64\n",
      "avg_Position        1199 non-null float64\n",
      "Polarity            1199 non-null float64\n",
      "Subjectivity        1199 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 140.5+ KB\n"
     ]
    }
   ],
   "source": [
    "de_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 947 entries, 0 to 1796\n",
      "Data columns (total 14 columns):\n",
      "Track Name          947 non-null object\n",
      "Artist              947 non-null object\n",
      "ID                  947 non-null object\n",
      "Lyrics              947 non-null object\n",
      "Acousticness        947 non-null float64\n",
      "Energy              947 non-null float64\n",
      "Instrumentalness    947 non-null float64\n",
      "Mode                947 non-null float64\n",
      "Tempo               947 non-null float64\n",
      "Valence             947 non-null float64\n",
      "avg_Streams         947 non-null float64\n",
      "avg_Position        947 non-null float64\n",
      "Polarity            947 non-null float64\n",
      "Subjectivity        947 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 111.0+ KB\n"
     ]
    }
   ],
   "source": [
    "ca_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1048 entries, 0 to 2037\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1048 non-null object\n",
      "Artist              1048 non-null object\n",
      "ID                  1048 non-null object\n",
      "Lyrics              1048 non-null object\n",
      "Acousticness        1048 non-null float64\n",
      "Energy              1048 non-null float64\n",
      "Instrumentalness    1048 non-null float64\n",
      "Mode                1048 non-null float64\n",
      "Tempo               1048 non-null float64\n",
      "Valence             1048 non-null float64\n",
      "avg_Streams         1048 non-null float64\n",
      "avg_Position        1048 non-null float64\n",
      "Polarity            1048 non-null float64\n",
      "Subjectivity        1048 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 122.8+ KB\n"
     ]
    }
   ],
   "source": [
    "nl_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 757 entries, 0 to 1486\n",
      "Data columns (total 14 columns):\n",
      "Track Name          757 non-null object\n",
      "Artist              757 non-null object\n",
      "ID                  757 non-null object\n",
      "Lyrics              757 non-null object\n",
      "Acousticness        757 non-null float64\n",
      "Energy              757 non-null float64\n",
      "Instrumentalness    757 non-null float64\n",
      "Mode                757 non-null float64\n",
      "Tempo               757 non-null float64\n",
      "Valence             757 non-null float64\n",
      "avg_Streams         757 non-null float64\n",
      "avg_Position        757 non-null float64\n",
      "Polarity            757 non-null float64\n",
      "Subjectivity        757 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 88.7+ KB\n"
     ]
    }
   ],
   "source": [
    "au_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1400 entries, 1 to 1800\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1400 non-null object\n",
      "Artist              1400 non-null object\n",
      "ID                  1400 non-null object\n",
      "Lyrics              1400 non-null object\n",
      "Acousticness        1400 non-null float64\n",
      "Energy              1400 non-null float64\n",
      "Instrumentalness    1400 non-null float64\n",
      "Mode                1400 non-null float64\n",
      "Tempo               1400 non-null float64\n",
      "Valence             1400 non-null float64\n",
      "avg_Streams         1400 non-null float64\n",
      "avg_Position        1400 non-null float64\n",
      "Polarity            1400 non-null float64\n",
      "Subjectivity        1400 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 164.1+ KB\n"
     ]
    }
   ],
   "source": [
    "fr_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the data into a train and a test set (with a test set of 25%, which is also default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_dep   = gb_clean['Valence']\n",
    "gb_indep = gb_clean\n",
    "gb_indep_train, gb_indep_test, gb_dep_train, gb_dep_test = train_test_split(gb_indep, gb_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "it_dep   = it_clean['Valence']\n",
    "it_indep = it_clean\n",
    "it_indep_train, it_indep_test, it_dep_train, it_dep_test = train_test_split(it_indep, it_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "us_dep   = us_clean['Valence']\n",
    "us_indep = us_clean\n",
    "us_indep_train, us_indep_test, us_dep_train, us_dep_test = train_test_split(us_indep, us_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "de_dep   = de_clean['Valence']\n",
    "de_indep = de_clean\n",
    "de_indep_train, de_indep_test, de_dep_train, de_dep_test = train_test_split(de_indep, de_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "ca_dep   = ca_clean['Valence']\n",
    "ca_indep = ca_clean\n",
    "ca_indep_train, ca_indep_test, ca_dep_train, ca_dep_test = train_test_split(ca_indep, ca_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "nl_dep   = nl_clean['Valence']\n",
    "nl_indep = nl_clean\n",
    "nl_indep_train, nl_indep_test, nl_dep_train, nl_dep_test = train_test_split(nl_indep, nl_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "au_dep   = au_clean['Valence']\n",
    "au_indep = au_clean\n",
    "au_indep_train, au_indep_test, au_dep_train, au_dep_test = train_test_split(au_indep, au_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "fr_dep   = fr_clean['Valence']\n",
    "fr_indep = fr_clean\n",
    "fr_indep_train, fr_indep_test, fr_dep_train, fr_dep_test = train_test_split(fr_indep, fr_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in csv with stop words\n",
    "stop_words_df = pd.read_csv('./stop_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn the df to list\n",
    "stop_words = stop_words_df['colummn'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer (use in model 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "cvec = CountVectorizer(stop_words = stop_words, max_features = 1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(gb_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "gb_cvec = cvec.transform(gb_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df  = pd.DataFrame(gb_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "gb_indep_train_cvec = pd.concat([gb_indep_train.reset_index(drop=True), gb_df], axis=1)\n",
    "# transform X_test\n",
    "gb_cvec2 = cvec.transform(gb_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df2  = pd.DataFrame(gb_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "gb_indep_test_cvec = pd.concat([gb_indep_test.reset_index(drop=True), gb_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(it_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "it_cvec = cvec.transform(it_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df  = pd.DataFrame(it_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "it_indep_train_cvec = pd.concat([it_indep_train.reset_index(drop=True), it_df], axis=1)\n",
    "# transform X_test\n",
    "it_cvec2 = cvec.transform(it_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df2  = pd.DataFrame(it_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "it_indep_test_cvec = pd.concat([it_indep_test.reset_index(drop=True), it_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(us_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "us_cvec = cvec.transform(us_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df  = pd.DataFrame(us_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "us_indep_train_cvec = pd.concat([us_indep_train.reset_index(drop=True), us_df], axis=1)\n",
    "# transform X_test\n",
    "us_cvec2 = cvec.transform(us_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df2  = pd.DataFrame(us_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "us_indep_test_cvec = pd.concat([us_indep_test.reset_index(drop=True), us_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(de_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "de_cvec = cvec.transform(de_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df  = pd.DataFrame(de_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "de_indep_train_cvec = pd.concat([de_indep_train.reset_index(drop=True), de_df], axis=1)\n",
    "# transform X_test\n",
    "de_cvec2 = cvec.transform(de_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df2  = pd.DataFrame(de_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "de_indep_test_cvec = pd.concat([de_indep_test.reset_index(drop=True), de_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(ca_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "ca_cvec = cvec.transform(ca_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df  = pd.DataFrame(ca_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "ca_indep_train_cvec = pd.concat([ca_indep_train.reset_index(drop=True), ca_df], axis=1)\n",
    "# transform X_test\n",
    "ca_cvec2 = cvec.transform(ca_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df2  = pd.DataFrame(ca_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "ca_indep_test_cvec = pd.concat([ca_indep_test.reset_index(drop=True), ca_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(nl_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "nl_cvec = cvec.transform(nl_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df  = pd.DataFrame(nl_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "nl_indep_train_cvec = pd.concat([nl_indep_train.reset_index(drop=True), nl_df], axis=1)\n",
    "# transform X_test\n",
    "nl_cvec2 = cvec.transform(nl_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df2  = pd.DataFrame(nl_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "nl_indep_test_cvec = pd.concat([nl_indep_test.reset_index(drop=True), nl_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(au_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "au_cvec = cvec.transform(au_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df  = pd.DataFrame(au_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "au_indep_train_cvec = pd.concat([au_indep_train.reset_index(drop=True), au_df], axis=1)\n",
    "# transform X_test\n",
    "au_cvec2 = cvec.transform(au_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df2  = pd.DataFrame(au_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "au_indep_test_cvec = pd.concat([au_indep_test.reset_index(drop=True), au_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(fr_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "fr_cvec = cvec.transform(fr_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df  = pd.DataFrame(fr_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "fr_indep_train_cvec = pd.concat([fr_indep_train.reset_index(drop=True), fr_df], axis=1)\n",
    "# transform X_test\n",
    "fr_cvec2 = cvec.transform(fr_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df2  = pd.DataFrame(fr_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "fr_indep_test_cvec = pd.concat([fr_indep_test.reset_index(drop=True), fr_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (use in model 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "tvec = TfidfVectorizer(stop_words = stop_words, max_features = 1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(gb_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "gb_tvec = tvec.transform(gb_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df  = pd.DataFrame(gb_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "gb_indep_train_tvec = pd.concat([gb_indep_train.reset_index(drop=True), gb_df], axis=1)\n",
    "# transform X_test\n",
    "gb_tvec2 = tvec.transform(gb_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df2  = pd.DataFrame(gb_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "gb_indep_test_tvec = pd.concat([gb_indep_test.reset_index(drop=True), gb_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(it_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "it_tvec = tvec.transform(it_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df  = pd.DataFrame(it_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "it_indep_train_tvec = pd.concat([it_indep_train.reset_index(drop=True), it_df], axis=1)\n",
    "# transform X_test\n",
    "it_tvec2 = tvec.transform(it_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df2  = pd.DataFrame(it_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "it_indep_test_tvec = pd.concat([it_indep_test.reset_index(drop=True), it_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(us_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "us_tvec = tvec.transform(us_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df  = pd.DataFrame(us_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "us_indep_train_tvec = pd.concat([us_indep_train.reset_index(drop=True), us_df], axis=1)\n",
    "# transform X_test\n",
    "us_tvec2 = tvec.transform(us_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df2  = pd.DataFrame(us_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "us_indep_test_tvec = pd.concat([us_indep_test.reset_index(drop=True), us_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(de_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "de_tvec = tvec.transform(de_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df  = pd.DataFrame(de_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "de_indep_train_tvec = pd.concat([de_indep_train.reset_index(drop=True), de_df], axis=1)\n",
    "# transform X_test\n",
    "de_tvec2 = tvec.transform(de_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df2  = pd.DataFrame(de_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "de_indep_test_tvec = pd.concat([de_indep_test.reset_index(drop=True), de_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(ca_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "ca_tvec = tvec.transform(ca_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df  = pd.DataFrame(ca_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "ca_indep_train_tvec = pd.concat([ca_indep_train.reset_index(drop=True), ca_df], axis=1)\n",
    "# transform X_test\n",
    "ca_tvec2 = tvec.transform(ca_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df2  = pd.DataFrame(ca_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "ca_indep_test_tvec = pd.concat([ca_indep_test.reset_index(drop=True), ca_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(nl_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "nl_tvec = tvec.transform(nl_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df  = pd.DataFrame(nl_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "nl_indep_train_tvec = pd.concat([nl_indep_train.reset_index(drop=True), nl_df], axis=1)\n",
    "# transform X_test\n",
    "nl_tvec2 = tvec.transform(nl_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df2  = pd.DataFrame(nl_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "nl_indep_test_tvec = pd.concat([nl_indep_test.reset_index(drop=True), nl_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(au_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "au_tvec = tvec.transform(au_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df  = pd.DataFrame(au_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "au_indep_train_tvec = pd.concat([au_indep_train.reset_index(drop=True), au_df], axis=1)\n",
    "# transform X_test\n",
    "au_tvec2 = tvec.transform(au_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df2  = pd.DataFrame(au_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "au_indep_test_tvec = pd.concat([au_indep_test.reset_index(drop=True), au_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(fr_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "fr_tvec = tvec.transform(fr_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df  = pd.DataFrame(fr_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "fr_indep_train_tvec = pd.concat([fr_indep_train.reset_index(drop=True), fr_df], axis=1)\n",
    "# transform X_test\n",
    "fr_tvec2 = tvec.transform(fr_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df2  = pd.DataFrame(fr_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "fr_indep_test_tvec = pd.concat([fr_indep_test.reset_index(drop=True), fr_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models (RandomForestRegressor) - CountVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did choose RF bc that gave the best score when looking at all countries togehter.<BR />\n",
    "If the RF scores very well in one country (compared to the total score) then I might consider trying other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not have to scale a Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_hype(model, params, X_train, y_train):  \n",
    "    # Best Hyperparameters\n",
    "    rs = RandomizedSearchCV(model, params, n_iter=40)\n",
    "    \n",
    "    # fit\n",
    "    rs.fit(X_train, y_train)\n",
    "     \n",
    "    return {'best_score': rs.best_score_,'best_params': rs.best_params_} \n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # fit\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate: predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Evaluate: score\n",
    "    score = model.score(X_test, y_test)\n",
    "    \n",
    "    return {'Score (R^2)': score.mean(), 'MSE': mean_square_error}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Brittan / United Kingdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.19020506510398869}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_gb = gb_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_gb = gb_dep_train\n",
    "X_test_gb = gb_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_gb = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_gb, y_train_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2013992039140816, 'Score (R^2)': 0.31418039815233123}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_gb, X_test_gb, y_train_gb, y_test_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.159446\n",
       "Acousticness        0.054006\n",
       "baby                0.026675\n",
       "avg_Streams         0.024217\n",
       "Polarity            0.023085\n",
       "Subjectivity        0.023027\n",
       "Tempo               0.021237\n",
       "Instrumentalness    0.019196\n",
       "girl                0.017983\n",
       "avg_Position        0.016795\n",
       "oh                  0.015238\n",
       "know                0.009870\n",
       "want                0.007324\n",
       "feel                0.007096\n",
       "love                0.007065\n",
       "dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_gb.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1535427709147048}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_gb2 = gb_indep_train_cvec[['Energy', 'Acousticness', 'baby', 'avg_Streams', 'Polarity', 'Subjectivity',\n",
    "                             'Tempo','Instrumentalness' , 'girl', 'avg_Position']]\n",
    "y_train_gb2  = gb_dep_train\n",
    "X_test_gb2  = gb_indep_test_cvec[['Energy', 'Acousticness', 'baby', 'avg_Streams', 'Polarity', 'Subjectivity',\n",
    "                             'Tempo','Instrumentalness' , 'girl', 'avg_Position']]\n",
    "y_test_gb2  = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_gb2, y_train_gb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20877369771902565, 'Score (R^2)': 0.2630365296467547}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='log2', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_gb2, X_test_gb2, y_train_gb2, y_test_gb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 60,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.14933958256956442}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_gb3 = gb_indep_train_cvec[['Energy', 'Acousticness', 'baby']]\n",
    "y_train_gb3 = gb_dep_train\n",
    "X_test_gb3 = gb_indep_test_cvec[['Energy', 'Acousticness', 'baby']]\n",
    "y_test_gb3 = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_gb3, y_train_gb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2107924227574241, 'Score (R^2)': 0.24871557476627015}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='auto', n_estimators=60, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_gb3, X_test_gb3, y_train_gb3, y_test_gb3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1839444875711641}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_it = it_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_it = it_dep_train\n",
    "X_test_it = it_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_it = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_it, y_train_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19321441534566536, 'Score (R^2)': 0.15968396438438126}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=11, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_it, X_test_it, y_train_it, y_test_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.183540\n",
       "Acousticness        0.055625\n",
       "Instrumentalness    0.037431\n",
       "Subjectivity        0.020645\n",
       "Polarity            0.017126\n",
       "oh                  0.016502\n",
       "avg_Streams         0.016062\n",
       "Tempo               0.015250\n",
       "che                 0.011669\n",
       "avg_Position        0.009455\n",
       "baby                0.008548\n",
       "ya                  0.008494\n",
       "ooh                 0.008389\n",
       "know                0.008297\n",
       "don                 0.008034\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_it.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17068581415878747}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_it2 = it_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Subjectivity', 'Polarity', 'oh',\n",
    "                                 'avg_Streams','Tempo' , 'che', 'avg_Position']]\n",
    "y_train_it2  = it_dep_train\n",
    "X_test_it2  = it_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Subjectivity', 'Polarity', 'oh',\n",
    "                                 'avg_Streams','Tempo' , 'che', 'avg_Position']]\n",
    "y_test_it2  = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_it2, y_train_it2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1948679881699861, 'Score (R^2)': 0.1452391861548371}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='sqrt', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_it2, X_test_it2, y_train_it2, y_test_it2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 40,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.13532993728269863}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_it3 = it_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_it3 = it_dep_train\n",
    "X_test_it3 = it_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_it3 = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_it3, y_train_it3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2030556393611383, 'Score (R^2)': 0.071902267156844}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=40, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_it3, X_test_it3, y_train_it3, y_test_it3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.2286913154582488}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_us = us_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_us = us_dep_train\n",
    "X_test_us = us_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_us = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_us, y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17934043610996833, 'Score (R^2)': 0.3188044396985018}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_us, X_test_us, y_train_us, y_test_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.200041\n",
       "Polarity            0.032033\n",
       "Acousticness        0.025230\n",
       "Subjectivity        0.024553\n",
       "Instrumentalness    0.018849\n",
       "baby                0.018661\n",
       "Tempo               0.018083\n",
       "snow                0.015545\n",
       "avg_Streams         0.012365\n",
       "little              0.011901\n",
       "like                0.010453\n",
       "girl                0.010006\n",
       "just                0.009424\n",
       "don                 0.009200\n",
       "yeah                0.009175\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_us.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1951059584084765}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_us2 = us_indep_train_cvec[['Energy', 'Polarity', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'baby',\n",
    "                                 'Tempo', 'snow', 'avg_Streams', 'little']]\n",
    "y_train_us2  = us_dep_train\n",
    "X_test_us2  = us_indep_test_cvec[['Energy', 'Polarity', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'baby',\n",
    "                                 'Tempo', 'snow', 'avg_Streams', 'little']]\n",
    "y_test_us2  = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_us2, y_train_us2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18772479150885646, 'Score (R^2)': 0.2536223484064851}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_us2, X_test_us2, y_train_us2, y_test_us2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 20,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.14930723728526551}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_us3 = us_indep_train_cvec[['Energy', 'Polarity', 'Acousticness']]\n",
    "y_train_us3 = us_dep_train\n",
    "X_test_us3 = us_indep_test_cvec[['Energy', 'Polarity', 'Acousticness']]\n",
    "y_test_us3 = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_us3, y_train_us3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1976759241094477, 'Score (R^2)': 0.17239535171712106}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=20, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_us3, X_test_us3, y_train_us3, y_test_us3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deutchland / Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.19856787145314805}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_de = de_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_de = de_dep_train\n",
    "X_test_de = de_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_de = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_de, y_train_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18744385533497981, 'Score (R^2)': 0.19659568557898718}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_de, X_test_de, y_train_de, y_test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.160537\n",
       "avg_Streams         0.038600\n",
       "Acousticness        0.018874\n",
       "avg_Position        0.018564\n",
       "Polarity            0.017861\n",
       "baby                0.017711\n",
       "Instrumentalness    0.017665\n",
       "Tempo               0.016726\n",
       "Subjectivity        0.015403\n",
       "oh                  0.012833\n",
       "ahh                 0.009537\n",
       "yeah                0.007708\n",
       "mal                 0.006976\n",
       "bad                 0.006930\n",
       "uh                  0.006543\n",
       "dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_de.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': False,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15865264589950268}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_de2 = de_indep_train_cvec[['Energy', 'avg_Streams', 'Acousticness', 'avg_Position', 'Polarity', 'baby',\n",
    "                                 'Instrumentalness', 'Tempo', 'Subjectivity', 'oh']]\n",
    "y_train_de2  = de_dep_train\n",
    "X_test_de2  = de_indep_test_cvec[['Energy', 'avg_Streams', 'Acousticness', 'avg_Position', 'Polarity', 'baby',\n",
    "                                 'Instrumentalness', 'Tempo', 'Subjectivity', 'oh']]\n",
    "y_test_de2  = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_de2, y_train_de2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19311413014730092, 'Score (R^2)': 0.14725369224245033}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='sqrt', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_de2, X_test_de2, y_train_de2, y_test_de2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.10534728809056754}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_de3 = de_indep_train_cvec[['Energy', 'avg_Streams', 'Acousticness']]\n",
    "y_train_de3 = de_dep_train\n",
    "X_test_de3 = de_indep_test_cvec[['Energy', 'avg_Streams', 'Acousticness']]\n",
    "y_test_de3 = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_de3, y_train_de3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19804338128448137, 'Score (R^2)': 0.10316528973537387}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_de3, X_test_de3, y_train_de3, y_test_de3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 60,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1836717879679668}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_ca = ca_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_ca = ca_dep_train\n",
    "X_test_ca = ca_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_ca = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_ca, y_train_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17539422177323977, 'Score (R^2)': 0.3273411319309155}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=60, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_ca, X_test_ca, y_train_ca, y_test_ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.161828\n",
       "Acousticness        0.044747\n",
       "Polarity            0.027854\n",
       "Instrumentalness    0.025598\n",
       "baby                0.023326\n",
       "oh                  0.018591\n",
       "Subjectivity        0.018013\n",
       "Tempo               0.017380\n",
       "avg_Position        0.012527\n",
       "avg_Streams         0.012308\n",
       "don                 0.011587\n",
       "know                0.010141\n",
       "heart               0.009652\n",
       "sing                0.009469\n",
       "christmas           0.008679\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_ca.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16748059839591597}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_ca2 = ca_indep_train_cvec[['Energy', 'Acousticness', 'Polarity', 'Instrumentalness', 'baby', 'oh',\n",
    "                                 'Subjectivity','Tempo' , 'avg_Position', 'avg_Streams']]\n",
    "y_train_ca2  = ca_dep_train\n",
    "X_test_ca2  = ca_indep_test_cvec[['Energy', 'Acousticness', 'Polarity', 'Instrumentalness', 'baby', 'oh',\n",
    "                                 'Subjectivity','Tempo' , 'avg_Position', 'avg_Streams']]\n",
    "y_test_ca2  = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_ca2, y_train_ca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1828956077296433, 'Score (R^2)': 0.2685732146069939}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='log2', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_ca2, X_test_ca2, y_train_ca2, y_test_ca2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.13722775315821212}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_ca3 = ca_indep_train_cvec[['Energy', 'Acousticness', 'Polarity']]\n",
    "y_train_ca3 = ca_dep_train\n",
    "X_test_ca3 = ca_indep_test_cvec[['Energy', 'Acousticness', 'Polarity']]\n",
    "y_test_ca3 = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_ca3, y_train_ca3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19174084734295438, 'Score (R^2)': 0.1961156143878502}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_ca3, X_test_ca3, y_train_ca3, y_test_ca3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Netherlands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.20775031378829542}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_nl = nl_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_nl = nl_dep_train\n",
    "X_test_nl = nl_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_nl = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_nl, y_train_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1798516475830444, 'Score (R^2)': 0.25069816123443533}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=11, max_features='auto', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_nl, X_test_nl, y_train_nl, y_test_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.226779\n",
       "Acousticness        0.063599\n",
       "Subjectivity        0.026627\n",
       "Instrumentalness    0.022419\n",
       "Polarity            0.019567\n",
       "Tempo               0.014691\n",
       "Mode                0.013898\n",
       "avg_Streams         0.012281\n",
       "oh                  0.012142\n",
       "avg_Position        0.011023\n",
       "life                0.009054\n",
       "sing                0.008623\n",
       "want                0.008090\n",
       "baby                0.007957\n",
       "bad                 0.007915\n",
       "dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_nl.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 40,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.18287113780664324}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_nl2 = nl_indep_train_cvec[['Energy', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'Polarity', 'Tempo',\n",
    "                                 'Mode', 'avg_Streams', 'oh', 'avg_Position']]\n",
    "y_train_nl2  = nl_dep_train\n",
    "X_test_nl2  = nl_indep_test_cvec[['Energy', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'Polarity', 'Tempo',\n",
    "                                 'Mode', 'avg_Streams', 'oh', 'avg_Position']]\n",
    "y_test_nl2  = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_nl2, y_train_nl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19061783107042715, 'Score (R^2)': 0.15830450182716116}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=40, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_nl2, X_test_nl2, y_train_nl2, y_test_nl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 2,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16760762715931107}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_nl3 = nl_indep_train_cvec[['Energy', 'Acousticness', 'Subjectivity']]\n",
    "y_train_nl3 = nl_dep_train\n",
    "X_test_nl3 = nl_indep_test_cvec[['Energy', 'Acousticness', 'Subjectivity']]\n",
    "y_test_nl3 = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_nl3, y_train_nl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18835322450431446, 'Score (R^2)': 0.178184977008047}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=2, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_nl3, X_test_nl3, y_train_nl3, y_test_nl3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.23200601587974196}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_au = au_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_au = au_dep_train\n",
    "X_test_au = au_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_au = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_au, y_train_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1924933401623924, 'Score (R^2)': 0.26258288149338593}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_au, X_test_au, y_train_au, y_test_au)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.181463\n",
       "Acousticness        0.048978\n",
       "Instrumentalness    0.033361\n",
       "Tempo               0.026213\n",
       "Polarity            0.024059\n",
       "Subjectivity        0.021284\n",
       "avg_Streams         0.015795\n",
       "bad                 0.012775\n",
       "come                0.010666\n",
       "snow                0.010337\n",
       "road                0.009914\n",
       "know                0.008901\n",
       "don                 0.008735\n",
       "hey                 0.008135\n",
       "avg_Position        0.008130\n",
       "dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_au.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1856167723834672}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_au2 = au_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'Polarity', 'Subjectivity',\n",
    "                                 'avg_Streams', 'bad', 'come', 'snow']]\n",
    "y_train_au2  = au_dep_train\n",
    "X_test_au2  = au_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'Polarity', 'Subjectivity',\n",
    "                                 'avg_Streams', 'bad', 'come', 'snow']]\n",
    "y_test_au2  = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_au2, y_train_au2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2038500615876285, 'Score (R^2)': 0.17300384155218806}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='log2', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_au2, X_test_au2, y_train_au2, y_test_au2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 20,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15487743199646634}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_au3 = au_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_au3 = au_dep_train\n",
    "X_test_au3 = au_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_au3 = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_au3, y_train_au3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2052699179641228, 'Score (R^2)': 0.16144333395793364}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=20, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_au3, X_test_au3, y_train_au3, y_test_au3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 60,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.2272638383722506}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_fr = fr_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_fr = fr_dep_train\n",
    "X_test_fr = fr_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_fr = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_fr, y_train_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18788818278679834, 'Score (R^2)': 0.25917183970000157}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=60, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_fr, X_test_fr, y_train_fr, y_test_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.185094\n",
       "Acousticness        0.047401\n",
       "Instrumentalness    0.028265\n",
       "Tempo               0.024499\n",
       "Subjectivity        0.022239\n",
       "x2                  0.020529\n",
       "avg_Streams         0.018529\n",
       "Polarity            0.016456\n",
       "avg_Position        0.011927\n",
       "baby                0.007661\n",
       "je                  0.007049\n",
       "ai                  0.006760\n",
       "oh                  0.006593\n",
       "faire               0.006236\n",
       "know                0.005921\n",
       "dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_fr.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1661687601523369}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_fr2 = fr_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'Subjectivity', 'avg_Streams',\n",
    "                                 'Polarity', 'avg_Position', 'baby', 'je']]\n",
    "y_train_fr2  = fr_dep_train\n",
    "X_test_fr2  = fr_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'Subjectivity', 'avg_Streams',\n",
    "                                 'Polarity', 'avg_Position', 'baby', 'je']]\n",
    "y_test_fr2  = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_fr2, y_train_fr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19373664931011902, 'Score (R^2)': 0.21233396452492503}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=8, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_fr2, X_test_fr2, y_train_fr2, y_test_fr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16755451622431095}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_fr3 = fr_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_fr3 = fr_dep_train\n",
    "X_test_fr3 = fr_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_fr3 = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_fr3, y_train_fr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18987893063312286, 'Score (R^2)': 0.24338995186336407}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=8, max_features='log2', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_fr3, X_test_fr3, y_train_fr3, y_test_fr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models (RandomForestRegressor) - TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did choose RF bc that gave the best score when looking at all countries togehter.<BR />\n",
    "If the RF scores very well in one country (compared to the total score) then I might consider trying other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not have to scale a Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_hype(model, params, X_train, y_train):  \n",
    "    # Best Hyperparameters\n",
    "    rs = RandomizedSearchCV(model, params, n_iter=40)\n",
    "    \n",
    "    # fit\n",
    "    rs.fit(X_train, y_train)\n",
    "     \n",
    "    return {'best_score': rs.best_score_,'best_params': rs.best_params_} \n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # fit\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate: predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Evaluate: score\n",
    "    score = model.score(X_test, y_test)\n",
    "    \n",
    "    return {'Score (R^2)': score.mean(), 'MSE': mean_square_error}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Brittan / United Kingdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF_IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.18371888553485655}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_gb = gb_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_gb = gb_dep_train\n",
    "X_test_gb = gb_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_gb = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_gb, y_train_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20565677256544868, 'Score (R^2)': 0.284877526037732}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_gb, X_test_gb, y_train_gb, y_test_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.146436\n",
       "Acousticness        0.047077\n",
       "baby                0.029120\n",
       "avg_Streams         0.021062\n",
       "girl                0.020947\n",
       "Polarity            0.017266\n",
       "Subjectivity        0.017155\n",
       "Instrumentalness    0.016977\n",
       "Tempo               0.016976\n",
       "know                0.013420\n",
       "oh                  0.013051\n",
       "avg_Position        0.010982\n",
       "just                0.009942\n",
       "don                 0.009308\n",
       "cause               0.009205\n",
       "dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_gb.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF_IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 60,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16112876301968113}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_gb2 = gb_indep_train_tvec[['Energy', 'Acousticness', 'baby', 'avg_Streams', 'girl', 'Polarity',\n",
    "                                 'Subjectivity', 'Instrumentalness', 'Tempo', 'know']]\n",
    "y_train_gb2  = gb_dep_train\n",
    "X_test_gb2  = gb_indep_test_tvec[['Energy', 'Acousticness', 'baby', 'avg_Streams', 'girl', 'Polarity',\n",
    "                                 'Subjectivity', 'Instrumentalness', 'Tempo', 'know']]\n",
    "y_test_gb2  = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_gb2, y_train_gb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2066262875077516, 'Score (R^2)': 0.2781191182533066}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='log2', n_estimators=60, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_gb2, X_test_gb2, y_train_gb2, y_test_gb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF_IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 30,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.14400072731396285}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_gb3 = gb_indep_train_tvec[['Energy', 'Acousticness', 'baby']]\n",
    "y_train_gb3 = gb_dep_train\n",
    "X_test_gb3 = gb_indep_test_tvec[['Energy', 'Acousticness', 'baby']]\n",
    "y_test_gb3 = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_gb3, y_train_gb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.21673851821164267, 'Score (R^2)': 0.20573286195124063}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=30, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_gb3, X_test_gb3, y_train_gb3, y_test_gb3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15197506629570712}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_it = it_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_it = it_dep_train\n",
    "X_test_it = it_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_it = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_it, y_train_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19526084449228942, 'Score (R^2)': 0.14178929497849657}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=8, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_it, X_test_it, y_train_it, y_test_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.214291\n",
       "Acousticness        0.049394\n",
       "Instrumentalness    0.041181\n",
       "oh                  0.015222\n",
       "che                 0.014432\n",
       "pi                 0.012921\n",
       "Subjectivity        0.012343\n",
       "Polarity            0.011315\n",
       "avg_Streams         0.010018\n",
       "Tempo               0.009328\n",
       "baby                0.008921\n",
       "ooh                 0.008890\n",
       "know                0.008874\n",
       "ya                  0.008727\n",
       "avg_Position        0.008670\n",
       "dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_it.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-ID + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17660733430414619}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_it2 = it_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'oh', 'che', 'pi',\n",
    "                                 'Subjectivity', 'Polarity', 'avg_Streams', 'Tempo']]\n",
    "y_train_it2  = it_dep_train\n",
    "X_test_it2  = it_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'oh', 'che', 'pi',\n",
    "                                 'Subjectivity', 'Polarity', 'avg_Streams', 'Tempo']]\n",
    "y_test_it2  = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_it2, y_train_it2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19840961590942735, 'Score (R^2)': 0.11388715176286202}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='sqrt', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_it2, X_test_it2, y_train_it2, y_test_it2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.13569655728478214}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_it3 = it_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_it3 = it_dep_train\n",
    "X_test_it3 = it_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_it3 = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_it3, y_train_it3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20359551369342424, 'Score (R^2)': 0.0669605453992903}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_it3, X_test_it3, y_train_it3, y_test_it3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.2146681037937301}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_us = us_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_us = us_dep_train\n",
    "X_test_us = us_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_us = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_us, y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17917928013654794, 'Score (R^2)': 0.320028139296918}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_us, X_test_us, y_train_us, y_test_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.187557\n",
       "Polarity            0.023403\n",
       "baby                0.019677\n",
       "Acousticness        0.019296\n",
       "Subjectivity        0.017887\n",
       "Instrumentalness    0.015495\n",
       "like                0.013965\n",
       "Tempo               0.013591\n",
       "snow                0.013458\n",
       "girl                0.012747\n",
       "avg_Streams         0.011243\n",
       "hey                 0.010525\n",
       "say                 0.009002\n",
       "don                 0.008385\n",
       "just                0.008335\n",
       "dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_us.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.2207176480167608}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_us2 = us_indep_train_tvec[['Energy', 'Polarity', 'baby', 'Acousticness', 'Subjectivity', 'Instrumentalness',\n",
    "                                 'like', 'Tempo', 'snow', 'girl']]\n",
    "y_train_us2  = us_dep_train\n",
    "X_test_us2  = us_indep_test_tvec[['Energy', 'Polarity', 'baby', 'Acousticness', 'Subjectivity', 'Instrumentalness',\n",
    "                                 'like', 'Tempo', 'snow', 'girl']]\n",
    "y_test_us2  = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_us2, y_train_us2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18878375823938226, 'Score (R^2)': 0.24517787593084972}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='sqrt', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_us2, X_test_us2, y_train_us2, y_test_us2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16932017485114467}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_us3 = us_indep_train_tvec[['Energy', 'Polarity', 'baby']]\n",
    "y_train_us3 = us_dep_train\n",
    "X_test_us3 = us_indep_test_tvec[['Energy', 'Polarity', 'baby']]\n",
    "y_test_us3 = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_us3, y_train_us3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19990724781225308, 'Score (R^2)': 0.1536062534059779}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_us3, X_test_us3, y_train_us3, y_test_us3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deutchland / Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17188079626034436}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_de = de_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_de = de_dep_train\n",
    "X_test_de = de_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_de = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_de, y_train_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18816349770506227, 'Score (R^2)': 0.1904149159896471}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_de, X_test_de, y_train_de, y_test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.164225\n",
       "avg_Streams         0.031034\n",
       "baby                0.024554\n",
       "oh                  0.015565\n",
       "Polarity            0.014232\n",
       "avg_Position        0.012694\n",
       "Acousticness        0.012616\n",
       "Tempo               0.011084\n",
       "Subjectivity        0.010997\n",
       "Instrumentalness    0.010641\n",
       "bad                 0.009257\n",
       "just                0.007819\n",
       "eh                  0.007666\n",
       "snow                0.007599\n",
       "got                 0.006996\n",
       "dtype: float64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_de.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16119525001110976}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_de2 = de_indep_train_tvec[['Energy', 'avg_Streams', 'baby', 'oh', 'Polarity', 'avg_Position', \n",
    "                                   'Acousticness', 'Tempo', 'Subjectivity', 'Instrumentalness']]\n",
    "y_train_de2  = de_dep_train\n",
    "X_test_de2  = de_indep_test_tvec[['Energy', 'avg_Streams', 'baby', 'oh', 'Polarity', 'avg_Position', \n",
    "                                    'Acousticness', 'Tempo', 'Subjectivity', 'Instrumentalness']]\n",
    "y_test_de2  = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_de2, y_train_de2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19130740836151128, 'Score (R^2)': 0.16313516365083858}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='sqrt', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_de2, X_test_de2, y_train_de2, y_test_de2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': False,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 40,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.12095804863368141}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_de3 = de_indep_train_tvec[['Energy', 'avg_Streams', 'baby']]\n",
    "y_train_de3 = de_dep_train\n",
    "X_test_de3 = de_indep_test_tvec[['Energy', 'avg_Streams', 'baby']]\n",
    "y_test_de3 = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_de3, y_train_de3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1993637539816148, 'Score (R^2)': 0.09116687308490101}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=40, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_de3, X_test_de3, y_train_de3, y_test_de3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1875516782295987}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_ca = ca_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_ca = ca_dep_train\n",
    "X_test_ca = ca_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_ca = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_ca, y_train_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17786596487448125, 'Score (R^2)': 0.3082486524139738}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_ca, X_test_ca, y_train_ca, y_test_ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.152878\n",
       "baby                0.035818\n",
       "Acousticness        0.034272\n",
       "Instrumentalness    0.024157\n",
       "Polarity            0.019430\n",
       "Subjectivity        0.016306\n",
       "oh                  0.015656\n",
       "don                 0.014247\n",
       "Tempo               0.013239\n",
       "sing                0.011653\n",
       "heart               0.010999\n",
       "girl                0.010609\n",
       "just                0.009083\n",
       "cause               0.008718\n",
       "avg_Streams         0.008622\n",
       "dtype: float64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_ca.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1861822351861458}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_ca2 = ca_indep_train_tvec[['Energy', 'baby', 'Acousticness', 'Instrumentalness', 'Polarity', 'Subjectivity',\n",
    "                                 'oh', 'don', 'Tempo', 'sing']]\n",
    "y_train_ca2  = ca_dep_train\n",
    "X_test_ca2  = ca_indep_test_tvec[['Energy', 'baby', 'Acousticness', 'Instrumentalness', 'Polarity', 'Subjectivity',\n",
    "                                 'oh', 'don', 'Tempo', 'sing']]\n",
    "y_test_ca2  = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_ca2, y_train_ca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1859943327785615, 'Score (R^2)': 0.2435787312746738}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=8, max_features='log2', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_ca2, X_test_ca2, y_train_ca2, y_test_ca2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15350443169864744}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_ca3 = ca_indep_train_tvec[['Energy', 'baby', 'Acousticness']]\n",
    "y_train_ca3 = ca_dep_train\n",
    "X_test_ca3 = ca_indep_test_tvec[['Energy', 'baby', 'Acousticness']]\n",
    "y_test_ca3 = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_ca3, y_train_ca3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18888789114451257, 'Score (R^2)': 0.21986000281487086}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_ca3, X_test_ca3, y_train_ca3, y_test_ca3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Netherlands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.20411463579142383}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_nl = nl_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_nl = nl_dep_train\n",
    "X_test_nl = nl_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_nl = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_nl, y_train_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17963835086509775, 'Score (R^2)': 0.2524743901759854}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=11, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_nl, X_test_nl, y_train_nl, y_test_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.223327\n",
       "Acousticness        0.054516\n",
       "Subjectivity        0.022405\n",
       "Instrumentalness    0.017538\n",
       "Polarity            0.014851\n",
       "Tempo               0.013531\n",
       "avg_Streams         0.013209\n",
       "baby                0.012948\n",
       "know                0.012684\n",
       "want                0.011728\n",
       "avg_Position        0.010072\n",
       "oh                  0.009952\n",
       "Mode                0.009132\n",
       "away                0.008415\n",
       "song                0.007253\n",
       "dtype: float64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_nl.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 40,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17698124752645786}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_nl2 = nl_indep_train_tvec[['Energy', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'Polarity', 'Tempo',\n",
    "                                 'avg_Streams', 'baby', 'know', 'want']]\n",
    "y_train_nl2  = nl_dep_train\n",
    "X_test_nl2  = nl_indep_test_tvec[['Energy', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'Polarity', 'Tempo',\n",
    "                                 'avg_Streams', 'baby', 'know', 'want']]\n",
    "y_test_nl2  = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_nl2, y_train_nl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.191636510979673, 'Score (R^2)': 0.14928426115479554}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='log2', n_estimators=40, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_nl2, X_test_nl2, y_train_nl2, y_test_nl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 2,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16766138209302633}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_nl3 = nl_indep_train_tvec[['Energy', 'Acousticness', 'Subjectivity']]\n",
    "y_train_nl3 = nl_dep_train\n",
    "X_test_nl3 = nl_indep_test_tvec[['Energy', 'Acousticness', 'Subjectivity']]\n",
    "y_test_nl3 = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_nl3, y_train_nl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1885238077582708, 'Score (R^2)': 0.17669573930427385}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=2, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_nl3, X_test_nl3, y_train_nl3, y_test_nl3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.22871378573224335}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_au = au_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_au = au_dep_train\n",
    "X_test_au = au_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_au = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_au, y_train_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19131517110382987, 'Score (R^2)': 0.2715820837463585}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_au, X_test_au, y_train_au, y_test_au)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.180291\n",
       "Acousticness        0.038735\n",
       "Instrumentalness    0.031357\n",
       "Polarity            0.023082\n",
       "Tempo               0.018245\n",
       "Subjectivity        0.016056\n",
       "snow                0.015395\n",
       "hey                 0.013942\n",
       "avg_Streams         0.013238\n",
       "end                 0.012757\n",
       "road                0.012757\n",
       "bad                 0.010009\n",
       "just                0.009554\n",
       "don                 0.009469\n",
       "know                0.009189\n",
       "dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_au.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.19665454313911662}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_au2 = au_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'Polarity', 'Tempo', 'Subjectivity',\n",
    "                                 'snow', 'hey', 'avg_Streams', 'end']]\n",
    "y_train_au2  = au_dep_train\n",
    "X_test_au2  = au_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'Polarity', 'Tempo', 'Subjectivity',\n",
    "                                 'snow', 'hey', 'avg_Streams', 'end']]\n",
    "y_test_au2  = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_au2, y_train_au2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20639120554240528, 'Score (R^2)': 0.15225707541645794}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=17, max_features='sqrt', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_au2, X_test_au2, y_train_au2, y_test_au2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 2,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 10,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15353285489934612}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_au3 = au_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_au3 = au_dep_train\n",
    "X_test_au3 = au_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_au3 = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_au3, y_train_au3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20919128034745282, 'Score (R^2)': 0.12909866914319623}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=2, max_features='auto', n_estimators=10, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_au3, X_test_au3, y_train_au3, y_test_au3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.212545002755988}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_fr = fr_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_fr = fr_dep_train\n",
    "X_test_fr = fr_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_fr = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_fr, y_train_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19207918862143117, 'Score (R^2)': 0.22575363459641162}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_fr, X_test_fr, y_train_fr, y_test_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.167301\n",
       "Acousticness        0.041652\n",
       "Instrumentalness    0.027502\n",
       "Subjectivity        0.019713\n",
       "Tempo               0.016747\n",
       "x2                  0.015546\n",
       "Polarity            0.015252\n",
       "avg_Streams         0.013585\n",
       "avg_Position        0.011396\n",
       "baby                0.008699\n",
       "oh                  0.007446\n",
       "got                 0.007280\n",
       "suis                0.007017\n",
       "je                  0.006579\n",
       "qu                  0.006511\n",
       "dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_fr.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17674201382895674}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_fr2 = fr_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'Subjectivity', 'Tempo', 'Polarity',\n",
    "                                 'avg_Streams', 'avg_Position', 'baby', 'oh']]\n",
    "y_train_fr2  = fr_dep_train\n",
    "X_test_fr2  = fr_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'Subjectivity', 'Tempo', 'Polarity',\n",
    "                                 'avg_Streams', 'avg_Position', 'baby', 'oh']]\n",
    "y_test_fr2  = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_fr2, y_train_fr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1996000180024958, 'Score (R^2)': 0.1639356555487793}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_fr2, X_test_fr2, y_train_fr2, y_test_fr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': False,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15848262661970244}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_fr3 = fr_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_fr3 = fr_dep_train\n",
    "X_test_fr3 = fr_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_fr3 = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_fr3, y_train_fr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18987893063312286, 'Score (R^2)': 0.24338995186336407}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_fr3, X_test_fr3, y_train_fr3, y_test_fr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CountVec**<BR />\n",
    "GB all - 'Score (R^2)': 0.31418039815233123<BR />\n",
    "GB 10 - 'Score (R^2)': 0.2630365296467547<BR />\n",
    "GB 3 - 'Score (R^2)': 0.24871557476627015<BR />\n",
    "IT all - 'Score (R^2)': 0.15968396438438126<BR />\n",
    "IT 10 - 'Score (R^2)': 0.1452391861548371<BR />\n",
    "IT 3 - 'Score (R^2)': 0.071902267156844<BR />\n",
    "US all - 'Score (R^2)': 0.3188044396985018<BR />\n",
    "US 10  - 'Score (R^2)': 0.2536223484064851<BR />\n",
    "US 3 - 'Score (R^2)': 0.17239535171712106<BR />\n",
    "DE all - 'Score (R^2)': 0.19659568557898718<BR />\n",
    "DE 10  - 'Score (R^2)': 0.14725369224245033<BR />\n",
    "DE 3 - 'Score (R^2)': 0.10316528973537387<BR />\n",
    "CA all - 'Score (R^2)': 0.3273411319309155<BR /> \n",
    "CA 10  - 'Score (R^2)': 0.2685732146069939<BR />\n",
    "CA 3 - 'Score (R^2)': 0.1961156143878502<BR />\n",
    "NL all - 'Score (R^2)': 0.25069816123443533<BR />\n",
    "NL 10  - 'Score (R^2)': 0.15830450182716116<BR />\n",
    "NL 3 - 'Score (R^2)': 0.178184977008047<BR />\n",
    "AU all - 'Score (R^2)': 0.26258288149338593<BR />\n",
    "AU 10 - 'Score (R^2)': 0.17300384155218806<BR />\n",
    "AU 3 - 'Score (R^2)': 0.16144333395793364<BR />\n",
    "FR all - 'Score (R^2)': 0.25917183970000157<BR />\n",
    "FR 10 - 'Score (R^2)': 0.21233396452492503<BR />\n",
    "FR 3 - 'Score (R^2)': 0.24338995186336407<BR />\n",
    "\n",
    "**TF-IDF**<BR />\n",
    "GB all - 'Score (R^2)': 0.284877526037732<BR />\n",
    "GB 10 - 'Score (R^2)': 0.2781191182533066<BR />\n",
    "GB 3 - 'Score (R^2)': 0.20573286195124063<BR />\n",
    "IT all - 'Score (R^2)': 0.14178929497849657<BR />\n",
    "IT 10 - 'Score (R^2)': 0.11388715176286202<BR />\n",
    "IT 3 - 'Score (R^2)': 0.0669605453992903<BR />\n",
    "US all - 'Score (R^2)': 0.320028139296918<BR />\n",
    "US 10  - 'Score (R^2)': 0.24517787593084972<BR />\n",
    "US 3 - 'Score (R^2)': 0.1536062534059779<BR />\n",
    "DE all - 'Score (R^2)': 0.1904149159896471<BR />\n",
    "DE 10  - 'Score (R^2)': 0.16313516365083858<BR />\n",
    "DE 3 - 'Score (R^2)': 0.09116687308490101<BR />\n",
    "CA all - 'Score (R^2)': 0.3082486524139738<BR />\n",
    "CA 10  - 'Score (R^2)': 0.2435787312746738<BR />\n",
    "CA 3 - 'Score (R^2)': 0.21986000281487086<BR />\n",
    "NL all - 'Score (R^2)': 0.2524743901759854<BR />\n",
    "NL 10  - 'Score (R^2)': 0.14928426115479554<BR />\n",
    "NL 3 - 'Score (R^2)': 0.17669573930427385<BR />\n",
    "AU all - 'Score (R^2)': 0.2715820837463585<BR />\n",
    "AU 10 - 'Score (R^2)': 0.15225707541645794<BR />\n",
    "AU 3 - 'Score (R^2)': 0.12909866914319623<BR />\n",
    "FR all - 'Score (R^2)': 0.22575363459641162<BR />\n",
    "FR 10 - 'Score (R^2)': 0.1639356555487793<BR />\n",
    "FR 3 - 'Score (R^2)': 0.24338995186336407<BR />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best model per country**<BR />\n",
    "GB all CountVec - 'Score (R^2)': 0.31418039815233123<BR />\n",
    "IT all CountVec - 'Score (R^2)': 0.15968396438438126<BR />\n",
    "US all TF-IDF - 'Score (R^2)': 0.320028139296918<BR />\n",
    "DE all CountVec - 'Score (R^2)': 0.19659568557898718<BR />\n",
    "CA all CountVec - 'Score (R^2)': 0.3273411319309155<BR />\n",
    "NL all TF-IDF - 'Score (R^2)': 0.2524743901759854<BR />\n",
    "AU all TF-IDF - 'Score (R^2)': 0.2715820837463585<BR />\n",
    "FR 3 CountVec - 'Score (R^2)': 0.24338995186336407<BR />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The score and how many varables to choose (and which ones) varies from country to country. Also the choice btw TF-IDF och CountVec seem to vary.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make some plots - compairing bar chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAILCAYAAADmGpUsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111f49e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a bar chart\n",
    "character = ('Canada',\n",
    "             'US',\n",
    "             'Great Britain',\n",
    "             'Australia', \n",
    "             'Netherlands',\n",
    "             'France',\n",
    "             'Germany',\n",
    "             'Italy')\n",
    "y_pos = np.arange(8)\n",
    "type_character = [0.3273411319309155,\n",
    "                  0.320028139296918,\n",
    "                  0.31418039815233123,\n",
    "                  0.2715820837463585,\n",
    "                  0.2524743901759854,\n",
    "                  0.24338995186336407, \n",
    "                  0.19659568557898718,\n",
    "                  0.15968396438438126]    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8, 8)\n",
    "\n",
    "barlist = ax.bar(y_pos, type_character, align='center')\n",
    "barlist[0].set_color('green')\n",
    "barlist[1].set_color('gray')\n",
    "barlist[2].set_color('gray')\n",
    "barlist[3].set_color('gray')\n",
    "barlist[4].set_color('gray')\n",
    "barlist[5].set_color('gray')\n",
    "barlist[6].set_color('gray')\n",
    "barlist[7].set_color('gray')\n",
    "\n",
    "plt.xticks(y_pos, character)\n",
    "plt.xticks(rotation=45)\n",
    "#plt.xlabel('Market')\n",
    "plt.ylabel('R2-Score')\n",
    "#plt.title('In what market was the model performing the best?')\n",
    "\n",
    "plt.rc('axes', titlesize=16)     \n",
    "plt.rc('axes', labelsize=14)    \n",
    "plt.rc('xtick', labelsize=12)   \n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rc('figure', titlesize=12)  \n",
    "\n",
    "plt.grid()\n",
    "ax.grid(color='grey', linestyle='-', linewidth=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
