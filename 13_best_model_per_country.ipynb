{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model per Coutry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end I might need to do everything per country.<BR />\n",
    "And only use the stong countries (if any) to look at what mood the country and the artists are and the try to combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-bright')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Position</th>\n",
       "      <th>Streams</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>40381</td>\n",
       "      <td>Bye Bye Bye</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>4r8lRYnoOGdEi6YyI5OC1o</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>gb</td>\n",
       "      <td>eu</td>\n",
       "      <td>hey, hey bye bye bye, bye bye bye bye  i'm doi...</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.00104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.656</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>24132</td>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>2017-12-23</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>it</td>\n",
       "      <td>eu</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>49766</td>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>2017-12-24</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>it</td>\n",
       "      <td>eu</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Position  Streams                       Track Name  Artist  \\\n",
       "0           0       177    40381                      Bye Bye Bye  *NSYNC   \n",
       "1           1       151    24132  Merry Christmas, Happy Holidays  *NSYNC   \n",
       "2           2        78    49766  Merry Christmas, Happy Holidays  *NSYNC   \n",
       "\n",
       "                       ID        Date  Year  Month  Day Country Region  \\\n",
       "0  4r8lRYnoOGdEi6YyI5OC1o  2017-10-05  2017     10    5      gb     eu   \n",
       "1  15coTBAzEN1bOeipoNDZAR  2017-12-23  2017     12   23      it     eu   \n",
       "2  15coTBAzEN1bOeipoNDZAR  2017-12-24  2017     12   24      it     eu   \n",
       "\n",
       "                                              Lyrics  Acousticness  Energy  \\\n",
       "0  hey, hey bye bye bye, bye bye bye bye  i'm doi...        0.0408   0.928   \n",
       "1  merry christmas and happy holidays merry chris...        0.1030   0.939   \n",
       "2  merry christmas and happy holidays merry chris...        0.1030   0.939   \n",
       "\n",
       "   Instrumentalness  Mode    Tempo  Valence  \n",
       "0           0.00104   0.0  172.656    0.879  \n",
       "1           0.00000   1.0  105.003    0.756  \n",
       "2           0.00000   1.0  105.003    0.756  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data_top10c_more_lyrics.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at each country individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gb', 'it', 'us', 'de', 'ca', 'nl', 'au', 'fr'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter by country and make 8 new data frames\n",
    "gb_data = data[data['Country'] == 'gb']\n",
    "it_data = data[data['Country'] == 'it']\n",
    "us_data = data[data['Country'] == 'us']\n",
    "de_data = data[data['Country'] == 'de']\n",
    "ca_data = data[data['Country'] == 'ca']\n",
    "nl_data = data[data['Country'] == 'nl']\n",
    "au_data = data[data['Country'] == 'au']\n",
    "fr_data = data[data['Country'] == 'fr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix a little bit with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group by ID, sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_data_groupbyID = gb_data.groupby('ID').sum()\n",
    "it_data_groupbyID = it_data.groupby('ID').sum()\n",
    "us_data_groupbyID = us_data.groupby('ID').sum()\n",
    "de_data_groupbyID = de_data.groupby('ID').sum()\n",
    "ca_data_groupbyID = ca_data.groupby('ID').sum()\n",
    "nl_data_groupbyID = nl_data.groupby('ID').sum()\n",
    "au_data_groupbyID = au_data.groupby('ID').sum()\n",
    "fr_data_groupbyID = fr_data.groupby('ID').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make 2 new columns for average Streams and average Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_data_groupbyID['avg_Streams'] = gb_data_groupbyID['Streams']/len(gb_data)\n",
    "gb_data_groupbyID['avg_Position'] = gb_data_groupbyID['Position']/len(gb_data)\n",
    "\n",
    "it_data_groupbyID['avg_Streams'] = it_data_groupbyID['Streams']/len(it_data)\n",
    "it_data_groupbyID['avg_Position'] = it_data_groupbyID['Position']/len(it_data)\n",
    "\n",
    "us_data_groupbyID['avg_Streams'] = us_data_groupbyID['Streams']/len(us_data)\n",
    "us_data_groupbyID['avg_Position'] = us_data_groupbyID['Position']/len(us_data)\n",
    "\n",
    "de_data_groupbyID['avg_Streams'] = de_data_groupbyID['Streams']/len(de_data)\n",
    "de_data_groupbyID['avg_Position'] = de_data_groupbyID['Position']/len(de_data)\n",
    "\n",
    "ca_data_groupbyID['avg_Streams'] = ca_data_groupbyID['Streams']/len(ca_data)\n",
    "ca_data_groupbyID['avg_Position'] = ca_data_groupbyID['Position']/len(ca_data)\n",
    "\n",
    "nl_data_groupbyID['avg_Streams'] = nl_data_groupbyID['Streams']/len(nl_data)\n",
    "nl_data_groupbyID['avg_Position'] = nl_data_groupbyID['Position']/len(nl_data)\n",
    "\n",
    "au_data_groupbyID['avg_Streams'] = au_data_groupbyID['Streams']/len(au_data)\n",
    "au_data_groupbyID['avg_Position'] = au_data_groupbyID['Position']/len(au_data)\n",
    "\n",
    "fr_data_groupbyID['avg_Streams'] = fr_data_groupbyID['Streams']/len(fr_data)\n",
    "fr_data_groupbyID['avg_Position'] = fr_data_groupbyID['Position']/len(fr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_data_sp = gb_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "it_data_sp = it_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "us_data_sp = us_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "de_data_sp = de_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "ca_data_sp = ca_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "nl_data_sp = nl_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "au_data_sp = au_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "fr_data_sp = fr_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a new column for ID so that I can merge on ID later\n",
    "gb_data_sp['ID'] = gb_data_sp.index\n",
    "it_data_sp['ID'] = it_data_sp.index\n",
    "us_data_sp['ID'] = us_data_sp.index\n",
    "de_data_sp['ID'] = de_data_sp.index\n",
    "ca_data_sp['ID'] = ca_data_sp.index\n",
    "nl_data_sp['ID'] = nl_data_sp.index\n",
    "au_data_sp['ID'] = au_data_sp.index\n",
    "fr_data_sp['ID'] = fr_data_sp.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop rows that are duplicates and keep only one row for each song (based on ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_data_per_song = gb_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "it_data_per_song = it_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "us_data_per_song = us_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "de_data_per_song = de_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "ca_data_per_song = ca_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "nl_data_per_song = nl_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "au_data_per_song = au_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "fr_data_per_song = fr_data.drop_duplicates(subset=['ID'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop all columns that might change per song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_data_per_song = gb_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "it_data_per_song = it_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "us_data_per_song = us_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "de_data_per_song = de_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "ca_data_per_song = ca_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "nl_data_per_song = nl_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "au_data_per_song = au_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "fr_data_per_song = fr_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the 2 data frames with columns that may and may not change per song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_big_song = gb_data_per_song.merge(gb_data_sp, how='inner', on='ID')\n",
    "it_big_song = it_data_per_song.merge(it_data_sp, how='inner', on='ID')\n",
    "us_big_song = us_data_per_song.merge(us_data_sp, how='inner', on='ID')\n",
    "de_big_song = de_data_per_song.merge(de_data_sp, how='inner', on='ID')\n",
    "ca_big_song = ca_data_per_song.merge(ca_data_sp, how='inner', on='ID')\n",
    "nl_big_song = nl_data_per_song.merge(nl_data_sp, how='inner', on='ID')\n",
    "au_big_song = au_data_per_song.merge(au_data_sp, how='inner', on='ID')\n",
    "fr_big_song = fr_data_per_song.merge(fr_data_sp, how='inner', on='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop rows that have missing values in the Lyrics column**<BR />\n",
    "We can use dropna to drop all rows that has missing values (should mostly be the Lyrics column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_clean = gb_big_song.dropna(axis=0, how='any')\n",
    "it_clean = it_big_song.dropna(axis=0, how='any')\n",
    "us_clean = us_big_song.dropna(axis=0, how='any')\n",
    "de_clean = de_big_song.dropna(axis=0, how='any')\n",
    "ca_clean = ca_big_song.dropna(axis=0, how='any')\n",
    "nl_clean = nl_big_song.dropna(axis=0, how='any')\n",
    "au_clean = au_big_song.dropna(axis=0, how='any')\n",
    "fr_clean = fr_big_song.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Turn the lyrics in the Lyrics column into string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "gb_clean['Lyrics'] = gb_clean['Lyrics'].astype(str)\n",
    "it_clean['Lyrics'] = it_clean['Lyrics'].astype(str)\n",
    "us_clean['Lyrics'] = us_clean['Lyrics'].astype(str)\n",
    "de_clean['Lyrics'] = de_clean['Lyrics'].astype(str)\n",
    "ca_clean['Lyrics'] = ca_clean['Lyrics'].astype(str)\n",
    "nl_clean['Lyrics'] = nl_clean['Lyrics'].astype(str)\n",
    "au_clean['Lyrics'] = au_clean['Lyrics'].astype(str)\n",
    "fr_clean['Lyrics'] = fr_clean['Lyrics'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make and run function for TextBlob on the Lyrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_func(lyrics):\n",
    "    try:\n",
    "        return TextBlob(lyrics).sentiment\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "gb_clean['pol_sub'] = gb_clean['Lyrics'].apply(sentiment_func)\n",
    "it_clean['pol_sub'] = it_clean['Lyrics'].apply(sentiment_func)\n",
    "us_clean['pol_sub'] = us_clean['Lyrics'].apply(sentiment_func)\n",
    "de_clean['pol_sub'] = de_clean['Lyrics'].apply(sentiment_func)\n",
    "ca_clean['pol_sub'] = ca_clean['Lyrics'].apply(sentiment_func)\n",
    "nl_clean['pol_sub'] = nl_clean['Lyrics'].apply(sentiment_func)\n",
    "au_clean['pol_sub'] = au_clean['Lyrics'].apply(sentiment_func)\n",
    "fr_clean['pol_sub'] = fr_clean['Lyrics'].apply(sentiment_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the pol_sub column into 2 new columns (Polarity, Subjectivity)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "gb_clean['Polarity'] = gb_clean['pol_sub'].apply(lambda x: x[0])\n",
    "gb_clean['Subjectivity'] = gb_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "it_clean['Polarity'] = it_clean['pol_sub'].apply(lambda x: x[0])\n",
    "it_clean['Subjectivity'] = it_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "us_clean['Polarity'] = us_clean['pol_sub'].apply(lambda x: x[0])\n",
    "us_clean['Subjectivity'] = us_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "de_clean['Polarity'] = de_clean['pol_sub'].apply(lambda x: x[0])\n",
    "de_clean['Subjectivity'] = de_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "ca_clean['Polarity'] = ca_clean['pol_sub'].apply(lambda x: x[0])\n",
    "ca_clean['Subjectivity'] = ca_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "nl_clean['Polarity'] = nl_clean['pol_sub'].apply(lambda x: x[0])\n",
    "nl_clean['Subjectivity'] = nl_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "au_clean['Polarity'] = au_clean['pol_sub'].apply(lambda x: x[0])\n",
    "au_clean['Subjectivity'] = au_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "fr_clean['Polarity'] = fr_clean['pol_sub'].apply(lambda x: x[0])\n",
    "fr_clean['Subjectivity'] = fr_clean['pol_sub'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop the pol_sub column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_clean = gb_clean.drop(['pol_sub'], axis=1)\n",
    "it_clean = it_clean.drop(['pol_sub'], axis=1)\n",
    "us_clean = us_clean.drop(['pol_sub'], axis=1)\n",
    "de_clean = de_clean.drop(['pol_sub'], axis=1)\n",
    "ca_clean = ca_clean.drop(['pol_sub'], axis=1)\n",
    "nl_clean = nl_clean.drop(['pol_sub'], axis=1)\n",
    "au_clean = au_clean.drop(['pol_sub'], axis=1)\n",
    "fr_clean = fr_clean.drop(['pol_sub'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a quick check of the entire data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1179 entries, 0 to 2381\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1179 non-null object\n",
      "Artist              1179 non-null object\n",
      "ID                  1179 non-null object\n",
      "Lyrics              1179 non-null object\n",
      "Acousticness        1179 non-null float64\n",
      "Energy              1179 non-null float64\n",
      "Instrumentalness    1179 non-null float64\n",
      "Mode                1179 non-null float64\n",
      "Tempo               1179 non-null float64\n",
      "Valence             1179 non-null float64\n",
      "avg_Streams         1179 non-null float64\n",
      "avg_Position        1179 non-null float64\n",
      "Polarity            1179 non-null float64\n",
      "Subjectivity        1179 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 138.2+ KB\n"
     ]
    }
   ],
   "source": [
    "gb_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1058 entries, 0 to 1694\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1058 non-null object\n",
      "Artist              1058 non-null object\n",
      "ID                  1058 non-null object\n",
      "Lyrics              1058 non-null object\n",
      "Acousticness        1058 non-null float64\n",
      "Energy              1058 non-null float64\n",
      "Instrumentalness    1058 non-null float64\n",
      "Mode                1058 non-null float64\n",
      "Tempo               1058 non-null float64\n",
      "Valence             1058 non-null float64\n",
      "avg_Streams         1058 non-null float64\n",
      "avg_Position        1058 non-null float64\n",
      "Polarity            1058 non-null float64\n",
      "Subjectivity        1058 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 124.0+ KB\n"
     ]
    }
   ],
   "source": [
    "it_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1073 entries, 0 to 1934\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1073 non-null object\n",
      "Artist              1073 non-null object\n",
      "ID                  1073 non-null object\n",
      "Lyrics              1073 non-null object\n",
      "Acousticness        1073 non-null float64\n",
      "Energy              1073 non-null float64\n",
      "Instrumentalness    1073 non-null float64\n",
      "Mode                1073 non-null float64\n",
      "Tempo               1073 non-null float64\n",
      "Valence             1073 non-null float64\n",
      "avg_Streams         1073 non-null float64\n",
      "avg_Position        1073 non-null float64\n",
      "Polarity            1073 non-null float64\n",
      "Subjectivity        1073 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 125.7+ KB\n"
     ]
    }
   ],
   "source": [
    "us_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1199 entries, 0 to 1984\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1199 non-null object\n",
      "Artist              1199 non-null object\n",
      "ID                  1199 non-null object\n",
      "Lyrics              1199 non-null object\n",
      "Acousticness        1199 non-null float64\n",
      "Energy              1199 non-null float64\n",
      "Instrumentalness    1199 non-null float64\n",
      "Mode                1199 non-null float64\n",
      "Tempo               1199 non-null float64\n",
      "Valence             1199 non-null float64\n",
      "avg_Streams         1199 non-null float64\n",
      "avg_Position        1199 non-null float64\n",
      "Polarity            1199 non-null float64\n",
      "Subjectivity        1199 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 140.5+ KB\n"
     ]
    }
   ],
   "source": [
    "de_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 947 entries, 0 to 1796\n",
      "Data columns (total 14 columns):\n",
      "Track Name          947 non-null object\n",
      "Artist              947 non-null object\n",
      "ID                  947 non-null object\n",
      "Lyrics              947 non-null object\n",
      "Acousticness        947 non-null float64\n",
      "Energy              947 non-null float64\n",
      "Instrumentalness    947 non-null float64\n",
      "Mode                947 non-null float64\n",
      "Tempo               947 non-null float64\n",
      "Valence             947 non-null float64\n",
      "avg_Streams         947 non-null float64\n",
      "avg_Position        947 non-null float64\n",
      "Polarity            947 non-null float64\n",
      "Subjectivity        947 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 111.0+ KB\n"
     ]
    }
   ],
   "source": [
    "ca_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1048 entries, 0 to 2037\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1048 non-null object\n",
      "Artist              1048 non-null object\n",
      "ID                  1048 non-null object\n",
      "Lyrics              1048 non-null object\n",
      "Acousticness        1048 non-null float64\n",
      "Energy              1048 non-null float64\n",
      "Instrumentalness    1048 non-null float64\n",
      "Mode                1048 non-null float64\n",
      "Tempo               1048 non-null float64\n",
      "Valence             1048 non-null float64\n",
      "avg_Streams         1048 non-null float64\n",
      "avg_Position        1048 non-null float64\n",
      "Polarity            1048 non-null float64\n",
      "Subjectivity        1048 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 122.8+ KB\n"
     ]
    }
   ],
   "source": [
    "nl_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 757 entries, 0 to 1486\n",
      "Data columns (total 14 columns):\n",
      "Track Name          757 non-null object\n",
      "Artist              757 non-null object\n",
      "ID                  757 non-null object\n",
      "Lyrics              757 non-null object\n",
      "Acousticness        757 non-null float64\n",
      "Energy              757 non-null float64\n",
      "Instrumentalness    757 non-null float64\n",
      "Mode                757 non-null float64\n",
      "Tempo               757 non-null float64\n",
      "Valence             757 non-null float64\n",
      "avg_Streams         757 non-null float64\n",
      "avg_Position        757 non-null float64\n",
      "Polarity            757 non-null float64\n",
      "Subjectivity        757 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 88.7+ KB\n"
     ]
    }
   ],
   "source": [
    "au_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1400 entries, 1 to 1800\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1400 non-null object\n",
      "Artist              1400 non-null object\n",
      "ID                  1400 non-null object\n",
      "Lyrics              1400 non-null object\n",
      "Acousticness        1400 non-null float64\n",
      "Energy              1400 non-null float64\n",
      "Instrumentalness    1400 non-null float64\n",
      "Mode                1400 non-null float64\n",
      "Tempo               1400 non-null float64\n",
      "Valence             1400 non-null float64\n",
      "avg_Streams         1400 non-null float64\n",
      "avg_Position        1400 non-null float64\n",
      "Polarity            1400 non-null float64\n",
      "Subjectivity        1400 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 164.1+ KB\n"
     ]
    }
   ],
   "source": [
    "fr_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the data into a train and a test set (with a test set of 25%, which is also default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_dep   = gb_clean['Valence']\n",
    "gb_indep = gb_clean\n",
    "gb_indep_train, gb_indep_test, gb_dep_train, gb_dep_test = train_test_split(gb_indep, gb_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "it_dep   = it_clean['Valence']\n",
    "it_indep = it_clean\n",
    "it_indep_train, it_indep_test, it_dep_train, it_dep_test = train_test_split(it_indep, it_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "us_dep   = us_clean['Valence']\n",
    "us_indep = us_clean\n",
    "us_indep_train, us_indep_test, us_dep_train, us_dep_test = train_test_split(us_indep, us_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "de_dep   = de_clean['Valence']\n",
    "de_indep = de_clean\n",
    "de_indep_train, de_indep_test, de_dep_train, de_dep_test = train_test_split(de_indep, de_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "ca_dep   = ca_clean['Valence']\n",
    "ca_indep = ca_clean\n",
    "ca_indep_train, ca_indep_test, ca_dep_train, ca_dep_test = train_test_split(ca_indep, ca_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "nl_dep   = nl_clean['Valence']\n",
    "nl_indep = nl_clean\n",
    "nl_indep_train, nl_indep_test, nl_dep_train, nl_dep_test = train_test_split(nl_indep, nl_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "au_dep   = au_clean['Valence']\n",
    "au_indep = au_clean\n",
    "au_indep_train, au_indep_test, au_dep_train, au_dep_test = train_test_split(au_indep, au_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "fr_dep   = fr_clean['Valence']\n",
    "fr_indep = fr_clean\n",
    "fr_indep_train, fr_indep_test, fr_dep_train, fr_dep_test = train_test_split(fr_indep, fr_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in csv with stop words\n",
    "stop_words_df = pd.read_csv('./stop_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn the df to list\n",
    "stop_words = stop_words_df['colummn'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer (use in model 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "cvec = CountVectorizer(stop_words = stop_words, max_features = 1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(gb_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "gb_cvec = cvec.transform(gb_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df  = pd.DataFrame(gb_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "gb_indep_train_cvec = pd.concat([gb_indep_train.reset_index(drop=True), gb_df], axis=1)\n",
    "# transform X_test\n",
    "gb_cvec2 = cvec.transform(gb_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df2  = pd.DataFrame(gb_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "gb_indep_test_cvec = pd.concat([gb_indep_test.reset_index(drop=True), gb_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(it_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "it_cvec = cvec.transform(it_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df  = pd.DataFrame(it_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "it_indep_train_cvec = pd.concat([it_indep_train.reset_index(drop=True), it_df], axis=1)\n",
    "# transform X_test\n",
    "it_cvec2 = cvec.transform(it_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df2  = pd.DataFrame(it_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "it_indep_test_cvec = pd.concat([it_indep_test.reset_index(drop=True), it_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(us_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "us_cvec = cvec.transform(us_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df  = pd.DataFrame(us_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "us_indep_train_cvec = pd.concat([us_indep_train.reset_index(drop=True), us_df], axis=1)\n",
    "# transform X_test\n",
    "us_cvec2 = cvec.transform(us_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df2  = pd.DataFrame(us_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "us_indep_test_cvec = pd.concat([us_indep_test.reset_index(drop=True), us_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(de_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "de_cvec = cvec.transform(de_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df  = pd.DataFrame(de_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "de_indep_train_cvec = pd.concat([de_indep_train.reset_index(drop=True), de_df], axis=1)\n",
    "# transform X_test\n",
    "de_cvec2 = cvec.transform(de_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df2  = pd.DataFrame(de_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "de_indep_test_cvec = pd.concat([de_indep_test.reset_index(drop=True), de_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(ca_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "ca_cvec = cvec.transform(ca_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df  = pd.DataFrame(ca_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "ca_indep_train_cvec = pd.concat([ca_indep_train.reset_index(drop=True), ca_df], axis=1)\n",
    "# transform X_test\n",
    "ca_cvec2 = cvec.transform(ca_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df2  = pd.DataFrame(ca_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "ca_indep_test_cvec = pd.concat([ca_indep_test.reset_index(drop=True), ca_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(nl_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "nl_cvec = cvec.transform(nl_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df  = pd.DataFrame(nl_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "nl_indep_train_cvec = pd.concat([nl_indep_train.reset_index(drop=True), nl_df], axis=1)\n",
    "# transform X_test\n",
    "nl_cvec2 = cvec.transform(nl_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df2  = pd.DataFrame(nl_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "nl_indep_test_cvec = pd.concat([nl_indep_test.reset_index(drop=True), nl_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(au_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "au_cvec = cvec.transform(au_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df  = pd.DataFrame(au_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "au_indep_train_cvec = pd.concat([au_indep_train.reset_index(drop=True), au_df], axis=1)\n",
    "# transform X_test\n",
    "au_cvec2 = cvec.transform(au_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df2  = pd.DataFrame(au_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "au_indep_test_cvec = pd.concat([au_indep_test.reset_index(drop=True), au_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(fr_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "fr_cvec = cvec.transform(fr_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df  = pd.DataFrame(fr_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "fr_indep_train_cvec = pd.concat([fr_indep_train.reset_index(drop=True), fr_df], axis=1)\n",
    "# transform X_test\n",
    "fr_cvec2 = cvec.transform(fr_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df2  = pd.DataFrame(fr_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "fr_indep_test_cvec = pd.concat([fr_indep_test.reset_index(drop=True), fr_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (use in model 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "tvec = TfidfVectorizer(stop_words = stop_words, max_features = 1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(gb_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "gb_tvec = tvec.transform(gb_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df  = pd.DataFrame(gb_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "gb_indep_train_tvec = pd.concat([gb_indep_train.reset_index(drop=True), gb_df], axis=1)\n",
    "# transform X_test\n",
    "gb_tvec2 = tvec.transform(gb_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df2  = pd.DataFrame(gb_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "gb_indep_test_tvec = pd.concat([gb_indep_test.reset_index(drop=True), gb_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(it_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "it_tvec = tvec.transform(it_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df  = pd.DataFrame(it_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "it_indep_train_tvec = pd.concat([it_indep_train.reset_index(drop=True), it_df], axis=1)\n",
    "# transform X_test\n",
    "it_tvec2 = tvec.transform(it_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df2  = pd.DataFrame(it_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "it_indep_test_tvec = pd.concat([it_indep_test.reset_index(drop=True), it_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(us_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "us_tvec = tvec.transform(us_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df  = pd.DataFrame(us_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "us_indep_train_tvec = pd.concat([us_indep_train.reset_index(drop=True), us_df], axis=1)\n",
    "# transform X_test\n",
    "us_tvec2 = tvec.transform(us_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df2  = pd.DataFrame(us_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "us_indep_test_tvec = pd.concat([us_indep_test.reset_index(drop=True), us_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(de_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "de_tvec = tvec.transform(de_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df  = pd.DataFrame(de_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "de_indep_train_tvec = pd.concat([de_indep_train.reset_index(drop=True), de_df], axis=1)\n",
    "# transform X_test\n",
    "de_tvec2 = tvec.transform(de_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df2  = pd.DataFrame(de_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "de_indep_test_tvec = pd.concat([de_indep_test.reset_index(drop=True), de_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(ca_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "ca_tvec = tvec.transform(ca_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df  = pd.DataFrame(ca_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "ca_indep_train_tvec = pd.concat([ca_indep_train.reset_index(drop=True), ca_df], axis=1)\n",
    "# transform X_test\n",
    "ca_tvec2 = tvec.transform(ca_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df2  = pd.DataFrame(ca_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "ca_indep_test_tvec = pd.concat([ca_indep_test.reset_index(drop=True), ca_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(nl_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "nl_tvec = tvec.transform(nl_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df  = pd.DataFrame(nl_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "nl_indep_train_tvec = pd.concat([nl_indep_train.reset_index(drop=True), nl_df], axis=1)\n",
    "# transform X_test\n",
    "nl_tvec2 = tvec.transform(nl_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df2  = pd.DataFrame(nl_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "nl_indep_test_tvec = pd.concat([nl_indep_test.reset_index(drop=True), nl_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(au_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "au_tvec = tvec.transform(au_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df  = pd.DataFrame(au_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "au_indep_train_tvec = pd.concat([au_indep_train.reset_index(drop=True), au_df], axis=1)\n",
    "# transform X_test\n",
    "au_tvec2 = tvec.transform(au_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df2  = pd.DataFrame(au_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "au_indep_test_tvec = pd.concat([au_indep_test.reset_index(drop=True), au_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(fr_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "fr_tvec = tvec.transform(fr_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df  = pd.DataFrame(fr_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "fr_indep_train_tvec = pd.concat([fr_indep_train.reset_index(drop=True), fr_df], axis=1)\n",
    "# transform X_test\n",
    "fr_tvec2 = tvec.transform(fr_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df2  = pd.DataFrame(fr_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "fr_indep_test_tvec = pd.concat([fr_indep_test.reset_index(drop=True), fr_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models (RandomForestRegressor) - CountVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did choose RF bc that gave the best score when looking at all countries togehter.<BR />\n",
    "If the RF scores very well in one country (compared to the total score) then I might consider trying other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not have to scale a Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_hype(model, params, X_train, y_train):  \n",
    "    # Best Hyperparameters\n",
    "    rs = RandomizedSearchCV(model, params, n_iter=40)\n",
    "    \n",
    "    # fit\n",
    "    rs.fit(X_train, y_train)\n",
    "     \n",
    "    return {'best_score': rs.best_score_,'best_params': rs.best_params_} \n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # fit\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate: predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Evaluate: score\n",
    "    score = model.score(X_test, y_test)\n",
    "    \n",
    "    return {'Score (R^2)': score.mean(), 'MSE': mean_square_error}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Brittan / United Kingdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.19020506510398869}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_gb = gb_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_gb = gb_dep_train\n",
    "X_test_gb = gb_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_gb = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_gb, y_train_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2013992039140816, 'Score (R^2)': 0.31418039815233123}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_gb, X_test_gb, y_train_gb, y_test_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.159446\n",
       "Acousticness        0.054006\n",
       "baby                0.026675\n",
       "avg_Streams         0.024217\n",
       "Polarity            0.023085\n",
       "Subjectivity        0.023027\n",
       "Tempo               0.021237\n",
       "Instrumentalness    0.019196\n",
       "girl                0.017983\n",
       "avg_Position        0.016795\n",
       "oh                  0.015238\n",
       "know                0.009870\n",
       "want                0.007324\n",
       "feel                0.007096\n",
       "love                0.007065\n",
       "dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_gb.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1535427709147048}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_gb2 = gb_indep_train_cvec[['Energy', 'Acousticness', 'baby', 'avg_Streams', 'Polarity', 'Subjectivity',\n",
    "                             'Tempo','Instrumentalness' , 'girl', 'avg_Position']]\n",
    "y_train_gb2  = gb_dep_train\n",
    "X_test_gb2  = gb_indep_test_cvec[['Energy', 'Acousticness', 'baby', 'avg_Streams', 'Polarity', 'Subjectivity',\n",
    "                             'Tempo','Instrumentalness' , 'girl', 'avg_Position']]\n",
    "y_test_gb2  = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_gb2, y_train_gb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20877369771902565, 'Score (R^2)': 0.2630365296467547}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='log2', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_gb2, X_test_gb2, y_train_gb2, y_test_gb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 60,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.14933958256956442}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_gb3 = gb_indep_train_cvec[['Energy', 'Acousticness', 'baby']]\n",
    "y_train_gb3 = gb_dep_train\n",
    "X_test_gb3 = gb_indep_test_cvec[['Energy', 'Acousticness', 'baby']]\n",
    "y_test_gb3 = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_gb3, y_train_gb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2107924227574241, 'Score (R^2)': 0.24871557476627015}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='auto', n_estimators=60, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_gb3, X_test_gb3, y_train_gb3, y_test_gb3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1839444875711641}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_it = it_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_it = it_dep_train\n",
    "X_test_it = it_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_it = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_it, y_train_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19321441534566536, 'Score (R^2)': 0.15968396438438126}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=11, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_it, X_test_it, y_train_it, y_test_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.183540\n",
       "Acousticness        0.055625\n",
       "Instrumentalness    0.037431\n",
       "Subjectivity        0.020645\n",
       "Polarity            0.017126\n",
       "oh                  0.016502\n",
       "avg_Streams         0.016062\n",
       "Tempo               0.015250\n",
       "che                 0.011669\n",
       "avg_Position        0.009455\n",
       "baby                0.008548\n",
       "ya                  0.008494\n",
       "ooh                 0.008389\n",
       "know                0.008297\n",
       "don                 0.008034\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_it.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17068581415878747}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_it2 = it_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Subjectivity', 'Polarity', 'oh',\n",
    "                                 'avg_Streams','Tempo' , 'che', 'avg_Position']]\n",
    "y_train_it2  = it_dep_train\n",
    "X_test_it2  = it_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Subjectivity', 'Polarity', 'oh',\n",
    "                                 'avg_Streams','Tempo' , 'che', 'avg_Position']]\n",
    "y_test_it2  = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_it2, y_train_it2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1948679881699861, 'Score (R^2)': 0.1452391861548371}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='sqrt', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_it2, X_test_it2, y_train_it2, y_test_it2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 40,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.13532993728269863}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_it3 = it_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_it3 = it_dep_train\n",
    "X_test_it3 = it_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_it3 = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_it3, y_train_it3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2030556393611383, 'Score (R^2)': 0.071902267156844}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=40, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_it3, X_test_it3, y_train_it3, y_test_it3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.2286913154582488}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_us = us_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_us = us_dep_train\n",
    "X_test_us = us_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_us = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_us, y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17934043610996833, 'Score (R^2)': 0.3188044396985018}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_us, X_test_us, y_train_us, y_test_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.200041\n",
       "Polarity            0.032033\n",
       "Acousticness        0.025230\n",
       "Subjectivity        0.024553\n",
       "Instrumentalness    0.018849\n",
       "baby                0.018661\n",
       "Tempo               0.018083\n",
       "snow                0.015545\n",
       "avg_Streams         0.012365\n",
       "little              0.011901\n",
       "like                0.010453\n",
       "girl                0.010006\n",
       "just                0.009424\n",
       "don                 0.009200\n",
       "yeah                0.009175\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_us.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1951059584084765}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_us2 = us_indep_train_cvec[['Energy', 'Polarity', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'baby',\n",
    "                                 'Tempo', 'snow', 'avg_Streams', 'little']]\n",
    "y_train_us2  = us_dep_train\n",
    "X_test_us2  = us_indep_test_cvec[['Energy', 'Polarity', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'baby',\n",
    "                                 'Tempo', 'snow', 'avg_Streams', 'little']]\n",
    "y_test_us2  = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_us2, y_train_us2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18772479150885646, 'Score (R^2)': 0.2536223484064851}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_us2, X_test_us2, y_train_us2, y_test_us2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 20,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.14930723728526551}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_us3 = us_indep_train_cvec[['Energy', 'Polarity', 'Acousticness']]\n",
    "y_train_us3 = us_dep_train\n",
    "X_test_us3 = us_indep_test_cvec[['Energy', 'Polarity', 'Acousticness']]\n",
    "y_test_us3 = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_us3, y_train_us3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1976759241094477, 'Score (R^2)': 0.17239535171712106}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=20, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_us3, X_test_us3, y_train_us3, y_test_us3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deutchland / Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.19856787145314805}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_de = de_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_de = de_dep_train\n",
    "X_test_de = de_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_de = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_de, y_train_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18744385533497981, 'Score (R^2)': 0.19659568557898718}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_de, X_test_de, y_train_de, y_test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.160537\n",
       "avg_Streams         0.038600\n",
       "Acousticness        0.018874\n",
       "avg_Position        0.018564\n",
       "Polarity            0.017861\n",
       "baby                0.017711\n",
       "Instrumentalness    0.017665\n",
       "Tempo               0.016726\n",
       "Subjectivity        0.015403\n",
       "oh                  0.012833\n",
       "ahh                 0.009537\n",
       "yeah                0.007708\n",
       "mal                 0.006976\n",
       "bad                 0.006930\n",
       "uh                  0.006543\n",
       "dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_de.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': False,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15865264589950268}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_de2 = de_indep_train_cvec[['Energy', 'avg_Streams', 'Acousticness', 'avg_Position', 'Polarity', 'baby',\n",
    "                                 'Instrumentalness', 'Tempo', 'Subjectivity', 'oh']]\n",
    "y_train_de2  = de_dep_train\n",
    "X_test_de2  = de_indep_test_cvec[['Energy', 'avg_Streams', 'Acousticness', 'avg_Position', 'Polarity', 'baby',\n",
    "                                 'Instrumentalness', 'Tempo', 'Subjectivity', 'oh']]\n",
    "y_test_de2  = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_de2, y_train_de2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19311413014730092, 'Score (R^2)': 0.14725369224245033}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='sqrt', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_de2, X_test_de2, y_train_de2, y_test_de2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.10534728809056754}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_de3 = de_indep_train_cvec[['Energy', 'avg_Streams', 'Acousticness']]\n",
    "y_train_de3 = de_dep_train\n",
    "X_test_de3 = de_indep_test_cvec[['Energy', 'avg_Streams', 'Acousticness']]\n",
    "y_test_de3 = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_de3, y_train_de3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19804338128448137, 'Score (R^2)': 0.10316528973537387}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_de3, X_test_de3, y_train_de3, y_test_de3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 60,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1836717879679668}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_ca = ca_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_ca = ca_dep_train\n",
    "X_test_ca = ca_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_ca = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_ca, y_train_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17539422177323977, 'Score (R^2)': 0.3273411319309155}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=60, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_ca, X_test_ca, y_train_ca, y_test_ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.161828\n",
       "Acousticness        0.044747\n",
       "Polarity            0.027854\n",
       "Instrumentalness    0.025598\n",
       "baby                0.023326\n",
       "oh                  0.018591\n",
       "Subjectivity        0.018013\n",
       "Tempo               0.017380\n",
       "avg_Position        0.012527\n",
       "avg_Streams         0.012308\n",
       "don                 0.011587\n",
       "know                0.010141\n",
       "heart               0.009652\n",
       "sing                0.009469\n",
       "christmas           0.008679\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_ca.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16748059839591597}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_ca2 = ca_indep_train_cvec[['Energy', 'Acousticness', 'Polarity', 'Instrumentalness', 'baby', 'oh',\n",
    "                                 'Subjectivity','Tempo' , 'avg_Position', 'avg_Streams']]\n",
    "y_train_ca2  = ca_dep_train\n",
    "X_test_ca2  = ca_indep_test_cvec[['Energy', 'Acousticness', 'Polarity', 'Instrumentalness', 'baby', 'oh',\n",
    "                                 'Subjectivity','Tempo' , 'avg_Position', 'avg_Streams']]\n",
    "y_test_ca2  = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_ca2, y_train_ca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1828956077296433, 'Score (R^2)': 0.2685732146069939}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='log2', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_ca2, X_test_ca2, y_train_ca2, y_test_ca2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.13722775315821212}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_ca3 = ca_indep_train_cvec[['Energy', 'Acousticness', 'Polarity']]\n",
    "y_train_ca3 = ca_dep_train\n",
    "X_test_ca3 = ca_indep_test_cvec[['Energy', 'Acousticness', 'Polarity']]\n",
    "y_test_ca3 = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_ca3, y_train_ca3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19174084734295438, 'Score (R^2)': 0.1961156143878502}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_ca3, X_test_ca3, y_train_ca3, y_test_ca3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Netherlands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.20775031378829542}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_nl = nl_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_nl = nl_dep_train\n",
    "X_test_nl = nl_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_nl = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_nl, y_train_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1798516475830444, 'Score (R^2)': 0.25069816123443533}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=11, max_features='auto', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_nl, X_test_nl, y_train_nl, y_test_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.226779\n",
       "Acousticness        0.063599\n",
       "Subjectivity        0.026627\n",
       "Instrumentalness    0.022419\n",
       "Polarity            0.019567\n",
       "Tempo               0.014691\n",
       "Mode                0.013898\n",
       "avg_Streams         0.012281\n",
       "oh                  0.012142\n",
       "avg_Position        0.011023\n",
       "life                0.009054\n",
       "sing                0.008623\n",
       "want                0.008090\n",
       "baby                0.007957\n",
       "bad                 0.007915\n",
       "dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_nl.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 40,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.18287113780664324}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_nl2 = nl_indep_train_cvec[['Energy', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'Polarity', 'Tempo',\n",
    "                                 'Mode', 'avg_Streams', 'oh', 'avg_Position']]\n",
    "y_train_nl2  = nl_dep_train\n",
    "X_test_nl2  = nl_indep_test_cvec[['Energy', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'Polarity', 'Tempo',\n",
    "                                 'Mode', 'avg_Streams', 'oh', 'avg_Position']]\n",
    "y_test_nl2  = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_nl2, y_train_nl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19061783107042715, 'Score (R^2)': 0.15830450182716116}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=40, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_nl2, X_test_nl2, y_train_nl2, y_test_nl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 2,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16760762715931107}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_nl3 = nl_indep_train_cvec[['Energy', 'Acousticness', 'Subjectivity']]\n",
    "y_train_nl3 = nl_dep_train\n",
    "X_test_nl3 = nl_indep_test_cvec[['Energy', 'Acousticness', 'Subjectivity']]\n",
    "y_test_nl3 = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_nl3, y_train_nl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18835322450431446, 'Score (R^2)': 0.178184977008047}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=2, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_nl3, X_test_nl3, y_train_nl3, y_test_nl3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.23200601587974196}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_au = au_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_au = au_dep_train\n",
    "X_test_au = au_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_au = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_au, y_train_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1924933401623924, 'Score (R^2)': 0.26258288149338593}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_au, X_test_au, y_train_au, y_test_au)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.181463\n",
       "Acousticness        0.048978\n",
       "Instrumentalness    0.033361\n",
       "Tempo               0.026213\n",
       "Polarity            0.024059\n",
       "Subjectivity        0.021284\n",
       "avg_Streams         0.015795\n",
       "bad                 0.012775\n",
       "come                0.010666\n",
       "snow                0.010337\n",
       "road                0.009914\n",
       "know                0.008901\n",
       "don                 0.008735\n",
       "hey                 0.008135\n",
       "avg_Position        0.008130\n",
       "dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_au.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1856167723834672}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_au2 = au_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'Polarity', 'Subjectivity',\n",
    "                                 'avg_Streams', 'bad', 'come', 'snow']]\n",
    "y_train_au2  = au_dep_train\n",
    "X_test_au2  = au_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'Polarity', 'Subjectivity',\n",
    "                                 'avg_Streams', 'bad', 'come', 'snow']]\n",
    "y_test_au2  = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_au2, y_train_au2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2038500615876285, 'Score (R^2)': 0.17300384155218806}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='log2', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_au2, X_test_au2, y_train_au2, y_test_au2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 20,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15487743199646634}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_au3 = au_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_au3 = au_dep_train\n",
    "X_test_au3 = au_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_au3 = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_au3, y_train_au3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2052699179641228, 'Score (R^2)': 0.16144333395793364}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=20, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_au3, X_test_au3, y_train_au3, y_test_au3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 60,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.2272638383722506}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_fr = fr_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_fr = fr_dep_train\n",
    "X_test_fr = fr_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_fr = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_fr, y_train_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18788818278679834, 'Score (R^2)': 0.25917183970000157}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=60, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_fr, X_test_fr, y_train_fr, y_test_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.185094\n",
       "Acousticness        0.047401\n",
       "Instrumentalness    0.028265\n",
       "Tempo               0.024499\n",
       "Subjectivity        0.022239\n",
       "x2                  0.020529\n",
       "avg_Streams         0.018529\n",
       "Polarity            0.016456\n",
       "avg_Position        0.011927\n",
       "baby                0.007661\n",
       "je                  0.007049\n",
       "ai                  0.006760\n",
       "oh                  0.006593\n",
       "faire               0.006236\n",
       "know                0.005921\n",
       "dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_fr.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1661687601523369}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_fr2 = fr_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'Subjectivity', 'avg_Streams',\n",
    "                                 'Polarity', 'avg_Position', 'baby', 'je']]\n",
    "y_train_fr2  = fr_dep_train\n",
    "X_test_fr2  = fr_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'Subjectivity', 'avg_Streams',\n",
    "                                 'Polarity', 'avg_Position', 'baby', 'je']]\n",
    "y_test_fr2  = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_fr2, y_train_fr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19373664931011902, 'Score (R^2)': 0.21233396452492503}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=8, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_fr2, X_test_fr2, y_train_fr2, y_test_fr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16755451622431095}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_fr3 = fr_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_fr3 = fr_dep_train\n",
    "X_test_fr3 = fr_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_fr3 = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_fr3, y_train_fr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18987893063312286, 'Score (R^2)': 0.24338995186336407}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=8, max_features='log2', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_fr3, X_test_fr3, y_train_fr3, y_test_fr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models (RandomForestRegressor) - TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did choose RF bc that gave the best score when looking at all countries togehter.<BR />\n",
    "If the RF scores very well in one country (compared to the total score) then I might consider trying other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not have to scale a Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_hype(model, params, X_train, y_train):  \n",
    "    # Best Hyperparameters\n",
    "    rs = RandomizedSearchCV(model, params, n_iter=40)\n",
    "    \n",
    "    # fit\n",
    "    rs.fit(X_train, y_train)\n",
    "     \n",
    "    return {'best_score': rs.best_score_,'best_params': rs.best_params_} \n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # fit\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate: predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Evaluate: score\n",
    "    score = model.score(X_test, y_test)\n",
    "    \n",
    "    return {'Score (R^2)': score.mean(), 'MSE': mean_square_error}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Brittan / United Kingdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF_IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.18371888553485655}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_gb = gb_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_gb = gb_dep_train\n",
    "X_test_gb = gb_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_gb = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_gb, y_train_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20565677256544868, 'Score (R^2)': 0.284877526037732}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_gb, X_test_gb, y_train_gb, y_test_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.146436\n",
       "Acousticness        0.047077\n",
       "baby                0.029120\n",
       "avg_Streams         0.021062\n",
       "girl                0.020947\n",
       "Polarity            0.017266\n",
       "Subjectivity        0.017155\n",
       "Instrumentalness    0.016977\n",
       "Tempo               0.016976\n",
       "know                0.013420\n",
       "oh                  0.013051\n",
       "avg_Position        0.010982\n",
       "just                0.009942\n",
       "don                 0.009308\n",
       "cause               0.009205\n",
       "dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_gb.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF_IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 60,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16112876301968113}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_gb2 = gb_indep_train_tvec[['Energy', 'Acousticness', 'baby', 'avg_Streams', 'girl', 'Polarity',\n",
    "                                 'Subjectivity', 'Instrumentalness', 'Tempo', 'know']]\n",
    "y_train_gb2  = gb_dep_train\n",
    "X_test_gb2  = gb_indep_test_tvec[['Energy', 'Acousticness', 'baby', 'avg_Streams', 'girl', 'Polarity',\n",
    "                                 'Subjectivity', 'Instrumentalness', 'Tempo', 'know']]\n",
    "y_test_gb2  = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_gb2, y_train_gb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2066262875077516, 'Score (R^2)': 0.2781191182533066}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='log2', n_estimators=60, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_gb2, X_test_gb2, y_train_gb2, y_test_gb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF_IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 30,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.14400072731396285}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_gb3 = gb_indep_train_tvec[['Energy', 'Acousticness', 'baby']]\n",
    "y_train_gb3 = gb_dep_train\n",
    "X_test_gb3 = gb_indep_test_tvec[['Energy', 'Acousticness', 'baby']]\n",
    "y_test_gb3 = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_gb3, y_train_gb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.21673851821164267, 'Score (R^2)': 0.20573286195124063}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=30, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_gb3, X_test_gb3, y_train_gb3, y_test_gb3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15197506629570712}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_it = it_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_it = it_dep_train\n",
    "X_test_it = it_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_it = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_it, y_train_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19526084449228942, 'Score (R^2)': 0.14178929497849657}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=8, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_it, X_test_it, y_train_it, y_test_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.214291\n",
       "Acousticness        0.049394\n",
       "Instrumentalness    0.041181\n",
       "oh                  0.015222\n",
       "che                 0.014432\n",
       "pi                 0.012921\n",
       "Subjectivity        0.012343\n",
       "Polarity            0.011315\n",
       "avg_Streams         0.010018\n",
       "Tempo               0.009328\n",
       "baby                0.008921\n",
       "ooh                 0.008890\n",
       "know                0.008874\n",
       "ya                  0.008727\n",
       "avg_Position        0.008670\n",
       "dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_it.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-ID + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17660733430414619}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_it2 = it_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'oh', 'che', 'pi',\n",
    "                                 'Subjectivity', 'Polarity', 'avg_Streams', 'Tempo']]\n",
    "y_train_it2  = it_dep_train\n",
    "X_test_it2  = it_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'oh', 'che', 'pi',\n",
    "                                 'Subjectivity', 'Polarity', 'avg_Streams', 'Tempo']]\n",
    "y_test_it2  = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_it2, y_train_it2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19840961590942735, 'Score (R^2)': 0.11388715176286202}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='sqrt', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_it2, X_test_it2, y_train_it2, y_test_it2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.13569655728478214}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_it3 = it_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_it3 = it_dep_train\n",
    "X_test_it3 = it_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_it3 = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_it3, y_train_it3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20359551369342424, 'Score (R^2)': 0.0669605453992903}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_it3, X_test_it3, y_train_it3, y_test_it3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.2146681037937301}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_us = us_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_us = us_dep_train\n",
    "X_test_us = us_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_us = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_us, y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17917928013654794, 'Score (R^2)': 0.320028139296918}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_us, X_test_us, y_train_us, y_test_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.187557\n",
       "Polarity            0.023403\n",
       "baby                0.019677\n",
       "Acousticness        0.019296\n",
       "Subjectivity        0.017887\n",
       "Instrumentalness    0.015495\n",
       "like                0.013965\n",
       "Tempo               0.013591\n",
       "snow                0.013458\n",
       "girl                0.012747\n",
       "avg_Streams         0.011243\n",
       "hey                 0.010525\n",
       "say                 0.009002\n",
       "don                 0.008385\n",
       "just                0.008335\n",
       "dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_us.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.2207176480167608}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_us2 = us_indep_train_tvec[['Energy', 'Polarity', 'baby', 'Acousticness', 'Subjectivity', 'Instrumentalness',\n",
    "                                 'like', 'Tempo', 'snow', 'girl']]\n",
    "y_train_us2  = us_dep_train\n",
    "X_test_us2  = us_indep_test_tvec[['Energy', 'Polarity', 'baby', 'Acousticness', 'Subjectivity', 'Instrumentalness',\n",
    "                                 'like', 'Tempo', 'snow', 'girl']]\n",
    "y_test_us2  = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_us2, y_train_us2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18878375823938226, 'Score (R^2)': 0.24517787593084972}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='sqrt', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_us2, X_test_us2, y_train_us2, y_test_us2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16932017485114467}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_us3 = us_indep_train_tvec[['Energy', 'Polarity', 'baby']]\n",
    "y_train_us3 = us_dep_train\n",
    "X_test_us3 = us_indep_test_tvec[['Energy', 'Polarity', 'baby']]\n",
    "y_test_us3 = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_us3, y_train_us3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19990724781225308, 'Score (R^2)': 0.1536062534059779}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_us3, X_test_us3, y_train_us3, y_test_us3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deutchland / Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17188079626034436}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_de = de_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_de = de_dep_train\n",
    "X_test_de = de_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_de = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_de, y_train_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18816349770506227, 'Score (R^2)': 0.1904149159896471}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_de, X_test_de, y_train_de, y_test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.164225\n",
       "avg_Streams         0.031034\n",
       "baby                0.024554\n",
       "oh                  0.015565\n",
       "Polarity            0.014232\n",
       "avg_Position        0.012694\n",
       "Acousticness        0.012616\n",
       "Tempo               0.011084\n",
       "Subjectivity        0.010997\n",
       "Instrumentalness    0.010641\n",
       "bad                 0.009257\n",
       "just                0.007819\n",
       "eh                  0.007666\n",
       "snow                0.007599\n",
       "got                 0.006996\n",
       "dtype: float64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_de.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16119525001110976}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_de2 = de_indep_train_tvec[['Energy', 'avg_Streams', 'baby', 'oh', 'Polarity', 'avg_Position', \n",
    "                                   'Acousticness', 'Tempo', 'Subjectivity', 'Instrumentalness']]\n",
    "y_train_de2  = de_dep_train\n",
    "X_test_de2  = de_indep_test_tvec[['Energy', 'avg_Streams', 'baby', 'oh', 'Polarity', 'avg_Position', \n",
    "                                    'Acousticness', 'Tempo', 'Subjectivity', 'Instrumentalness']]\n",
    "y_test_de2  = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_de2, y_train_de2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19130740836151128, 'Score (R^2)': 0.16313516365083858}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='sqrt', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_de2, X_test_de2, y_train_de2, y_test_de2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': False,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 40,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.12095804863368141}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_de3 = de_indep_train_tvec[['Energy', 'avg_Streams', 'baby']]\n",
    "y_train_de3 = de_dep_train\n",
    "X_test_de3 = de_indep_test_tvec[['Energy', 'avg_Streams', 'baby']]\n",
    "y_test_de3 = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_de3, y_train_de3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1993637539816148, 'Score (R^2)': 0.09116687308490101}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=40, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_de3, X_test_de3, y_train_de3, y_test_de3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1875516782295987}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_ca = ca_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_ca = ca_dep_train\n",
    "X_test_ca = ca_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_ca = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_ca, y_train_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17786596487448125, 'Score (R^2)': 0.3082486524139738}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_ca, X_test_ca, y_train_ca, y_test_ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.152878\n",
       "baby                0.035818\n",
       "Acousticness        0.034272\n",
       "Instrumentalness    0.024157\n",
       "Polarity            0.019430\n",
       "Subjectivity        0.016306\n",
       "oh                  0.015656\n",
       "don                 0.014247\n",
       "Tempo               0.013239\n",
       "sing                0.011653\n",
       "heart               0.010999\n",
       "girl                0.010609\n",
       "just                0.009083\n",
       "cause               0.008718\n",
       "avg_Streams         0.008622\n",
       "dtype: float64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_ca.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1861822351861458}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_ca2 = ca_indep_train_tvec[['Energy', 'baby', 'Acousticness', 'Instrumentalness', 'Polarity', 'Subjectivity',\n",
    "                                 'oh', 'don', 'Tempo', 'sing']]\n",
    "y_train_ca2  = ca_dep_train\n",
    "X_test_ca2  = ca_indep_test_tvec[['Energy', 'baby', 'Acousticness', 'Instrumentalness', 'Polarity', 'Subjectivity',\n",
    "                                 'oh', 'don', 'Tempo', 'sing']]\n",
    "y_test_ca2  = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_ca2, y_train_ca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1859943327785615, 'Score (R^2)': 0.2435787312746738}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=8, max_features='log2', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_ca2, X_test_ca2, y_train_ca2, y_test_ca2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15350443169864744}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_ca3 = ca_indep_train_tvec[['Energy', 'baby', 'Acousticness']]\n",
    "y_train_ca3 = ca_dep_train\n",
    "X_test_ca3 = ca_indep_test_tvec[['Energy', 'baby', 'Acousticness']]\n",
    "y_test_ca3 = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_ca3, y_train_ca3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18888789114451257, 'Score (R^2)': 0.21986000281487086}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_ca3, X_test_ca3, y_train_ca3, y_test_ca3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Netherlands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.20411463579142383}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_nl = nl_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_nl = nl_dep_train\n",
    "X_test_nl = nl_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_nl = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_nl, y_train_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17963835086509775, 'Score (R^2)': 0.2524743901759854}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=11, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_nl, X_test_nl, y_train_nl, y_test_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.223327\n",
       "Acousticness        0.054516\n",
       "Subjectivity        0.022405\n",
       "Instrumentalness    0.017538\n",
       "Polarity            0.014851\n",
       "Tempo               0.013531\n",
       "avg_Streams         0.013209\n",
       "baby                0.012948\n",
       "know                0.012684\n",
       "want                0.011728\n",
       "avg_Position        0.010072\n",
       "oh                  0.009952\n",
       "Mode                0.009132\n",
       "away                0.008415\n",
       "song                0.007253\n",
       "dtype: float64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_nl.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 40,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17698124752645786}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_nl2 = nl_indep_train_tvec[['Energy', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'Polarity', 'Tempo',\n",
    "                                 'avg_Streams', 'baby', 'know', 'want']]\n",
    "y_train_nl2  = nl_dep_train\n",
    "X_test_nl2  = nl_indep_test_tvec[['Energy', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'Polarity', 'Tempo',\n",
    "                                 'avg_Streams', 'baby', 'know', 'want']]\n",
    "y_test_nl2  = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_nl2, y_train_nl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.191636510979673, 'Score (R^2)': 0.14928426115479554}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='log2', n_estimators=40, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_nl2, X_test_nl2, y_train_nl2, y_test_nl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 2,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16766138209302633}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_nl3 = nl_indep_train_tvec[['Energy', 'Acousticness', 'Subjectivity']]\n",
    "y_train_nl3 = nl_dep_train\n",
    "X_test_nl3 = nl_indep_test_tvec[['Energy', 'Acousticness', 'Subjectivity']]\n",
    "y_test_nl3 = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_nl3, y_train_nl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1885238077582708, 'Score (R^2)': 0.17669573930427385}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=2, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_nl3, X_test_nl3, y_train_nl3, y_test_nl3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.22871378573224335}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_au = au_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_au = au_dep_train\n",
    "X_test_au = au_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_au = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_au, y_train_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19131517110382987, 'Score (R^2)': 0.2715820837463585}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_au, X_test_au, y_train_au, y_test_au)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.180291\n",
       "Acousticness        0.038735\n",
       "Instrumentalness    0.031357\n",
       "Polarity            0.023082\n",
       "Tempo               0.018245\n",
       "Subjectivity        0.016056\n",
       "snow                0.015395\n",
       "hey                 0.013942\n",
       "avg_Streams         0.013238\n",
       "end                 0.012757\n",
       "road                0.012757\n",
       "bad                 0.010009\n",
       "just                0.009554\n",
       "don                 0.009469\n",
       "know                0.009189\n",
       "dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_au.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.19665454313911662}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_au2 = au_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'Polarity', 'Tempo', 'Subjectivity',\n",
    "                                 'snow', 'hey', 'avg_Streams', 'end']]\n",
    "y_train_au2  = au_dep_train\n",
    "X_test_au2  = au_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'Polarity', 'Tempo', 'Subjectivity',\n",
    "                                 'snow', 'hey', 'avg_Streams', 'end']]\n",
    "y_test_au2  = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_au2, y_train_au2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20639120554240528, 'Score (R^2)': 0.15225707541645794}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=17, max_features='sqrt', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_au2, X_test_au2, y_train_au2, y_test_au2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 2,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 10,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15353285489934612}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_au3 = au_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_au3 = au_dep_train\n",
    "X_test_au3 = au_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_au3 = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_au3, y_train_au3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20919128034745282, 'Score (R^2)': 0.12909866914319623}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=2, max_features='auto', n_estimators=10, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_au3, X_test_au3, y_train_au3, y_test_au3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.212545002755988}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_fr = fr_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_fr = fr_dep_train\n",
    "X_test_fr = fr_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_fr = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_fr, y_train_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19207918862143117, 'Score (R^2)': 0.22575363459641162}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_fr, X_test_fr, y_train_fr, y_test_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.167301\n",
       "Acousticness        0.041652\n",
       "Instrumentalness    0.027502\n",
       "Subjectivity        0.019713\n",
       "Tempo               0.016747\n",
       "x2                  0.015546\n",
       "Polarity            0.015252\n",
       "avg_Streams         0.013585\n",
       "avg_Position        0.011396\n",
       "baby                0.008699\n",
       "oh                  0.007446\n",
       "got                 0.007280\n",
       "suis                0.007017\n",
       "je                  0.006579\n",
       "qu                  0.006511\n",
       "dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_fr.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17674201382895674}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_fr2 = fr_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'Subjectivity', 'Tempo', 'Polarity',\n",
    "                                 'avg_Streams', 'avg_Position', 'baby', 'oh']]\n",
    "y_train_fr2  = fr_dep_train\n",
    "X_test_fr2  = fr_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'Subjectivity', 'Tempo', 'Polarity',\n",
    "                                 'avg_Streams', 'avg_Position', 'baby', 'oh']]\n",
    "y_test_fr2  = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_fr2, y_train_fr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1996000180024958, 'Score (R^2)': 0.1639356555487793}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_fr2, X_test_fr2, y_train_fr2, y_test_fr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': False,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15848262661970244}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_fr3 = fr_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_fr3 = fr_dep_train\n",
    "X_test_fr3 = fr_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_fr3 = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_fr3, y_train_fr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18987893063312286, 'Score (R^2)': 0.24338995186336407}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_fr3, X_test_fr3, y_train_fr3, y_test_fr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMMARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CountVec**<BR />\n",
    "GB all - 'Score (R^2)': 0.31418039815233123<BR />\n",
    "GB 10 - 'Score (R^2)': 0.2630365296467547<BR />\n",
    "GB 3 - 'Score (R^2)': 0.24871557476627015<BR />\n",
    "IT all - 'Score (R^2)': 0.15968396438438126<BR />\n",
    "IT 10 - 'Score (R^2)': 0.1452391861548371<BR />\n",
    "IT 3 - 'Score (R^2)': 0.071902267156844<BR />\n",
    "US all - 'Score (R^2)': 0.3188044396985018<BR />\n",
    "US 10  - 'Score (R^2)': 0.2536223484064851<BR />\n",
    "US 3 - 'Score (R^2)': 0.17239535171712106<BR />\n",
    "DE all - 'Score (R^2)': 0.19659568557898718<BR />\n",
    "DE 10  - 'Score (R^2)': 0.14725369224245033<BR />\n",
    "DE 3 - 'Score (R^2)': 0.10316528973537387<BR />\n",
    "CA all - 'Score (R^2)': 0.3273411319309155<BR /> \n",
    "CA 10  - 'Score (R^2)': 0.2685732146069939<BR />\n",
    "CA 3 - 'Score (R^2)': 0.1961156143878502<BR />\n",
    "NL all - 'Score (R^2)': 0.25069816123443533<BR />\n",
    "NL 10  - 'Score (R^2)': 0.15830450182716116<BR />\n",
    "NL 3 - 'Score (R^2)': 0.178184977008047<BR />\n",
    "AU all - 'Score (R^2)': 0.26258288149338593<BR />\n",
    "AU 10 - 'Score (R^2)': 0.17300384155218806<BR />\n",
    "AU 3 - 'Score (R^2)': 0.16144333395793364<BR />\n",
    "FR all - 'Score (R^2)': 0.25917183970000157<BR />\n",
    "FR 10 - 'Score (R^2)': 0.21233396452492503<BR />\n",
    "FR 3 - 'Score (R^2)': 0.24338995186336407<BR />\n",
    "\n",
    "**TF-IDF**<BR />\n",
    "GB all - 'Score (R^2)': 0.284877526037732<BR />\n",
    "GB 10 - 'Score (R^2)': 0.2781191182533066<BR />\n",
    "GB 3 - 'Score (R^2)': 0.20573286195124063<BR />\n",
    "IT all - 'Score (R^2)': 0.14178929497849657<BR />\n",
    "IT 10 - 'Score (R^2)': 0.11388715176286202<BR />\n",
    "IT 3 - 'Score (R^2)': 0.0669605453992903<BR />\n",
    "US all - 'Score (R^2)': 0.320028139296918<BR />\n",
    "US 10  - 'Score (R^2)': 0.24517787593084972<BR />\n",
    "US 3 - 'Score (R^2)': 0.1536062534059779<BR />\n",
    "DE all - 'Score (R^2)': 0.1904149159896471<BR />\n",
    "DE 10  - 'Score (R^2)': 0.16313516365083858<BR />\n",
    "DE 3 - 'Score (R^2)': 0.09116687308490101<BR />\n",
    "CA all - 'Score (R^2)': 0.3082486524139738<BR />\n",
    "CA 10  - 'Score (R^2)': 0.2435787312746738<BR />\n",
    "CA 3 - 'Score (R^2)': 0.21986000281487086<BR />\n",
    "NL all - 'Score (R^2)': 0.2524743901759854<BR />\n",
    "NL 10  - 'Score (R^2)': 0.14928426115479554<BR />\n",
    "NL 3 - 'Score (R^2)': 0.17669573930427385<BR />\n",
    "AU all - 'Score (R^2)': 0.2715820837463585<BR />\n",
    "AU 10 - 'Score (R^2)': 0.15225707541645794<BR />\n",
    "AU 3 - 'Score (R^2)': 0.12909866914319623<BR />\n",
    "FR all - 'Score (R^2)': 0.22575363459641162<BR />\n",
    "FR 10 - 'Score (R^2)': 0.1639356555487793<BR />\n",
    "FR 3 - 'Score (R^2)': 0.24338995186336407<BR />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best model per country**<BR />\n",
    "GB all CountVec - 'Score (R^2)': 0.31418039815233123<BR />\n",
    "IT all CountVec - 'Score (R^2)': 0.15968396438438126<BR />\n",
    "US all TF-IDF - 'Score (R^2)': 0.320028139296918<BR />\n",
    "DE all CountVec - 'Score (R^2)': 0.19659568557898718<BR />\n",
    "CA all CountVec - 'Score (R^2)': 0.3273411319309155<BR />\n",
    "NL all TF-IDF - 'Score (R^2)': 0.2524743901759854<BR />\n",
    "AU all TF-IDF - 'Score (R^2)': 0.2715820837463585<BR />\n",
    "FR 3 CountVec - 'Score (R^2)': 0.24338995186336407<BR />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The score and how many varables to choose (and which ones) varies from country to country. Also the choice btw TF-IDF och CountVec seem to vary.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make some plots - compairing bar chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAHsCAYAAACT7qdbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3Xl0FOeB7v+n1K0dLSAJISGBkFgF\nSGIz++ol3oON1yHGhNjmNxNPMncuc+bcm8yAZjnx3Ny5E2Y89thn4jEOHid2YhvHdozNZhswYAkQ\nQuwgQGIREiAktC/1+0NRuVvdklpLl7D0/ZyjM11Vb731VjnD0+9bb1UbpmkKAADYJ6CvGwAAwEBD\n+AIAYDPCFwAAmxG+AADYjPAFAMBmhC8AADYjfAEAsBnhCwCAzQhfAABs5vRn5WFhYWZ6ero/D3HL\nu3jxohITE/u6GX1moJ+/xDWQuAYS10AaGNcgNze3zDTNuE4Lmqbpt7+EhARzoFu3bl1fN6FPDfTz\nN02ugWlyDUyTa2CaA+MaSMoxfchHhp0BALAZ4QsAgM0IXwAAbEb4AgBgM8IXAACbEb4AANiM8AUA\nwGaELwAANiN8AQCwGeELAIDNCF8AAGxG+AIAYDPCFwAAmxG+AADYjPAFAMBmhC8AADYjfAEAsBnh\nCwCAzQzTNP1WuSPRYTavbvZb/QAAdFd8eLwur7ncq3UahpFrmub0zsr5tefbLIIXAHBrKqkq6bNj\nM+wMAIDNCF8AAGxG+AIAYDPCFwAAmxG+AADYjPAFAMBmhC8AADYjfAEAsBnhCwCAzQhfAABsRvgC\nAGAzZ183oLcZMvTAuAe0fPJy3Tb8Ng0NH6rG5kZdqLig3Eu5+k3Bb/ThiQ/d9glxhqhkTYkigyOt\ndT/8+Id66euXPOpfOHKhdqzcYS0fKT2iyS9PVrP5zXustz+9XYtSFkmSXtj5gv7X1v/lUU9SZJLO\n/visHAEOa919/32fPj75sUfZpzOf1utLX7eWm81m1TfV60btDRVXFCvnUo5eP/i69hTv6fDazE2e\nq52rdrqtm/jSRB0pPdLhfgCA3tWver5Dw4dq+9PbtemJTXps4mNKiU5RWGCYIoMjNSFugr6X8T39\n/snfKyo4ym2/ZROWuQWvJK3MXOnTMdPj0vVUxlNdbuvTmU+7BW9XjhlgBCjEGaL4QfGaljhNq6et\n1lc/+EobH9qosMCwdvdbmeVZv7d1AAD/6jfhG+oM1ebvbdbClIWSpKbmJv3ywC/10G8e0pINS/T0\n+0/r14d/rfqmeo99vQXQjOEzlB6X7tOx1y5cq8CAwC61d0XmCo91D4x7QINDBne677zX5mnxhsX6\n/qbv65NTn1jrl2cs19uPvO11nxBniB5Nf9Rj/fcmf08BRr/5nwEAfCv0m391fzzrx8oalmUtL393\nuZ754Bm9f+x9bT+7XW/kvaEnf/ekJr00SdUN1Va5pMgkLU5ZLEmqaajRW/lvWdueznzap2OPGjxK\nz0571ue2zkmeo7ExYyVJxRXF+vT0p5JaAvKJSU90uv+uol3acXaHXj/4uu558x79dNtPrW33jb1P\nj018zGOfhyc8rKiQlh7/V0Vf6WjpUUlSQkSCvpP2HZ/bDgDoOZ/D1zCMIYZhvGcYRpVhGOcMw/gT\nfzasq1yDcuuZrfpNwW+8ljt57aQamhus5RWZK6zh3w9PfKh///rfrW3fy+i8V/hV0VeSpJ/M/4lC\nnaE+tdW1p/3W4bf0Rt4bXrf56h+//EeduHrCWvb2pcF1SHtj/ka9mf9mj44JAOi+rvR8/11SvaR4\nScslvWwYxkS/tKqLwgLDND52vLX86ZlPfd53RcY3w79v5r+pXUW7VHi9UJKUGJHYaa/wJ9t+YpV9\n/rbnOz1eiDNEj6V/0zN989Cbeu/Ye7pZf1OSdNvw2zQhdoLP7W+1tXCr9Xl64nS3bUmRSVoyaokk\nqaGpQW8XvO0Wvg+Oe1DRIdFdPiYAoHt8Cl/DMMIlLZP0N6Zp3jRNc6ekDyR1faaRH7QNjqvVV33a\nb3bSbI2LHSdJulZzzZpp/N+H/9sq09nQ8+6i3froxEeSpL+e+9eKCIrosPxD4x+yhn8LrhQoryRP\n1Q3V2nRs0zfHzPJtuNuV6zm3vR5PZTxl9e43n96ssuoynS0/q13nd0nyfbgbANA7fH3UaKykJtM0\nT7isy5O0sG1BwzCek/ScJCmhp83zTXltudtyTFiMT/u5Dre+c+Qdazj6zUNv6ifzW3q03x3/XUWH\nRHscw9VPtv1E94y5RzFhMfqfc/6nz8fcmL/R+vxm/ptanrFcUsskqP+99X+7Pb7UmbjwOOtz27a6\nfoFw7fG+mf+m5o6Y29KuzJX6j5z/8Pl4ANAfZGdn98lxfQ3fQZJutFl3Q5JHN880zVclvSpJRqJh\n9qh1PqpuqNaxsmPW0PMdo+7Q/9n1fzrcJ8QZ4jYxafW01Vo9bbXXck9MeqLDYMorydNvj/xWj018\nTP9j1v/Q+RvnvZYbHjFct4+63Vr+2e0/089u/5lnucjhuivtLreZzB0xZOiOUXdYyzkXc6zPrr17\nSXpr2Vt6a9lbamtm0kyNjx2vY2XHfDomAPQHa9eu7dX61q1b51M5X+/53pQU2WZdpKRK35vkX68f\nfN36fGfanXok/RGv5UYPGa3AgEAtHb/U5/ucvsx6/pvtf6PG5kZFBkdq0tBJXss8lfmUx7O9PTmm\ndeyFf6O0IWnW8oa8Dd/U04Uh7K4cEwDQfb72fE9IchqGMcY0zZN/XJcpqcA/zeq69XvX64lJT1iP\nG7217C3dlXaXPjzxoSrqKjQ8YrjuHn23Hk1/VPH/N95t9u+mY5v0h1N/cKsv2Bms9XevlyTNSpql\ncTHjdPzq8XaPf+LqCb2R94ZWTVnVbhnXcHvtwGvad2Gf2/bEiET97cK/lSR9d9x3FRUcpRt1bQcc\nWt5UFegI1MiokXpy0pP6zuhvJoV9dOIjvV3Q8qxvsCNYj0983Nr2890/1+lrp93qmhw/WT+c8UNJ\nLfeGf7LtJ10a7gYAdJ1P4WuaZpVhGO9K+jvDMJ6RlCXpu5Lm+LNxXVHbWKu7N96t3zzyGy1MWShn\ngFPPTn1Wz071fP42PChcd6R+M0z7s50/094Lez3KfW/y9zRj+AxJLfdqvb0m0lX259laPnm5gp3B\nHttmJc2yhsWbzWb9dNtPdenmJbcyhgw9N+05DRs0TKGBoXpi0hN6JfcVj7raviKy1ZuH3tRzHz5n\nLT804SGrd3+j9oZ+uu2nHi8ZiQqO0rNTn1WQI0jDI4frztQ7tfn05g7PEwDQM1151OjPJIVKuiLp\nLUl/aprmLdPzlaSSqhIt3rBYS3+9VO8UvKNz5edU01CjyrpKHSs7pjcPvakH33rQ7dne4opir8Er\nSe8ee9f6/FTGU50+83v+xnm9uv9Vr9tce71fFX3lEbySZMrUpuPfzHpu7/nbZrNZdY11KrlZotyL\nuXol9xXN/uVsfe+977m9QMT1mB+e+NDr271u1N3Q9sLtnR4TANB7DNP035woI9Ew5TmHCQCAW4K5\ntncz0DCMXNM0p3dWrt+8XhIAgG8LwhcAAJsRvgAA2IzwBQDAZoQvAAA2I3wBALAZ4QsAgM0IXwAA\nbEb4AgBgM8IXAACbEb4AANiM8AUAwGaELwAANvNr+AaQ7QCAW1R8eHzfHdw0Tb/9JSQkmAPdunXr\n+roJfWqgn79pcg1Mk2tgmlwD0xwY10BSjulDPtI1BQDAZoQvAAA2I3wBALAZ4QsAgM0IXwAAbEb4\nAgBgM8IXAACbEb4AANjMaHkm2D8SExPN1atX+61+AADaCg8P15o1a/rk2IZh5JqmOb2zcvR8AQD9\nSlVVVV83oVOELwAANiN8AQCwGeELAIDNCF8AAGxG+AIAYDPCFwAAmxG+AADYjPAFAMBmhC8AADYj\nfAEAsBnhCwCAzZx93YDekpmZqaVLl1rL2dnZbtsXLlyoRYsWSZLKy8u1fv16a1taWppuu+02JSYm\nKjQ0VA0NDaqpqdG1a9dUUlKivXv3qqKiwpbzAAD0f/0mfLvrtttu0z333OO2zuFwKCQkRIMHD1Za\nWppOnTpF+AIAes2ADt/AwEDdfvvt1vL+/ft17NgxNTU1KTo6WomJiRo/fnwfthAA0B8N6PCNi4tT\nUFCQJKmmpka///3v3bbv379fH330kRwOR180DwDQT/k04cowjOcNw8gxDKPOMIzX/dwm29TV1Vmf\nQ0NDdddddykhIUEBAd9cFtM01djY2BfNAwD0U772fC9K+gdJ35EU6r/m2OvatWsqKytTbGysJGn2\n7NmaPXu2GhsbdenSJZ0+fVq5ubm6efNmH7cUANCf+NTzNU3zXdM035d01c/tsZVpmvrd736n8vJy\nt/VOp1PJyclatGiRnn/+eY0YMaKPWggA6I/6zXO+pml2uN0wDK9lL1++rBdffFHvvPOO9u/frytX\nrrhtDw4O1gMPPND7DQYADFi9PuHKMIznJD0nSQkJCb1dfbvq6+vdlsPCwlRdXe223Kq2ttatbFNT\nk44cOaIjR45IksLDw3XHHXcoKytLkhQbG6vg4GC3e8QAgFtX23c93Gp6PXxN03xV0quSlJiY2HF3\ntBdduXLFbXnMmDHKy8uT1NLrTUtLs7aVlpZKkkJCQhQfH69z58657VtVVaWcnBwrfFvrAAB8O6xd\nu7ZPjrtu3TqfyvWbR42uXbumCxcuaPjw4ZKk+++/X8nJyaqqqtLo0aM1ZMgQq2x+fr6klhnOK1eu\nVGlpqY4dO6ZLly6purpagwYN0uzZs63yZWVlHr1lAAC6y6fwNQzD+ceyDkkOwzBCJDWapnlLPYOz\nadMmrVy5UmFhYXI6nZo2bZpHmZycHJ06dcptXVxcnOLi4rzW2dTUpM2bN/ulvQCAgcnXnu9PJbn2\n4b8nKVvSut5uUE+Ulpbq5Zdf1uzZs5WWlqbBgwfL4XCopqZGly5d0oEDB3T06FGr/I0bN/TWW29p\n1KhRGj58uCIiIhQeHi7DMFRZWanz589rz549unz5ch+eFQCgvzE6myXcE4mJiebq1av9Vj8AAN70\n1T1fwzByTdOc3lm5fvOoEQAA3xaELwAANiN8AQCwGeELAIDNCF8AAGxG+AIAYDPCFwAAmxG+AADY\njPAFAMBmhC8AADYjfAEAsBnhCwCAzQhfAABsRvgCAGAzwhcA0K+Eh4f3dRM6Z5qm3/4SEhLMgW7d\nunV93YQ+NdDP3zS5BqbJNTBNroFpDoxrICnH9CEf6fkCAGAzwhcAAJsRvgAA2IzwBQDAZoQvAAA2\nI3wBALAZ4QsAgM0IXwAAbGa0PBPsH4mJiebq1av9Vj8AYGAKDw/XmjVr+roZHgzDyDVNc3pn5ej5\nAgC+daqqqvq6CT1C+AIAYDPCFwAAmxG+AADYjPAFAMBmhC8AADYjfAEAsBnhCwCAzQhfAABsRvgC\nAGAzwhcAAJsRvgAA2MzZ1w3wh9TUVGVkZCgpKUmDBg2Sw+FQVVWVbt68qaKiIp04cUKFhYVW+YUL\nF2rRokUe9dTX1+vGjRsqLCzUrl27VFFR4bb96aefVkpKSodtef/995WXl+exfvLkyXr44Yet5cbG\nRv3zP/+zamtrrXWDBw/Wj370Ix/PWmpubtbf//3ft7vdMAz97d/+rcf6pqYm1dbWqrS0VAUFBcrN\nzZXrD25MmTJFDz74oMd+DQ0Nqqys1Llz57R7926VlZW5bX/ooYeUkZEhSTpz5ox+9atfafHixVqw\nYIHP57R//379/ve/d1vXto7y8nKtX7/e6/4/+MEPlJSUJEnKycnRRx99JEmKiYnR888/b5WrrKzU\nv/7rv6qxsdFat2zZMk2aNEmSdPDgQW3atMnndgNAR/pVzzcsLEzLly/XU089pczMTMXExCg4OFhO\np1NRUVEaPny4Zs2apRUrVsjhcHRaX1BQkOLi4nTbbbfp2Wef1aBBg3qtrVlZWW7LTqdTkydP7rX6\nu8LhcCg8PFwpKSm67777tHTpUp/2CwwM1JAhQzRlyhQ988wziouL83NLW7QGeqvo6GiNGjWqR3VG\nRERo5syZPaoDAHzVb3q+DodDy5cvV2JiorWuoKBAx44d082bNxUYGKihQ4dqzJgxGjlyZLv1VFZW\n6p133pHT6VRqaqrmzZsnSRo0aJCysrK0c+dOr/udPHlSX375pcf6q1eveqyLjIz02mPOzMzU119/\nbS1XVFTotddecytz3333KT4+XpJ0/Phx7dq1q91z6cznn3+u06dPKzAwULNmzdKYMWMktYTbli1b\nVFlZ6bFPc3OzXn/9dTkcDg0fPlxLlixRQECAgoODNWPGDH388ccdHjM3N1enTp2yliMjI/XII49Y\nyx999JFKSkqs5Zs3b7rtP2rUKEVHR3vUm5mZ6Taa0R1z585VTk6O6urqelQPAHSm34TvrFmz3IL3\ngw8+0IEDB9zKnDx5Urt27VJ8fLyam5u91tPU1KSioiJJUmFhocaOHauhQ4dKkqKioto9flVVlbVf\nZzIzMxUQ0DLocPToUY0aNUohISEaPny4YmNjreFb17a0cg2GrhzTm6tXr1r7V1VVWeErtXzZ8Ba+\nkqx9zp49q5SUFI0ePVpSx9enVUVFhdvw/eDBg922l5SUdHhOmZmZ1ueDBw8qMzNThmFowoQJ+vjj\nj1VfX99pG9oTGhqqOXPmaPv27d2uAwB84dOws2EYwYZh/NIwjHOGYVQahnHAMIx7/N24rnD9R/ns\n2bMeweuqpKTE7Z6mr9re8+0u12HTAwcO6MiRI9Zy2+FoOzidTqWnp1vL9fX1unbtWpfr6a3r056g\noCBNmDDBWv7iiy+soA4KCnI7h65qrWfmzJkKCwvrWUMBoBO+9nydkookLZR0XtK9kt42DGOyaZpn\n/dQ2nzmdTrf7ja7DmpI0bNgwBQYGuq2rqKjQjRs3POpyOBxKTk6W0+nUqFGjrF5vbW2tDh482G4b\nsrKyvAbnCy+84NZbTU5OVmxsrKSW3uapU6fU0NCgqVOnSmoJ5q1bt3bry0FXPfzww26TvqSWnvVH\nH33U4dBrcnKyHA6HEhMTlZqaKqllwlhOTo5f2ztx4kQFBQVJkoqLi3X9+nXl5+drxIgRklr+G3T0\n36gjO3bs0PLlyxUcHKx58+bp008/7bV2A0BbPoWvaZpVkta5rPrQMIxCSdMkne39ZnVNaGio23J1\ndbXb8kMPPWSFaKudO3dq69atHnVFRERo1apVbutOnz6tzZs3tzsM2xWuPfSCggKZpqmzZ8/qxo0b\nioqKUkREhNLS0jy+QNilsbHRCjhvAgICPK5PcXGxNm/e7Hav1h9cr92hQ4cktVzDu+++Ww6HQyNG\njFB0dLTKy8u7XPfVq1eVl5enKVOmaPr06frqq696rd0A0Fa37vkahhEvaaykAi/bnpP0nCQlJCT0\nqHG+cn08R1KvDxsmJCR0Wmd7E65c70E6nU5NnDjRWs7Pz7c+Hz58WHPnzpXUEjJ2hG/rhCun06mU\nlBTNnz9f4eHhuv/++1VeXq7Tp0/7VM/QoUMVERHh17ZGR0dbPdympiYVFLT8T6+mpkanTp3SuHHj\nZBiGsrKytGPHjm4dY8eOHZo8ebICAwO1cOHC3mo6AD/Jzs7u6yZ0W5fD1zCMQElvStpgmuaxtttN\n03xV0quSlJiY6P+xU7U8b1pWVmYN56amprrNAn755Zcl+fZcbuszo5GRkXrggQc0evRohYWF6fHH\nH9eLL77o0atu5cvkp/HjxyskJMRa/sEPftBhubZfKnqb64SrwsJCJSUlWcPIkydP9hq+rc8Sh4WF\n6Tvf+Y4yMjIUFBSkhx9+WP/xH//hdXZ3b8jKypJhGJJabg381V/9lddyGRkZ3Q7fiooK5ebmaubM\nmcrKytLly5e721wANli7dm1fN8HDunXrfCrXped8DcMIkPQrSfWSnu+kuK1c7/Wlpqa69TC7o6Ki\nQu+++64VgKGhoV16OYQ3rsOmHWnbQ+4LbYfy26qurtYHH3xgDfE6nU7dfvvtfmtP22d72zN48OAO\nHyXrzJdffqn6+nrrUSoA8Aefe75GS7fjl5LiJd1rmmaD31rVDXv37tWkSZM0bNgwSS2TiUaPHq0T\nJ06ourpaYWFhioyM7FKdNTU12rdvnxW6U6dO1c6dOz2ePZWk8PBwJScne6yvrKxUeXm5IiIirF6l\nJG3ZssWjZ5uSkmK9USkrK0u5ubldam9XxcTEWJPLUlJS3NpXWlra6f5NTU3auXOn7r//fkktPfah\nQ4fqypUrvdrOlJQU65GkhoYGbd682aPMxIkTrRdtZGVl6dy5c906VlVVlfbu3av58+d3v8EA0Imu\nDDu/LGmCpDtM06zxU3u6rbGxURs3btQjjzyilJQUBQQEtDsDWWoJDl/s2bNHM2fOVHBwsAIDAzV3\n7lyv//iPGTPG7TlZ1/03b97s9mxvWVmZ15djnD9/3grfpKQkxcTE+G0YV2p5raa3e5uVlZXas2eP\nT3UcOHBACxYsUGRkpAzD0IIFC/Tb3/62V9vpOmJw+vRpr19KqqurrfBNT0/Xxx9/rIaG7n0/3L17\nt6ZPn95p7x8AusvX53xHSlotKUvSZcMwbv7xb7lfW9dFVVVV2rBhg9566y0dPnxY169fV0NDg5qa\nmqx7snv27NEbb7zh833Bmpoat0dopk2b1q0JXa4BcvToUa9lSktL3d6PbOczv/X19SopKdFXX32l\nV155xWvv3pvm5ma3LxLp6enWvffeEBgY6Pb8bnvX7uTJk1bY9vSZ39raWmY7A/Arw5/PkyYmJpqr\nV6/2W/0AgIHrVpxwZRhGrmma0zsr169+WAEAgG8DwhcAAJsRvgAA2IzwBQDAZoQvAAA2I3wBALAZ\n4QsAgM0IXwAAbEb4AgBgM8IXAACbEb4AANiM8AUAwGaELwAANiN8AQCwGeELAPjWCQ8P7+sm9Ixp\nmn77S0hIMAe6devW9XUT+tRAP3/T5BqYJtfANLkGpjkwroGkHNOHfKTnCwCAzQhfAABsRvgCAGAz\nwhcAAJsRvgAA2IzwBQDAZoQvAAA2I3wBALCZ0fJMsH8kJiaaq1ev9lv9AADvwsPDtWbNmr5uhpvs\n7GytXbu2r5vhV4Zh5JqmOb2zcvR8AaAfqqqq6usmoAOELwAANiN8AQCwGeELAIDNCF8AAGxG+AIA\nYDPCFwAAmxG+AADYjPAFAMBmhC8AADYjfAEAsBnhCwCAzZx93QB/SE5O1qpVq9zWvfTSSyotLXVb\nt3DhQi1atEiSVF5ervXr17tt/+53v6usrCxJ0tmzZ7Vhwwa37RMnTtTUqVM1bNgwBQcHq76+XtXV\n1bp69apKSkq0a9cu1dXVuR3HFwcPHtSmTZvcjt/KNE3V19fr+vXrOnXqlHbv3q2ampp263rqqaeU\nmppqLRcUFOi3v/2t17KuLzx///33lZeX1269nV2bVs8//7xiYmKs5d27d+uzzz5rt14AGAj6Zc+3\nbWC1t64n7rrrLj3yyCNKTU1VWFiYHA6HQkNDFRMTo7Fjx2r+/PkKCwvr1WNKkmEYCg4O1rBhwzRv\n3jytWrVKTqf371CRkZFKSUlxWzdu3DiFhIT0eru8SU5OdgteSZo8ebIMw7Dl+ABwq+p3PV+n06n0\n9HSP9ZMnT9aWLVvUGz+hGB0drVmzZklq6Ynu3r1bhYWFMgxD0dHRSk5O1tixY63yBw4c0JkzZ6zl\nQYMG6bHHHrOW//CHP+jSpUvWsrdfI7l06ZL+8Ic/KDAwUJMmTdKUKVMkSbGxsRo/frwOHz7ssU9m\nZqYCAty/XzmdTk2ePFlff/11N8/ed96+8ERERGj06NE6efKk348PALeqfhe+EyZMsHp2RUVFCgkJ\nUVxcnCIiIpSWlqZTp071+BiJiYlW7+3y5cvasmWL2/acnBw5HA4r6CsqKlRRUWFtj4qKcitfUlKi\noqKiDo9ZV1dnlTlz5ozbebatr1VmZqb1+cCBA1ZgZ2Zm+j18234Jant8whfAQObzsLNhGBsNw7hk\nGEaFYRgnDMN4xp8N6y7XwMnPz1d+fr613FtDz3V1ddbnoUOHav78+YqLi3Mr09TUpObm5l45njeu\nQ7euwd7Kdcj35s2b+uSTT6x2Dx8+XLGxsX5rm+T+JejChQvasWOH9WXEzqFvALgVdaXn+zNJPzBN\ns84wjPGSdhiGccA0zVw/ta3LIiMjNWrUKEkt4VdQUKCgoCAtWbJE0jf/6NfW1vboOMXFxaqqqlJ4\neLgcDoeWLFmiJUuWqL6+XhcvXtTJkye1f//+Hh/HVXBwsJKTkxUYGKiJEycqODhYknTjxg0dO3bM\no7zrF43Dhw+rvr5eR48etdZnZWV59Nh7U9svQRUVFTp37pxSUlLkdDo1adIk5eTk+O34AHAr87nn\na5pmgWmarV0+849/aX5pVTdlZGRY9zhPnz6t6upqlZeX6/z585Jk/aPfU3V1dXr33XdVXV3ttj4o\nKEgpKSm688479cMf/tBjslFPJCQkaNWqVXrqqac0depUSS2h+tprr6mhocGtbNsh30OHDkmS2yhA\nRkaG3yY+RUREWF+CmpubrfvRrsd3DWcAGGi6dM/XMIyXJK2UFCrpgKSPvZR5TtJzUktg2Kltb8v1\n84gRI6wyrT2urky+alv2zJkzWr9+vdLT0zVq1CglJSVpyJAh1vZBgwbp7rvv1ptvvtmtc/FFUlKS\n1QN2NX78eGtYt6yszJrMVVhYqMrKSkVERPTqPfC2XCd6nTlzxppAduTIEd1zzz1yOp1KSkpSbGys\nysrKev34AFpkZ2f3dRM83Ipt6gtdCl/TNP/MMIw/lzRb0iJJdV7KvCrpVUlKTEzs+dRiH7X+Y95q\n2bJlWrZsWbvlysrKVF9fb6339lhQeHi49dnbEHJ9fb0OHjyogwcPSmqZBX3vvfdqzJgxklrurfaW\n1mdpY2JitGzZMiUkJCg6OlpPPPGEXnrpJTU1NVllXYecY2Nj3Z7fdZWZmem38G01evTodo/v76Fv\nYKBr7//3+kp2dvYt16betm7dOp/Kdfk5X9M0m0zT3CkpSdKfdnV/f+nKZKrWcLhy5Yq1LigoSCNH\njrSWW++xtnLtoUVFRWnYsGEKDw+iAAAgAElEQVQe9ZaXl7u9mMIfw7pXr17Vu+++a03mGjJkiGbM\nmGFtdx3y7cz48eO99px7ou2XoI7wzC+Agaonjxo5dYvc83U4HJo4caK1vHv3bl27ds2tTHx8vBVS\nGRkZ2rZtm86ePauKigpFRkZKkh5//HEdOnRIDQ0NbrN1TdN0G8YeMmSIVqxYoQsXLujEiRMqKSlR\nXV2doqKiNH/+fKtccXGxX863rKxM+fn51peIOXPmKCcnR42NjW5DvqWlpdq7d6/H/vPmzVN0dLR1\nDzw313POXHp6utcQzcvL63Co2PVL0Pnz5637za7uuusuBQUFKTIyUqmpqTp9+nTnJw0A/YhP4WsY\nxlBJSyR9KKlG0h2SnpT0J/5rmu9cg7K2tlbbtm1zG4aVWnqyU6dOlcPhcPtH/7333tOTTz6poKAg\nhYaGaubMmR71b9261ePVlFLLsHJ7Q8t1dXXaunVrL5yddzt37tTkyZMVEBCgiIgITZs2TXv37nUb\n8s3Ly/MarEOGDNGcOXMktYSltzJjx451e1FIq+Li4nbD1+FwuE302rdvnwoKCjzKjRo1yvqylJWV\nRfgCGHB8HXY21TLEXCzpuqT/K+kvTNPc5K+GdYVr4Jw4ccIjeKWWMCwsLLSWXd9L/MorrygnJ0dl\nZWVqaGhQU1OTKioqdOTIEW3YsEG7du1yq6u4uFjvvPOOcnJydPHiRVVUVKixsVENDQ0qKytTTk6O\nXnnlFV2+fNlPZ9zS+z169Ki1PGfOHI0cOdKtt+q63ZXr+qSkpF6blT1+/HiFhoZKkhobG9t9kYbr\no1Hjxo3r9aFvALjVGb3xusX2JCYmmqtXr/Zb/QCA9t1qk5sGwoQrwzByTdOc3lm5fvnDCgAA3MoI\nXwAAbEb4AgBgM8IXAACbEb4AANiM8AUAwGaELwAANiN8AQCwGeELAIDNCF8AAGxG+AIAYDPCFwAA\nmxG+AADYjPAFgH4oPDy8r5uADjj9fYD+/vNRnRkIP6HVkYF+/hLXQOIaSFwDuKPnCwCAzQhfAABs\nRvgCAGAzwhcAAJsRvgAA2IzwBQDAZoQvAAA2I3wBALCZYZqm3ypPTEw0V69e7bf6AeDbKDw8XGvW\nrOnrZthuILxoxDCMXNM0p3dWjp4vANisqqqqr5uAPkb4AgBgM8IXAACbEb4AANiM8AUAwGaELwAA\nNiN8AQCwGeELAIDNCF8AAGxG+AIAYDPCFwAAmxG+AADYzNnXDegtmZmZWrp0qbV8+vRpbdy40a3M\nj3/8Y0VHR0uSPvzwQ+Xm5nrs583Zs2e1YcMGffe731VWVpbPbdqxY4c+//xzPf3000pJSZEkHTx4\nUJs2beqw7dnZ2dZn133b8/777ysvL0+StHDhQi1atMijTH19vW7cuKHCwkLt2rVLFRUVbts7a2N7\nkpOTtWrVKrd1L730kkpLSz3Ktm1bbm6uPvzwQ7cyri9d37hxo06fPu113+bmZjU1Nam2tlY3btxQ\ncXGx9u/f7/W4khQREaF58+YpLS1NkZGRkqSamhpVVlbqypUrOnr0qE6ePOnTOQNAT/Wb8G0rLS1N\nI0eO1Llz5/q6KbeEoKAgxcXFKS4uTunp6XrllVd08+bNHtfr7ctIVlaWPvvsM5/23bVrl65fv97l\n4wYEBCggIECBgYGKiIhQUlKSZs2apa+++kqfffaZXH+tKzo6Ws8884zCw8Pd6ggMDFRkZKSGDx8u\nh8NB+AKwTb8NX0lasmSJ/uu//qtL+7z22mse6+rq6iRJX375pfbv32+tT0hI0D333GMtv/32226B\nduPGja42uUMnT57Ul19+6bH+6tWrXstXVlbqnXfekdPpVGpqqubNmydJGjRokLKysrRz584etcfp\ndCo9Pd1j/eTJk7VlyxZ19nOVDodDixYt0nvvvdel47qe15AhQ5SVlaWkpCRJ0uzZs+V0OvXxxx9b\n5RcuXGgF7+XLl/XVV1+poqJCgwYNUmxsrMaOHdtpWwGgN/Xr8B0xYoTGjBnTpR5NUVFRu9uuXbum\na9euWcsBAe63zC9evNjrgeuqqqqqw/a11dTUZJUvLCzU2LFjNXToUElSVFRUj9szYcIEhYSESGq5\nbiEhIYqLi1NERITS0tJ06tSpTuuYNGmSdu3apStXrvh83LbnlZubq/vvv1/Tpk2TJM2YMUN5eXm6\ncOGCJGn48OHWvtu3b9eJEyfc6tuxY4eCgoJ8Pj4A9FSXJ1wZhjHGMIxawzA2dl66b1RXV1u9wcWL\nF/dxa25Nbe/5dkdmZqb1OT8/X/n5+dZyZ/fGy8rKVFNTo4CAgF75b7R582bV1tZ6bZvr+vnz52vs\n2LHWl4ZW9fX1PW4DAPiqOz3ff5f0dW83pDc1Nzdrx44dWrZsmRISEpSenq4jR474tK/rhJ9Wn3zy\nifbu3dsrbcvKyurSpC1f9n3hhResoXFXDodDycnJcjqdGjVqlNXrra2t1cGDB7vVhlaRkZEaNWqU\npJaeaEFBgYKCgrRkyRJJ0rhx4xQSEuIWfK5qa2uVl5en22+/XePHj9fw4cOtnmp3NDQ0qKioSGPG\njJEkJSYmWttOnjyp5ORkSVJSUpKefPJJSS0jGefOnVNeXh5zAwDYqks9X8MwnpBULmmrf5rTew4f\nPqySkhJJLb1fwzD6uEX2i4iI0KpVq7RixQrNnz9fUsss8Ndee02VlZU9qjsjI8Madj99+rSqq6tV\nXl6u8+fPS2q5Hzxp0qQO69i7d691j7w1tHuipqbG+uzas921a5fXL19DhgzRlClTtHLlSt199909\nPj4A+Mrnnq9hGJGS/k7S7ZJ+4LcW9aLt27friSeeUGxsrNswZEe8Tbjqzmzc9nibNDVmzBgrHLu6\nr9S1IdOEhASFhYX5XL49bYecXT+PGDHCKpOTk9NuHQ0NDdq5c6fuvvtupaamdvpIVWdcz8u1x93c\n3Kx33nlHCQkJmjBhgpKTk5WYmOh2n3fmzJnKz8/vUe8bAHzVlWHnv5f0S9M0izrqRRqG8Zyk56SW\nf+j70vHjx1VcXKykpCQtXLhQDoej0326MqGpO7xNmhoyZEi39+1IeXm51q9fr8jISD3wwAMaPXq0\nwsLC9Pjjj+vFF19UdXV1l9reKikpSbGxsdbysmXLtGzZsnbLlZWVtVtXTk6OZs+eraioqB71foOC\ngqyhZall8ltbly5d0qVLlyS1DMmPHz9eS5culdPptNpL+MIurs/zDyQD9bzb8il8DcPIknSHpCmd\nlTVN81VJr0pSYmJinz+/sW3bNq1YscJ6ucZAVFFRoXfffVc/+tGPFBISotDQUC1YsECffPJJt+rr\nyj3rzMxMbd3a/l2KpqYmff7553rwwQfdwrOr7r77bgUHB1vLrS8dkVqe+T537pwaGxvdjltQUKCF\nCxcqLi5OkgbkrQn0HW/zS/q77Ozsfn/e69at86mcrz3fRZJSJJ3/4z9QgyQ5DMNIN01zatebZ5/C\nwkIVFhZak4M64y0Ampubb4keUXh4uNf2VVZWqry8vMN9a2pqtG/fPi1YsECSNHXqVO3cudPrizYS\nEhJ0++23e6w/f/68zpw5o4kTJ1rrdu/e7fb4lSTFx8drxowZklruDW/btq3D52gPHjyouXPnKiYm\npsNzaNU6kczhcCgmJsbtOV9J+vrrr93+ey1YsEBDhw7VsWPHdP78eZWXlysgIEBjx461glfy/6gH\nALTyNXxflfRrl+U1agnjP+3tBvnDtm3b9IMf+Habuu2rEqWW+4f/9E//1NvN6rIxY8ZYs3ld7dmz\nR5s3b+50/z179mjmzJkKDg5WYGCg5s6d63W/+Ph4xcfHe90/ODjYmsxUW1urbdu2qampya1ccHCw\npk6dKofDocjISKWmplqvifTGNE1rdrovWieSedP6hqu2QkJCOpxpfujQoVviCxaAgcGn2c6maVab\npnm59U/STUm1pml6f5HuLaa4uFjHjx/v62b0uZqaGrcJUNOmTevy5CvXiVYnTpzwCF6p5Y1ghYWF\n1rIvw9SHDx/W5cuXfW6HaZpqbGxUZWWliouLtWfPHr300kv69NNPPXrZH330kbZs2aKTJ09azxc3\nNzerurpahYWF2rRpU5ffsgUAPWH487V6iYmJ5urVq/1WPwB8W/X3e5/eDIR7voZh5JqmOb2zcvyk\nIAAANiN8AQCwGeELAIDNCF8AAGxG+AIAYDPCFwAAmxG+AADYjPAFAMBmhC8AADYjfAEAsBnhCwCA\nzQhfAABsRvgCAGAzwhcAAJsRvgBgs/Dw8L5uAvqY098H6O+/3diZgfD7lR0Z6OcvcQ0kroHENYA7\ner4AANiM8AUAwGaELwAANiN8AQCwGeELAIDNCF8AAGxG+AIAYDPCFwAAm/n9JRvZ2dn+PsQtb6Bf\ng4F+/hLXQOr/1yA8PFxr1qzp62bgW4KeLwD0gqqqqr5uAr5FCF8AAGxG+AIAYDPCFwAAmxG+AADY\njPAFAMBmhC8AADYjfAEAsBnhCwCAzQhfAABsRvgCAGAzwhcAAJv5/YcV7JKZmamlS5d2WObs2bPa\nsGGDoqKi9Bd/8Rce25uamlRVVaVLly4pNzdXJ0+ebLeu5ORkrVq1ym3dSy+9pNLSUo+yCxcu1KJF\ni6zl3Nxcffjhh25l1q5da33euHGjTp8+7bY9ICBAkyZNUnp6uhISEhQWFqaGhgZVVlaqqKhI+fn5\nOnfunCRp5MiRWrlyZbttl6Ty8nKtX7++wzIAAP+g5+vC4XAoMjJS48aN05/8yZ9oypQp7ZbNysry\naV17+w4ePNjndg0ZMkTPPfecHnroIY0bN06RkZFyOp0KDQ3V0KFDNW3aND3xxBM+1wcA6Fv9pufb\n1muvveaxrq6uzmvZP/zhD7p8+bIGDx6sJUuWKDIyUpI0d+5cHThwwKO80+lUenq6x/rJkydry5Yt\nMk2zw7Y5HA4tWrRI7733XqfnER4erhUrVigqKkqS1NDQoNzcXJ05c0aNjY0aPHiwxo0bp+Tk5Hbr\nePvtt3Xz5k23dY2NjZ0eGwDgH/02fIuKinwuW1JSovPnz+v8+fMKCwvTXXfdJUlW4LU1YcIEhYSE\nWMcJCQlRXFycIiIilJaWplOnTnV6zEmTJmnXrl26cuVKh+UWL15staOpqUkbN27U+fPnre2FhYXa\nv3+/hg4d2m4dFy9e1I0bNzptEwDAHj4POxuGscMwjFrDMG7+8e+4Pxt2K6ioqPC6PjMz0/qcn5+v\n/Px8a7mzoeeysjLV1NQoICBAixcv7rBs633eVocOHXILXledhTgA4NbR1Z7v86Zp/qdfWtLLXCcw\ntfrkk0+0d+9ej/Xx8fEyTVPR0dGaNWuWtd5b2cjISI0aNUpSS0+0oKBAQUFBWrJkiSRp3LhxCgkJ\nUW1trdd21dbWKi8vT7fffrvGjx+v4cOH68KFC17LxsTEKDg42FpuOwnLV94ml+3Zs0ebN2/uVn0A\ngJ5hwpWke+65R9///vf10EMPKTIyUhUVFdq0aZP27dvnUTYjI0MBAS2X7fTp06qurlZ5ebnVI3U6\nnW69VW/27t1r3YNtDW1vWoe2W1VXV3fpvAAAt6au9nx/ZhjGC5KOS/qJaZo72hYwDOM5Sc9JUkJC\nQo8b2F3eJlxdv37dp30HDRrU7j3UtkPOrp9HjBhhlcnJyWm3/oaGBu3cuVN33323UlNTlZKS4rVc\n295zWFiYT+1vy9uEq8rKym7VBaB92dnZPdo+EHANWnQlfP9a0hFJ9ZKekPR7wzCyTNN0Gws1TfNV\nSa9KUmJiYsfTfv2oKxOuXn/9dV24cEFTp07VPffco4CAAM2ePVulpaVus52TkpIUGxtrLS9btkzL\nli3zqK+1XFlZWbvHzMnJ0ezZsxUVFdVu7/fq1auqq6uzhp5TU1NVUFDg83m1YsIVYA9vt7taZWdn\nd7h9IBgI12DdunU+lfN52Nk0zb2maVaapllnmuYGSbsk3du95t16GhsbtW/fPh06dMhat2TJEjmd\n33w/8fU5Xsm9h+xNU1OTPv/8c0lq9zGh5uZmt951RkaGkpKSvJaNi4vzuW0AgL7Vk0eNTElGbzXk\nVvH5559r0qRJCggI0KBBgzR9+nTt2bNHDodDEydOtMrt3r1b165dc9s3Pj5eM2bMkNQSlNu2bevw\nmd+DBw9q7ty5iomJabfMjh07NGbMGEVFRcnpdGrFihXKyclxe8537NixGjFihH7+8597rSMxMdF6\ndtlVcXFxp88kAwB6n0/haxhGtKSZkj6X1CjpcUkLJHlOo/2Wu3btmgoKCjR58mRJ0pw5c/T111+7\nPdtbW1urbdu2qampyW3f4OBgTZ061XpTVmpqaoczlE3T1I4dO7wOXbeqqqrSG2+8occee0zx8fEK\nDAzU7NmzNXv2bLdy7c2ulqTHHnvM6/oXXnih3RePAAD8x9dh50BJ/yCpVFKZpD+XtNQ0zX75rO+X\nX35p9QgjIiI0bdo0t2HkEydOeASv1PIGrcLCQmvZl2Hqw4cP6/Llyx2WuXbtml599VW99957On78\nuCoqKtTY2Kja2lpduXJF+/fv129+8xtfTw8A0McMfw47JiYmmqtXr/Zb/QBwK2HCVccGwjUwDCPX\nNM3pnZXjOV8AAGxG+AIAYDPCFwAAmxG+AADYjPAFAMBmhC8AADYjfAEAsBnhCwCAzQhfAABsRvgC\nAGAzwhcAAJsRvgAA2IzwBQDAZoQvAAA2I3wBoBeEh4f3dRPwLeL09wH6+283dmYg/H5lRwb6+Utc\nA4lrALRFzxcAAJsRvgAA2IzwBQDAZoQvAAA2I3wBALAZ4QsAgM0IXwAAbEb4AgBgM7+/ZCM7O9vf\nh7jlDfRrMNDPXxp41yA8PFxr1qzp62YAtyx6vgB6XVVVVV83AbilEb4AANiM8AUAwGaELwAANiN8\nAQCwGeELAIDNCF8AAGxG+AIAYDPCFwAAmxG+AADYjPAFAMBmhC8AADbz+w8r9IXU1FRlZGQoKSlJ\ngwYNksPhUFVVlW7evKmioiKdOHFChYWFkqSFCxdq0aJFHdZ38OBBbdq0SZI0cuRIrVy50qNMY2Oj\nbt68qQsXLmjPnj0qLi522972OI2NjfrFL37h8Q7cGTNm6N5773Vb94tf/EI3btzwOOb8+fO1ZMkS\na7myslL/8i//ItM0Pco+/fTTSklJsZZ/97vf6fDhw9Zy2/P6h3/4B8XGxurZZ5+Vw+GQJH355Zfa\ntm2bW71xcXFavXq1VWbXrl3asmWLx/EBAN/oVz3fsLAwLV++XE899ZQyMzMVExOj4OBgOZ1ORUVF\nafjw4Zo1a5ZWrFhhhUVvcTqdio6O1sSJE/X9739fqampnZafNm2ax/oZM2b4fMzMzEy35YiICI0e\nPdqnfRctWiTDMDosU1JSop07d1rLc+bMUXx8vFuZBx980LqWZWVl2r59u0/HB4CBrN/0fB0Oh5Yv\nX67ExERrXUFBgY4dO6abN28qMDBQQ4cO1ZgxYzRy5EivdVRWVuqdd97xWN/RL7S8/fbbqq6uVlxc\nnO644w4FBwcrICBAc+bM0ZkzZzps8/Tp07Vz5041NzdLktLS0hQXF+fL6So5OVkxMTEe6zMzM3Xy\n5MlO94+JidGUKVO0f//+Dst98cUXGjdunIYNGyaHw6EHH3xQ//mf/ynTNDVr1iwlJSVJkpqbm7Vp\n0yY1NTX51H4AGMj6TfjOmjXLLXg/+OADHThwwK3MyZMntWvXLsXHx1uB56qpqUlFRUVdOu7Fixd1\n48YNnTt3TnFxcbrtttskSVFRUe3uU1tbq5CQEEVERGjChAkqKCiQJGvf1u0dycrKsj4fPHhQGRkZ\nCggI0Lhx4xQSEqLa2tpO275gwQLl5eV1GJitofrMM8/I4XAoMTFRs2fP1pEjR7R48WKrnLehdgCA\nd10adjYM4wnDMI4ahlFlGMZpwzDm+6thXeU6BHv27FmP4HVVUlLi9b5ob6qoqGh3W1lZmRVUrYE7\nePBgjRkzRlJLmHbE6XQqPT3dWt69e7fOnj1rbZs0aVKH+7d+wYiKivJpmPvy5ctuw8+LFi3SsmXL\nFBQUZJ1P23vBAID2+dzzNQzjTkn/JOlxSfskJfirUV3ldDrdhmtPnTrltn3YsGEKDAx0W1dRUeEx\niSk6Olpr1671qP/Xv/61jh8/7vXYiYmJio6OVkxMjDIyMiRJpmlq7969Hbb566+/VlJSkkaMGKFh\nw4YpKytLhmGovr5eBw8e1KxZs9rdd8KECVbP+PLlyyotLVV+fr51nzkrK0s5OTnt7n/u3DnV19cr\nLS1N8+bNU25ubodtldyHnwMDAxluBoAe6Mqwc7akvzNNc88fly/4oT3dEhoa6rZcXV3ttvzQQw9p\n6NChbut27typrVu39vjYjz32mNtyWVmZPvvsM504caLD/Q4fPqw777xTgwYN0rx585SWliZJOnTo\nUKdDxq69/EOHDkmSjhw5onvvvVeBgYEaPny4YmNjVVZW1m4d27ZtU1pamsLDwzVr1iydP3++w2O2\nHX5uxXAzAHSdT+FrGIZD0nRJHxiGcUpSiKT3Jf2VaZo1bco+J+k5SUpIsKdz3DaswsLCulVPexOu\nSktLfa5j8ODBGjJkSKflmpubtX//fi1YsEATJ0601u/bt6/D/SIiIjRq1CirjtbHherr63XixAmr\nrqysrA4f+bl48aKOHj2qCRMmaM6cOT6d4+XLl7V//35rqLq6uprZzWhXdnZ2h8sDEdeAa9DK155v\nvKRASY9Imi+pQdImST+V9BPXgqZpvirpVUlKTEz0743VP2poaFBZWZliY2MltTznu2vXLmv7yy+/\nLMnzWde2ujPh6he/+IVqa2s1b948zZs3Tw6HQ9/5zndUUlJiPUvcnpycHM2dO9fqSZ45c0alpaUd\nTtbKzMxUQEDLrfqAgAD95V/+pddykydP1tatWzu8t719+3ZrgtacOXM6O1VJ7jO/6+vr1djY6NN+\nGHhcb+FkZ2d7vaUzkHANBsY1WLdunU/lfJ1w1dq7/TfTNC+Zplkm6f9JureDfWzlOkkpNTXVrTfp\nb3V1ddq6davb0O1dd93V6X6VlZU6evSotdxZr1fyfLa3PZGRkZ0+a1xaWmr1nJOTk32qFwDQcz71\nfE3TvG4YRrEkW3qy3bF3715NmjRJw4YNkyQ9/PDDGj16tE6cOKHq6mqFhYUpMjKywzocDofXEKqv\nr1dJSUmnbdixY4dWrFghqWWS1/jx43Xs2LEO9/niiy9UVlam5ubmTu8TJyUlWb37pqYmffLJJx49\n2wkTJlj3j7OysnT69OlO2zxx4sRef+kIAKB9XZlw9V+S/twwjE/UMuz8F5I+9EuruqGxsVEbN27U\nI488opSUFAUEBCgrK8vteVhX3mbnRkREaNWqVR7rL1++rFdeeaXTNhQWFqqoqMgK8AULFnQavqWl\npfr88887rVtyf7a3sLDQ64zmiooKK3zHjRun4OBg1dXVtVvn9evXdfDgQa9v2wIA+EdXnvP9e0lf\nSzoh6aikA5L+0R+N6q6qqipt2LBBb731lg4fPqzr16+roaFBTU1NqqqqUlFRkfbs2aM33nhDO3bs\n8EsbvvjiC+tzQkKCxo4d2yv1OhwOt2d7XYerXZ05c8aagBYYGNjpM7+S9Pnnn6uhoaFX2gkA6Jzh\nz5dNJCYmmqtXr/Zb/QBuXUy4csc1GBjXwDCMXNM0p3dWrl/9sAIAAN8GhC8AADYjfAEAsBnhCwCA\nzQhfAABsRvgCAGAzwhcAAJsRvgAA2IzwBQDAZoQvAAA2I3wBALAZ4QsAgM0IXwAAbEb4Auh14eHh\nfd0E4Jbm9PcB+vvPR3VmIPyEVkcG+vlLXAMAnuj5AgBgM8IXAACbEb4AANiM8AUAwGaELwAANiN8\nAQCwGeELAIDNCF8AAGzm95dsZGdn+/sQt7yBfg0G+vlLXb8G4eHhWrNmjZ9aA6Cv0fMFbkFVVVV9\n3QQAfkT4AgBgM8IXAACbEb4AANiM8AUAwGaELwAANiN8AQCwGeELAIDNCF8AAGxG+AIAYDPCFwAA\nmxG+AADYjPAFAMBmfv9VI7tkZmZq6dKl1vLrr7+ulStX+rx/eXm51q9f77Zu5MiRHnW8+OKLunr1\nqsf+ixcv1oIFCyRJ165d07/92795Pc59992n6dOnS5IaGhr08ssv6/r1625l7rnnHt12221WmVde\necXrMQEA3070fDuQlZXl07qu+PTTT1VeXi5JCgwM1AMPPOC2PSkpyQpnSdq+fTvBCwD9TL/p+bZ1\n+fJlvfbaa27rHn30UUVEREiSDhw4oAMHDljbGhsb3coGBgZqwoQJHvVmZGRo69at3W5XQ0ODPvjg\nA61YsUKSNGrUKE2ZMkUHDhxQQECAHnzwQQUEtHwnKioq0ldffdXtYwEAbk39Nnzr6upUVFTktq6p\nqcn6fOPGDY/trtLT0xUcHCxJOnfunAYNGqSYmBhFRkYqNTVVZ86c6XbbCgsLlZOTY/Vw77zzTp08\neVLTp09XXFycpJaQ3rRpU7ePAQC4dfk07GwYxs02f02GYXi/qdlPZGZmWp/z8/OVn59vLfd06FmS\nPvvsM2v4OTQ0VI8++qjmzZtnbd+xYwfDzQDQT/kUvqZpDmr9kxQvqUbSO35tWR+KiopSSkqKpJbh\n6IKCArfwHT9+vNUr7q76+np98MEH1vKIESPkcDgkScXFxQw3A0A/1p0JV49IuiLpy15uyy0jMzNT\nhmFIkk6dOqXa2lpdu3ZNxcXFklruB0+cOLHHxyksLFRubq7butbhZtM0e1w/AODW1J17vk9LesNs\nJx0Mw3hO0nOSlJCQ0IOm9Z22Q86un5OSkqwy+/fv7/GxPv30U02ePFlBQUGSpH379qmsrKzH9eLb\nLzs7u6+b0Kv62/l0B9eAa9CqS+FrGMYISQsl/aC9MqZpvirpVUlKTEz81nXfRowYoSFDhljLjz76\naIflrl271qPj1dfXqzv3eggAAAwZSURBVLGx0QrfqqqqHtWH/mPt2rV93YRek52d3a/Opzu4BgPj\nGqxbt86ncl0ddl4haadpmoVdbdC3RVcmU7n2kAEA8FVXh51XSHrBHw25FTidTqWnp1vLO3futGYk\ntxo2bJj1iFBmZqa2b9/uUU9oaKhuv/12j/UVFRX6+uuve7nVAIBvG5/D1zCMOZKGqx/PcnZ9trem\npkbbt29Xc3OzW5nQ0FBNmTJFDodDUVFRGjVqlAoLCz3KuD421OrixYuELwCgS8POT0t61zTNSn81\npq+5DiMfP37cI3illlA+d+6ctdwbz/wCAAYWn3u+pmmu9mdDeiovL095eXkdlmn7wwlt/epXv/Lp\nWN7Kbd++3esQtC9+/vOfd2s/AMC3Ez+sAACAzQhfAABsRvgCAGAzwhcAAJsRvgAA2IzwBQDAZoQv\nAAA2I3wBALAZ4QsAgM0IXwAAbEb4AgBgM8IXAACbEb4AANiM8AVuQeHh4X3dBAB+5PNPCnbX2rVr\n/X2IW1p2dvaAvgYD/fwlrgEAT/R8AQCwGeELAIDNCF8AAGxG+AIAYDPCFwAAmxG+AADYjPAFAMBm\nhC8AADYjfAEAsBnhCwCAzQhfAABsRvgCAGAzwhcAAJsRvgAA2IzwBQDAZoQvAAA2I3wBALAZ4QsA\ngM0M0zT9V7lhVEo67rcDfDvESirr60b0oYF+/hLXQOIaSFwDaWBcg5GmacZ1Vsjp50YcN01zup+P\ncUszDCNnIF+DgX7+EtdA4hpIXAOJa+CKYWcAAGxG+AIAYDN/h++rfq7/22CgX4OBfv4S10DiGkhc\nA4lrYPHrhCsAAOCJYWcAAGxG+AIAYDPCFwAAm/kcvoZh/JlhGIWGYdQahpFrGMb8Tsov/GO5WsMw\nzhiG8f/1tM6+1tvXwDCMdYZhmG3+Lvv3LHqmK9fAMIwEwzD+2zCMY4ZhNBmG8Xo75ZYZhnHEMIy6\nP/7fh/x2Ar2gt6+BYRgrvfzv4P9v79yDrarqOP75Klg20B8QeDNJIDG0yckekpQylA8Mx0RNaIby\nBuQwND6mpww2WKnIGCX28hUm4KiTljj0EKyUjFfo+EwRgUsDBgo6ykPhir/+WOs4m80+9557ztnn\n3HvO7zOzZt+91m//1l6/87vnt9c6a69lkt6ba0MqoIs2OE/SEkmvSNopaZWkczLkGtkPOrVBE/jB\nKEnLJe2Q9Gb8n/huhlyP8oOyMbNOEzAeaAe+CRwH/ALYBXy4iPwQYHeUOy5e1w6cX67OeqecbHAV\n8DzQkkgD6t3WKtpgMHAj0AosB36XIXMy8DYwI+qcEc9H1Lu9NbRBa/SVpB+01LutVbTBXOAK4CTg\nGGAmsB84pYn8oBQbNLoffAqYAHwsfj9OjO2d1lP9oCL7lWjkVcCtqbx1wKwi8rOBdam824AV5eqs\nd8rJBlcBz9S7bXnZICW3uEjguQdYmsp7CLir3u2toQ1agV31blstbJCQXw3MaUY/6MAGzegHf0h+\nxj3NDypJnQ47SzqM8MSyJFW0BBhZ5LKTM+QfBD4tqXeZOutGHjZI5A2VtCUO3dwtaWhVbrrK5PiZ\nFbNTo/hBqRwuaZOkzZIWSzqxQn25UEUb9AVeS5w3ox+kbQBN5AexbSOBRxLZPcYPKqWU33w/ABwK\nbEvlbyMMi2TRUkS+V9RXjs56kocNIDw5tgJnEYZuWoDlkvpXfstVJ6/PrJidGsUPSmEtMAn4MvBV\n4C3gX5KGVaAzLyq2gaRvAUcBCxLZTeUHRWzQFH4QHyz2AmuAX5vZTYninuQHFdGVjRXSq3EoI68z\n+UK+OpDpzqt+VNMGmNlfDiiUVgIbgIuAn5V/m7mSx2fW6H7QsTKzFcCKd5VJy4EngEuAS8vVmzNl\n2UDS+cD1wAQz21QNnXWkqjZoIj84BegDfBaYLWmjmSUfQnqaH5RFKcF3O2FiQPrJYyAHP6EU2FpE\n/m1gB8GYXdVZT/KwwUGY2S5JzwLd8Um3HBuUQjE7NYofdBkz2y9pDQ3mBzHoLAC+bmYPpIqbwg86\nscEBNKofmNnG+OfTko4gzH0pBN+e5AcV0emws5ntAx4DTk8VnU6YvZnFCuC0DPk1ZtZeps66kYcN\nsi6IrxQMB/5X/t3mQ46f2YocdOZCrfxWkoATaCA/kHQhsBBoNbN7M0Qa3g9KsEFavuH8IINDgPck\nznuMH1RMiTPSxgP7gCmE6d9zCVPKj47l84H5CfnCazY3RPkp8fr0q0ZFdXa3lJMNfgqMirIjCLNh\n32gUG8S8T8S0DHgg/n18onwkYTRgOuHBYzrh9YVu+WpBTjaYCZwJDI1l86INTqp3e6thA8LrJe3A\nZRz4Gk2/ZvGDEm3Q6H5wCXA2oSc/DJgcv++u66l+UJH9umDoaUAbsJfwxHNqouxh4OGU/Cjg8Si/\nEZjaFZ3dMVXbBsDdwEvRgbcA95H4Uu6OqQwbWEZqS8lcQHjfeR/wHHBevdtZSxsAPwc2RX0vE2Z3\nnlzvdlbLBvE8ywZpOzWsH5Rigybwg8uBZwmdktcJ343TgEN6sh+Um3xXI8dxHMepMb62s+M4juPU\nGA++juM4jlNjPPg6juM4To3x4Os4juM4NcaDr+M4juPUGA++juM4jlNjPPg6TpXI2Ax9n6T1kq5N\nbogu6YuSFsayN+PxN5IGdqGucyUtk/Ry1LFJ0v2SxuTTOsdxqokHX8epPl8hbI02lrBQwnTCQvoF\npgL9gauBMcAs4BxgpaQ+nSmXdCnwR8LeqZNjPVfH4i9UpwmO4+SJL7LhOFVCUitwOzDMzF5M5C8F\nPgf0MbN3JA0ws1dS155K2Nd0spnN66Se/wKPmdm4jLJDzOydylvTMXHd4d4W1vh1HKeLeM/XcfLn\nceBw4j7O6cAb+Xc8fqgEff0Iu78cRDrwShoiaYGkrZL2StogaW5KZqKkJyW9JWl7lP9gSqYtDpVP\nklRY+m9sLHufpNmSNsah9o2SZkjy7xfHKUJX9vN1HKc8BhPWss3cSjIyKh6fK0HfauAiSRuARWb2\nQpaQpCFRdg9h0f51wCDgjITMxcDNwD2E4fEjgWuBEZI+aWa7EipHExb8/xFh7eE2Sb0IQ+vHAz8B\nnibs0/pDwkPCd0poj+M0HT7s7DhVIjHsPBxYD/QFxgG3AJeb2S+LXNeX0PN9BzjBzN7upJ5jgXuB\nj8esHcBS4HYzW5KQmw+cBxxrZi9l6DmUsLHHf8xsdCL/88A/gcvM7MaY10bYV3WomW1NyH6NsHvN\nKDNblsifQQj4R5nZyx21x3GaER8Wcpzq8zxhG7RXgd8CN3cQeHsBdxGGmyckA6+kXqkkgNjTPZHQ\nW74GeIIQ5B+UdGVC/RnA4qzAG/koIaDemcw0s0cJu+uMSsmvTAbeyJgouzx5r8ASoDehF+w4Tgof\ndnac6jMO2AwMAL4NTJO0yszmJ4Xib6J3AKcBY83sqZSe9tT5aMI2bZjZfsL+wMuiriOBvwIzJf3K\nzF4jzKje3MF99ovHrM3atybK6UBuIHB0xr0W6N9B/Y7TtHjwdZzq80xhtrOkvwNPAddLus/Mdifk\nbiJsSH6Bmf0tQ89nUudri1VoZi9Juo2wofkwwm+92+l4Ater8diSUdYCrElXkyG3g7BX9YVF6mjr\noH7HaVp82NlxcsTM9gLfI/QQpxXyJc0BpgDfMLP7i1y7JpV2xmsHFalueDwWhoaXAGenZy4nWAts\nAyYkMyWNJPRmH+msfYTe9iBgV8b9rjGz7SXocJymwydcOU6VKPaebyxbTQhog4FLgeuAecCtKTWv\nmNn6Tup5HfgHYaGNjcD7gS8RFu/4vZmNj3KDCb3XnYQZzC8SesJjzGxilCnMdr4TWBjLrwHeAN6d\n7RwnXD1auC5xL72Bh4BjgDnAk8BhwEcIC4eca2Z7OmqP4zQjPuzsOLXhSsIrOVOBs2LepJiS3AG0\ndqLrB4Rg+2PgCGA/8AJwBXBDQcjM2iSNIKx+NYsw+3oLsCghc4ukPYTe+SJgF/Bn4Pup14wyMbN2\nSWfGui8GhgC7CbO9/0R4H9hxnBTe83Ucx3GcGuO/+TqO4zhOjfHg6ziO4zg1xoOv4ziO49QYD76O\n4ziOU2M8+DqO4zhOjfHg6ziO4zg1xoOv4ziO49QYD76O4ziOU2P+D11U2PD0LPSKAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112926978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a bar chart\n",
    "character = ('CANADA',\n",
    "             'US',\n",
    "             'GREAT BRITAIN',\n",
    "             'AUSTRALIA', \n",
    "             'NETHERLANDS',\n",
    "             'FRANCE',\n",
    "             'GERMANY',\n",
    "             'ITALY')\n",
    "y_pos = np.arange(8)\n",
    "type_character = [0.3273411319309155,\n",
    "                  0.320028139296918,\n",
    "                  0.31418039815233123,\n",
    "                  0.2715820837463585,\n",
    "                  0.2524743901759854,\n",
    "                  0.24338995186336407, \n",
    "                  0.19659568557898718,\n",
    "                  0.15968396438438126]    \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8, 8)\n",
    "\n",
    "for i, p in enumerate(character):\n",
    "    ax.text(s=p, x=0.02, y=i, color=\"w\", verticalalignment=\"center\", fontsize=18, fontweight='bold')\n",
    "barlist = ax.barh(y_pos, type_character, align='center')\n",
    "barlist[0].set_color('green')\n",
    "barlist[1].set_color('gray')\n",
    "barlist[2].set_color('gray')\n",
    "barlist[3].set_color('gray')\n",
    "barlist[4].set_color('gray')\n",
    "barlist[5].set_color('gray')\n",
    "barlist[6].set_color('gray')\n",
    "barlist[7].set_color('gray')\n",
    "\n",
    "# plt.yticks(y_pos, character)\n",
    "# plt.yticks(rotation=45)\n",
    "#plt.ylabel('Market')\n",
    "plt.xlabel('R2-Score', fontsize='16')\n",
    "#plt.title('In what market was the model performing the best?')\n",
    "ax.invert_yaxis() \n",
    "\n",
    "#plt.rc('axes', titlesize=16)     \n",
    "#plt.rc('axes', labelsize=14)    \n",
    "#plt.rc('xtick', labelsize=14)   \n",
    "#plt.rc('ytick', labelsize=12)\n",
    "#plt.rc('figure', titlesize=14)  \n",
    "\n",
    "plt.grid()\n",
    "ax.grid(color='grey', linestyle='-', linewidth=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
