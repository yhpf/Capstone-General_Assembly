{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model per Coutry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end I might need to do everything per country.<BR />\n",
    "And only use the stong countries (if any) to look at what mood the country and the artists are and the try to combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Position</th>\n",
       "      <th>Streams</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>40381</td>\n",
       "      <td>Bye Bye Bye</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>4r8lRYnoOGdEi6YyI5OC1o</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>gb</td>\n",
       "      <td>eu</td>\n",
       "      <td>hey, hey bye bye bye, bye bye bye bye  i'm doi...</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.00104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.656</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>24132</td>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>2017-12-23</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>it</td>\n",
       "      <td>eu</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>49766</td>\n",
       "      <td>Merry Christmas, Happy Holidays</td>\n",
       "      <td>*NSYNC</td>\n",
       "      <td>15coTBAzEN1bOeipoNDZAR</td>\n",
       "      <td>2017-12-24</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>it</td>\n",
       "      <td>eu</td>\n",
       "      <td>merry christmas and happy holidays merry chris...</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.003</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Position  Streams                       Track Name  Artist  \\\n",
       "0           0       177    40381                      Bye Bye Bye  *NSYNC   \n",
       "1           1       151    24132  Merry Christmas, Happy Holidays  *NSYNC   \n",
       "2           2        78    49766  Merry Christmas, Happy Holidays  *NSYNC   \n",
       "\n",
       "                       ID        Date  Year  Month  Day Country Region  \\\n",
       "0  4r8lRYnoOGdEi6YyI5OC1o  2017-10-05  2017     10    5      gb     eu   \n",
       "1  15coTBAzEN1bOeipoNDZAR  2017-12-23  2017     12   23      it     eu   \n",
       "2  15coTBAzEN1bOeipoNDZAR  2017-12-24  2017     12   24      it     eu   \n",
       "\n",
       "                                              Lyrics  Acousticness  Energy  \\\n",
       "0  hey, hey bye bye bye, bye bye bye bye  i'm doi...        0.0408   0.928   \n",
       "1  merry christmas and happy holidays merry chris...        0.1030   0.939   \n",
       "2  merry christmas and happy holidays merry chris...        0.1030   0.939   \n",
       "\n",
       "   Instrumentalness  Mode    Tempo  Valence  \n",
       "0           0.00104   0.0  172.656    0.879  \n",
       "1           0.00000   1.0  105.003    0.756  \n",
       "2           0.00000   1.0  105.003    0.756  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data_top10c_more_lyrics.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at each country individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gb', 'it', 'us', 'de', 'ca', 'nl', 'au', 'fr'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter by country and make 8 new data frames\n",
    "gb_data = data[data['Country'] == 'gb']\n",
    "it_data = data[data['Country'] == 'it']\n",
    "us_data = data[data['Country'] == 'us']\n",
    "de_data = data[data['Country'] == 'de']\n",
    "ca_data = data[data['Country'] == 'ca']\n",
    "nl_data = data[data['Country'] == 'nl']\n",
    "au_data = data[data['Country'] == 'au']\n",
    "fr_data = data[data['Country'] == 'fr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix a little bit with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group by ID, sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_data_groupbyID = gb_data.groupby('ID').sum()\n",
    "it_data_groupbyID = it_data.groupby('ID').sum()\n",
    "us_data_groupbyID = us_data.groupby('ID').sum()\n",
    "de_data_groupbyID = de_data.groupby('ID').sum()\n",
    "ca_data_groupbyID = ca_data.groupby('ID').sum()\n",
    "nl_data_groupbyID = nl_data.groupby('ID').sum()\n",
    "au_data_groupbyID = au_data.groupby('ID').sum()\n",
    "fr_data_groupbyID = fr_data.groupby('ID').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make 2 new columns for average Streams and average Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_data_groupbyID['avg_Streams'] = gb_data_groupbyID['Streams']/len(gb_data)\n",
    "gb_data_groupbyID['avg_Position'] = gb_data_groupbyID['Position']/len(gb_data)\n",
    "\n",
    "it_data_groupbyID['avg_Streams'] = it_data_groupbyID['Streams']/len(it_data)\n",
    "it_data_groupbyID['avg_Position'] = it_data_groupbyID['Position']/len(it_data)\n",
    "\n",
    "us_data_groupbyID['avg_Streams'] = us_data_groupbyID['Streams']/len(us_data)\n",
    "us_data_groupbyID['avg_Position'] = us_data_groupbyID['Position']/len(us_data)\n",
    "\n",
    "de_data_groupbyID['avg_Streams'] = de_data_groupbyID['Streams']/len(de_data)\n",
    "de_data_groupbyID['avg_Position'] = de_data_groupbyID['Position']/len(de_data)\n",
    "\n",
    "ca_data_groupbyID['avg_Streams'] = ca_data_groupbyID['Streams']/len(ca_data)\n",
    "ca_data_groupbyID['avg_Position'] = ca_data_groupbyID['Position']/len(ca_data)\n",
    "\n",
    "nl_data_groupbyID['avg_Streams'] = nl_data_groupbyID['Streams']/len(nl_data)\n",
    "nl_data_groupbyID['avg_Position'] = nl_data_groupbyID['Position']/len(nl_data)\n",
    "\n",
    "au_data_groupbyID['avg_Streams'] = au_data_groupbyID['Streams']/len(au_data)\n",
    "au_data_groupbyID['avg_Position'] = au_data_groupbyID['Position']/len(au_data)\n",
    "\n",
    "fr_data_groupbyID['avg_Streams'] = fr_data_groupbyID['Streams']/len(fr_data)\n",
    "fr_data_groupbyID['avg_Position'] = fr_data_groupbyID['Position']/len(fr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_data_sp = gb_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "it_data_sp = it_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "us_data_sp = us_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "de_data_sp = de_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "ca_data_sp = ca_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "nl_data_sp = nl_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "au_data_sp = au_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)\n",
    "fr_data_sp = fr_data_groupbyID.drop(['Unnamed: 0', 'Position', 'Streams', 'Year', 'Month', 'Day', 'Acousticness',\n",
    "                        'Energy', 'Instrumentalness', 'Mode', 'Tempo', 'Valence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column for ID so that I can merge on ID later\n",
    "gb_data_sp['ID'] = gb_data_sp.index\n",
    "it_data_sp['ID'] = it_data_sp.index\n",
    "us_data_sp['ID'] = us_data_sp.index\n",
    "de_data_sp['ID'] = de_data_sp.index\n",
    "ca_data_sp['ID'] = ca_data_sp.index\n",
    "nl_data_sp['ID'] = nl_data_sp.index\n",
    "au_data_sp['ID'] = au_data_sp.index\n",
    "fr_data_sp['ID'] = fr_data_sp.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop rows that are duplicates and keep only one row for each song (based on ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_data_per_song = gb_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "it_data_per_song = it_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "us_data_per_song = us_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "de_data_per_song = de_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "ca_data_per_song = ca_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "nl_data_per_song = nl_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "au_data_per_song = au_data.drop_duplicates(subset=['ID'], keep='first')\n",
    "fr_data_per_song = fr_data.drop_duplicates(subset=['ID'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop all columns that might change per song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_data_per_song = gb_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "it_data_per_song = it_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "us_data_per_song = us_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "de_data_per_song = de_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "ca_data_per_song = ca_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "nl_data_per_song = nl_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "au_data_per_song = au_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)\n",
    "fr_data_per_song = fr_data_per_song.drop(['Unnamed: 0', 'Position', 'Streams', 'Date', 'Year', 'Month', 'Day', 'Country',\n",
    "                                   'Region'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the 2 data frames with columns that may and may not change per song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_big_song = gb_data_per_song.merge(gb_data_sp, how='inner', on='ID')\n",
    "it_big_song = it_data_per_song.merge(it_data_sp, how='inner', on='ID')\n",
    "us_big_song = us_data_per_song.merge(us_data_sp, how='inner', on='ID')\n",
    "de_big_song = de_data_per_song.merge(de_data_sp, how='inner', on='ID')\n",
    "ca_big_song = ca_data_per_song.merge(ca_data_sp, how='inner', on='ID')\n",
    "nl_big_song = nl_data_per_song.merge(nl_data_sp, how='inner', on='ID')\n",
    "au_big_song = au_data_per_song.merge(au_data_sp, how='inner', on='ID')\n",
    "fr_big_song = fr_data_per_song.merge(fr_data_sp, how='inner', on='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop rows that have missing values in the Lyrics column**<BR />\n",
    "We can use dropna to drop all rows that has missing values (should mostly be the Lyrics column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clean = gb_big_song.dropna(axis=0, how='any')\n",
    "it_clean = it_big_song.dropna(axis=0, how='any')\n",
    "us_clean = us_big_song.dropna(axis=0, how='any')\n",
    "de_clean = de_big_song.dropna(axis=0, how='any')\n",
    "ca_clean = ca_big_song.dropna(axis=0, how='any')\n",
    "nl_clean = nl_big_song.dropna(axis=0, how='any')\n",
    "au_clean = au_big_song.dropna(axis=0, how='any')\n",
    "fr_clean = fr_big_song.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Turn the lyrics in the Lyrics column into string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "gb_clean['Lyrics'] = gb_clean['Lyrics'].astype(str)\n",
    "it_clean['Lyrics'] = it_clean['Lyrics'].astype(str)\n",
    "us_clean['Lyrics'] = us_clean['Lyrics'].astype(str)\n",
    "de_clean['Lyrics'] = de_clean['Lyrics'].astype(str)\n",
    "ca_clean['Lyrics'] = ca_clean['Lyrics'].astype(str)\n",
    "nl_clean['Lyrics'] = nl_clean['Lyrics'].astype(str)\n",
    "au_clean['Lyrics'] = au_clean['Lyrics'].astype(str)\n",
    "fr_clean['Lyrics'] = fr_clean['Lyrics'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make and run function for TextBlob on the Lyrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_func(lyrics):\n",
    "    try:\n",
    "        return TextBlob(lyrics).sentiment\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "gb_clean['pol_sub'] = gb_clean['Lyrics'].apply(sentiment_func)\n",
    "it_clean['pol_sub'] = it_clean['Lyrics'].apply(sentiment_func)\n",
    "us_clean['pol_sub'] = us_clean['Lyrics'].apply(sentiment_func)\n",
    "de_clean['pol_sub'] = de_clean['Lyrics'].apply(sentiment_func)\n",
    "ca_clean['pol_sub'] = ca_clean['Lyrics'].apply(sentiment_func)\n",
    "nl_clean['pol_sub'] = nl_clean['Lyrics'].apply(sentiment_func)\n",
    "au_clean['pol_sub'] = au_clean['Lyrics'].apply(sentiment_func)\n",
    "fr_clean['pol_sub'] = fr_clean['Lyrics'].apply(sentiment_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the pol_sub column into 2 new columns (Polarity, Subjectivity)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "gb_clean['Polarity'] = gb_clean['pol_sub'].apply(lambda x: x[0])\n",
    "gb_clean['Subjectivity'] = gb_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "it_clean['Polarity'] = it_clean['pol_sub'].apply(lambda x: x[0])\n",
    "it_clean['Subjectivity'] = it_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "us_clean['Polarity'] = us_clean['pol_sub'].apply(lambda x: x[0])\n",
    "us_clean['Subjectivity'] = us_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "de_clean['Polarity'] = de_clean['pol_sub'].apply(lambda x: x[0])\n",
    "de_clean['Subjectivity'] = de_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "ca_clean['Polarity'] = ca_clean['pol_sub'].apply(lambda x: x[0])\n",
    "ca_clean['Subjectivity'] = ca_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "nl_clean['Polarity'] = nl_clean['pol_sub'].apply(lambda x: x[0])\n",
    "nl_clean['Subjectivity'] = nl_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "au_clean['Polarity'] = au_clean['pol_sub'].apply(lambda x: x[0])\n",
    "au_clean['Subjectivity'] = au_clean['pol_sub'].apply(lambda x: x[1])\n",
    "\n",
    "fr_clean['Polarity'] = fr_clean['pol_sub'].apply(lambda x: x[0])\n",
    "fr_clean['Subjectivity'] = fr_clean['pol_sub'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop the pol_sub column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_clean = gb_clean.drop(['pol_sub'], axis=1)\n",
    "it_clean = it_clean.drop(['pol_sub'], axis=1)\n",
    "us_clean = us_clean.drop(['pol_sub'], axis=1)\n",
    "de_clean = de_clean.drop(['pol_sub'], axis=1)\n",
    "ca_clean = ca_clean.drop(['pol_sub'], axis=1)\n",
    "nl_clean = nl_clean.drop(['pol_sub'], axis=1)\n",
    "au_clean = au_clean.drop(['pol_sub'], axis=1)\n",
    "fr_clean = fr_clean.drop(['pol_sub'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a quick check of the entire data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1179 entries, 0 to 2381\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1179 non-null object\n",
      "Artist              1179 non-null object\n",
      "ID                  1179 non-null object\n",
      "Lyrics              1179 non-null object\n",
      "Acousticness        1179 non-null float64\n",
      "Energy              1179 non-null float64\n",
      "Instrumentalness    1179 non-null float64\n",
      "Mode                1179 non-null float64\n",
      "Tempo               1179 non-null float64\n",
      "Valence             1179 non-null float64\n",
      "avg_Streams         1179 non-null float64\n",
      "avg_Position        1179 non-null float64\n",
      "Polarity            1179 non-null float64\n",
      "Subjectivity        1179 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 138.2+ KB\n"
     ]
    }
   ],
   "source": [
    "gb_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1058 entries, 0 to 1694\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1058 non-null object\n",
      "Artist              1058 non-null object\n",
      "ID                  1058 non-null object\n",
      "Lyrics              1058 non-null object\n",
      "Acousticness        1058 non-null float64\n",
      "Energy              1058 non-null float64\n",
      "Instrumentalness    1058 non-null float64\n",
      "Mode                1058 non-null float64\n",
      "Tempo               1058 non-null float64\n",
      "Valence             1058 non-null float64\n",
      "avg_Streams         1058 non-null float64\n",
      "avg_Position        1058 non-null float64\n",
      "Polarity            1058 non-null float64\n",
      "Subjectivity        1058 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 124.0+ KB\n"
     ]
    }
   ],
   "source": [
    "it_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1073 entries, 0 to 1934\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1073 non-null object\n",
      "Artist              1073 non-null object\n",
      "ID                  1073 non-null object\n",
      "Lyrics              1073 non-null object\n",
      "Acousticness        1073 non-null float64\n",
      "Energy              1073 non-null float64\n",
      "Instrumentalness    1073 non-null float64\n",
      "Mode                1073 non-null float64\n",
      "Tempo               1073 non-null float64\n",
      "Valence             1073 non-null float64\n",
      "avg_Streams         1073 non-null float64\n",
      "avg_Position        1073 non-null float64\n",
      "Polarity            1073 non-null float64\n",
      "Subjectivity        1073 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 125.7+ KB\n"
     ]
    }
   ],
   "source": [
    "us_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1199 entries, 0 to 1984\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1199 non-null object\n",
      "Artist              1199 non-null object\n",
      "ID                  1199 non-null object\n",
      "Lyrics              1199 non-null object\n",
      "Acousticness        1199 non-null float64\n",
      "Energy              1199 non-null float64\n",
      "Instrumentalness    1199 non-null float64\n",
      "Mode                1199 non-null float64\n",
      "Tempo               1199 non-null float64\n",
      "Valence             1199 non-null float64\n",
      "avg_Streams         1199 non-null float64\n",
      "avg_Position        1199 non-null float64\n",
      "Polarity            1199 non-null float64\n",
      "Subjectivity        1199 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 140.5+ KB\n"
     ]
    }
   ],
   "source": [
    "de_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 947 entries, 0 to 1796\n",
      "Data columns (total 14 columns):\n",
      "Track Name          947 non-null object\n",
      "Artist              947 non-null object\n",
      "ID                  947 non-null object\n",
      "Lyrics              947 non-null object\n",
      "Acousticness        947 non-null float64\n",
      "Energy              947 non-null float64\n",
      "Instrumentalness    947 non-null float64\n",
      "Mode                947 non-null float64\n",
      "Tempo               947 non-null float64\n",
      "Valence             947 non-null float64\n",
      "avg_Streams         947 non-null float64\n",
      "avg_Position        947 non-null float64\n",
      "Polarity            947 non-null float64\n",
      "Subjectivity        947 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 111.0+ KB\n"
     ]
    }
   ],
   "source": [
    "ca_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1048 entries, 0 to 2037\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1048 non-null object\n",
      "Artist              1048 non-null object\n",
      "ID                  1048 non-null object\n",
      "Lyrics              1048 non-null object\n",
      "Acousticness        1048 non-null float64\n",
      "Energy              1048 non-null float64\n",
      "Instrumentalness    1048 non-null float64\n",
      "Mode                1048 non-null float64\n",
      "Tempo               1048 non-null float64\n",
      "Valence             1048 non-null float64\n",
      "avg_Streams         1048 non-null float64\n",
      "avg_Position        1048 non-null float64\n",
      "Polarity            1048 non-null float64\n",
      "Subjectivity        1048 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 122.8+ KB\n"
     ]
    }
   ],
   "source": [
    "nl_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 757 entries, 0 to 1486\n",
      "Data columns (total 14 columns):\n",
      "Track Name          757 non-null object\n",
      "Artist              757 non-null object\n",
      "ID                  757 non-null object\n",
      "Lyrics              757 non-null object\n",
      "Acousticness        757 non-null float64\n",
      "Energy              757 non-null float64\n",
      "Instrumentalness    757 non-null float64\n",
      "Mode                757 non-null float64\n",
      "Tempo               757 non-null float64\n",
      "Valence             757 non-null float64\n",
      "avg_Streams         757 non-null float64\n",
      "avg_Position        757 non-null float64\n",
      "Polarity            757 non-null float64\n",
      "Subjectivity        757 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 88.7+ KB\n"
     ]
    }
   ],
   "source": [
    "au_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1400 entries, 1 to 1800\n",
      "Data columns (total 14 columns):\n",
      "Track Name          1400 non-null object\n",
      "Artist              1400 non-null object\n",
      "ID                  1400 non-null object\n",
      "Lyrics              1400 non-null object\n",
      "Acousticness        1400 non-null float64\n",
      "Energy              1400 non-null float64\n",
      "Instrumentalness    1400 non-null float64\n",
      "Mode                1400 non-null float64\n",
      "Tempo               1400 non-null float64\n",
      "Valence             1400 non-null float64\n",
      "avg_Streams         1400 non-null float64\n",
      "avg_Position        1400 non-null float64\n",
      "Polarity            1400 non-null float64\n",
      "Subjectivity        1400 non-null float64\n",
      "dtypes: float64(10), object(4)\n",
      "memory usage: 164.1+ KB\n"
     ]
    }
   ],
   "source": [
    "fr_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the data into a train and a test set (with a test set of 25%, which is also default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_dep   = gb_clean['Valence']\n",
    "gb_indep = gb_clean\n",
    "gb_indep_train, gb_indep_test, gb_dep_train, gb_dep_test = train_test_split(gb_indep, gb_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "it_dep   = it_clean['Valence']\n",
    "it_indep = it_clean\n",
    "it_indep_train, it_indep_test, it_dep_train, it_dep_test = train_test_split(it_indep, it_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "us_dep   = us_clean['Valence']\n",
    "us_indep = us_clean\n",
    "us_indep_train, us_indep_test, us_dep_train, us_dep_test = train_test_split(us_indep, us_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "de_dep   = de_clean['Valence']\n",
    "de_indep = de_clean\n",
    "de_indep_train, de_indep_test, de_dep_train, de_dep_test = train_test_split(de_indep, de_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "ca_dep   = ca_clean['Valence']\n",
    "ca_indep = ca_clean\n",
    "ca_indep_train, ca_indep_test, ca_dep_train, ca_dep_test = train_test_split(ca_indep, ca_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "nl_dep   = nl_clean['Valence']\n",
    "nl_indep = nl_clean\n",
    "nl_indep_train, nl_indep_test, nl_dep_train, nl_dep_test = train_test_split(nl_indep, nl_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "au_dep   = au_clean['Valence']\n",
    "au_indep = au_clean\n",
    "au_indep_train, au_indep_test, au_dep_train, au_dep_test = train_test_split(au_indep, au_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)\n",
    "\n",
    "fr_dep   = fr_clean['Valence']\n",
    "fr_indep = fr_clean\n",
    "fr_indep_train, fr_indep_test, fr_dep_train, fr_dep_test = train_test_split(fr_indep, fr_dep, test_size = 0.25,\n",
    "                                                                            random_state=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in csv with stop words\n",
    "stop_words_df = pd.read_csv('./stop_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn the df to list\n",
    "stop_words = stop_words_df['colummn'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer (use in model 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "cvec = CountVectorizer(stop_words = stop_words, max_features = 1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(gb_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "gb_cvec = cvec.transform(gb_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df  = pd.DataFrame(gb_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "gb_indep_train_cvec = pd.concat([gb_indep_train.reset_index(drop=True), gb_df], axis=1)\n",
    "# transform X_test\n",
    "gb_cvec2 = cvec.transform(gb_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df2  = pd.DataFrame(gb_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "gb_indep_test_cvec = pd.concat([gb_indep_test.reset_index(drop=True), gb_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(it_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "it_cvec = cvec.transform(it_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df  = pd.DataFrame(it_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "it_indep_train_cvec = pd.concat([it_indep_train.reset_index(drop=True), it_df], axis=1)\n",
    "# transform X_test\n",
    "it_cvec2 = cvec.transform(it_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df2  = pd.DataFrame(it_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "it_indep_test_cvec = pd.concat([it_indep_test.reset_index(drop=True), it_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(us_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "us_cvec = cvec.transform(us_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df  = pd.DataFrame(us_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "us_indep_train_cvec = pd.concat([us_indep_train.reset_index(drop=True), us_df], axis=1)\n",
    "# transform X_test\n",
    "us_cvec2 = cvec.transform(us_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df2  = pd.DataFrame(us_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "us_indep_test_cvec = pd.concat([us_indep_test.reset_index(drop=True), us_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(de_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "de_cvec = cvec.transform(de_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df  = pd.DataFrame(de_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "de_indep_train_cvec = pd.concat([de_indep_train.reset_index(drop=True), de_df], axis=1)\n",
    "# transform X_test\n",
    "de_cvec2 = cvec.transform(de_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df2  = pd.DataFrame(de_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "de_indep_test_cvec = pd.concat([de_indep_test.reset_index(drop=True), de_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(ca_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "ca_cvec = cvec.transform(ca_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df  = pd.DataFrame(ca_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "ca_indep_train_cvec = pd.concat([ca_indep_train.reset_index(drop=True), ca_df], axis=1)\n",
    "# transform X_test\n",
    "ca_cvec2 = cvec.transform(ca_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df2  = pd.DataFrame(ca_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "ca_indep_test_cvec = pd.concat([ca_indep_test.reset_index(drop=True), ca_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(nl_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "nl_cvec = cvec.transform(nl_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df  = pd.DataFrame(nl_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "nl_indep_train_cvec = pd.concat([nl_indep_train.reset_index(drop=True), nl_df], axis=1)\n",
    "# transform X_test\n",
    "nl_cvec2 = cvec.transform(nl_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df2  = pd.DataFrame(nl_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "nl_indep_test_cvec = pd.concat([nl_indep_test.reset_index(drop=True), nl_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(au_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "au_cvec = cvec.transform(au_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df  = pd.DataFrame(au_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "au_indep_train_cvec = pd.concat([au_indep_train.reset_index(drop=True), au_df], axis=1)\n",
    "# transform X_test\n",
    "au_cvec2 = cvec.transform(au_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df2  = pd.DataFrame(au_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "au_indep_test_cvec = pd.concat([au_indep_test.reset_index(drop=True), au_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "cvec.fit(fr_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "fr_cvec = cvec.transform(fr_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df  = pd.DataFrame(fr_cvec.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "fr_indep_train_cvec = pd.concat([fr_indep_train.reset_index(drop=True), fr_df], axis=1)\n",
    "# transform X_test\n",
    "fr_cvec2 = cvec.transform(fr_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df2  = pd.DataFrame(fr_cvec2.todense(),columns=cvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "fr_indep_test_cvec = pd.concat([fr_indep_test.reset_index(drop=True), fr_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (use in model 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "tvec = TfidfVectorizer(stop_words = stop_words, max_features = 1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(gb_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "gb_tvec = tvec.transform(gb_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df  = pd.DataFrame(gb_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "gb_indep_train_tvec = pd.concat([gb_indep_train.reset_index(drop=True), gb_df], axis=1)\n",
    "# transform X_test\n",
    "gb_tvec2 = tvec.transform(gb_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "gb_df2  = pd.DataFrame(gb_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "gb_indep_test_tvec = pd.concat([gb_indep_test.reset_index(drop=True), gb_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(it_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "it_tvec = tvec.transform(it_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df  = pd.DataFrame(it_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "it_indep_train_tvec = pd.concat([it_indep_train.reset_index(drop=True), it_df], axis=1)\n",
    "# transform X_test\n",
    "it_tvec2 = tvec.transform(it_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "it_df2  = pd.DataFrame(it_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "it_indep_test_tvec = pd.concat([it_indep_test.reset_index(drop=True), it_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(us_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "us_tvec = tvec.transform(us_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df  = pd.DataFrame(us_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "us_indep_train_tvec = pd.concat([us_indep_train.reset_index(drop=True), us_df], axis=1)\n",
    "# transform X_test\n",
    "us_tvec2 = tvec.transform(us_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "us_df2  = pd.DataFrame(us_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "us_indep_test_tvec = pd.concat([us_indep_test.reset_index(drop=True), us_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(de_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "de_tvec = tvec.transform(de_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df  = pd.DataFrame(de_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "de_indep_train_tvec = pd.concat([de_indep_train.reset_index(drop=True), de_df], axis=1)\n",
    "# transform X_test\n",
    "de_tvec2 = tvec.transform(de_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "de_df2  = pd.DataFrame(de_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "de_indep_test_tvec = pd.concat([de_indep_test.reset_index(drop=True), de_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(ca_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "ca_tvec = tvec.transform(ca_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df  = pd.DataFrame(ca_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "ca_indep_train_tvec = pd.concat([ca_indep_train.reset_index(drop=True), ca_df], axis=1)\n",
    "# transform X_test\n",
    "ca_tvec2 = tvec.transform(ca_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "ca_df2  = pd.DataFrame(ca_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "ca_indep_test_tvec = pd.concat([ca_indep_test.reset_index(drop=True), ca_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(nl_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "nl_tvec = tvec.transform(nl_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df  = pd.DataFrame(nl_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "nl_indep_train_tvec = pd.concat([nl_indep_train.reset_index(drop=True), nl_df], axis=1)\n",
    "# transform X_test\n",
    "nl_tvec2 = tvec.transform(nl_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "nl_df2  = pd.DataFrame(nl_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "nl_indep_test_tvec = pd.concat([nl_indep_test.reset_index(drop=True), nl_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(au_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "au_tvec = tvec.transform(au_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df  = pd.DataFrame(au_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "au_indep_train_tvec = pd.concat([au_indep_train.reset_index(drop=True), au_df], axis=1)\n",
    "# transform X_test\n",
    "au_tvec2 = tvec.transform(au_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "au_df2  = pd.DataFrame(au_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "au_indep_test_tvec = pd.concat([au_indep_test.reset_index(drop=True), au_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the count vectorizer with training data. \n",
    "tvec.fit(fr_indep_train['Lyrics'])\n",
    "# transform X_train\n",
    "fr_tvec = tvec.transform(fr_indep_train['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df  = pd.DataFrame(fr_tvec.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for fitting the model\n",
    "fr_indep_train_tvec = pd.concat([fr_indep_train.reset_index(drop=True), fr_df], axis=1)\n",
    "# transform X_test\n",
    "fr_tvec2 = tvec.transform(fr_indep_test['Lyrics'])\n",
    "# Turn the features into a data frame\n",
    "fr_df2  = pd.DataFrame(fr_tvec2.todense(),columns=tvec.get_feature_names())\n",
    "# Concat with big data frame and use for scoring the model\n",
    "fr_indep_test_tvec = pd.concat([fr_indep_test.reset_index(drop=True), fr_df2 ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models (RandomForestRegressor) - CountVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did choose RF bc that gave the best score when looking at all countries togehter.<BR />\n",
    "If the RF scores very well in one country (compared to the total score) then I might consider trying other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not have to scale a Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_hype(model, params, X_train, y_train):  \n",
    "    # Best Hyperparameters\n",
    "    rs = RandomizedSearchCV(model, params, n_iter=40)\n",
    "    \n",
    "    # fit\n",
    "    rs.fit(X_train, y_train)\n",
    "     \n",
    "    return {'best_score': rs.best_score_,'best_params': rs.best_params_} \n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # fit\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate: predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Evaluate: score\n",
    "    score = model.score(X_test, y_test)\n",
    "    \n",
    "    return {'Score (R^2)': score.mean(), 'MSE': mean_square_error}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Brittan / United Kingdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.19020506510398869}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_gb = gb_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_gb = gb_dep_train\n",
    "X_test_gb = gb_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_gb = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_gb, y_train_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2013992039140816, 'Score (R^2)': 0.31418039815233123}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_gb, X_test_gb, y_train_gb, y_test_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.159446\n",
       "Acousticness        0.054006\n",
       "baby                0.026675\n",
       "avg_Streams         0.024217\n",
       "Polarity            0.023085\n",
       "Subjectivity        0.023027\n",
       "Tempo               0.021237\n",
       "Instrumentalness    0.019196\n",
       "girl                0.017983\n",
       "avg_Position        0.016795\n",
       "oh                  0.015238\n",
       "know                0.009870\n",
       "want                0.007324\n",
       "feel                0.007096\n",
       "love                0.007065\n",
       "dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_gb.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1535427709147048}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_gb2 = gb_indep_train_cvec[['Energy', 'Acousticness', 'baby', 'avg_Streams', 'Polarity', 'Subjectivity',\n",
    "                             'Tempo','Instrumentalness' , 'girl', 'avg_Position']]\n",
    "y_train_gb2  = gb_dep_train\n",
    "X_test_gb2  = gb_indep_test_cvec[['Energy', 'Acousticness', 'baby', 'avg_Streams', 'Polarity', 'Subjectivity',\n",
    "                             'Tempo','Instrumentalness' , 'girl', 'avg_Position']]\n",
    "y_test_gb2  = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_gb2, y_train_gb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20877369771902565, 'Score (R^2)': 0.2630365296467547}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='log2', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_gb2, X_test_gb2, y_train_gb2, y_test_gb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 60,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.14933958256956442}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_gb3 = gb_indep_train_cvec[['Energy', 'Acousticness', 'baby']]\n",
    "y_train_gb3 = gb_dep_train\n",
    "X_test_gb3 = gb_indep_test_cvec[['Energy', 'Acousticness', 'baby']]\n",
    "y_test_gb3 = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_gb3, y_train_gb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2107924227574241, 'Score (R^2)': 0.24871557476627015}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='auto', n_estimators=60, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_gb3, X_test_gb3, y_train_gb3, y_test_gb3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1839444875711641}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_it = it_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_it = it_dep_train\n",
    "X_test_it = it_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_it = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_it, y_train_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19321441534566536, 'Score (R^2)': 0.15968396438438126}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=11, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_it, X_test_it, y_train_it, y_test_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.183540\n",
       "Acousticness        0.055625\n",
       "Instrumentalness    0.037431\n",
       "Subjectivity        0.020645\n",
       "Polarity            0.017126\n",
       "oh                  0.016502\n",
       "avg_Streams         0.016062\n",
       "Tempo               0.015250\n",
       "che                 0.011669\n",
       "avg_Position        0.009455\n",
       "baby                0.008548\n",
       "ya                  0.008494\n",
       "ooh                 0.008389\n",
       "know                0.008297\n",
       "don                 0.008034\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_it.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17068581415878747}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_it2 = it_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Subjectivity', 'Polarity', 'oh',\n",
    "                                 'avg_Streams','Tempo' , 'che', 'avg_Position']]\n",
    "y_train_it2  = it_dep_train\n",
    "X_test_it2  = it_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Subjectivity', 'Polarity', 'oh',\n",
    "                                 'avg_Streams','Tempo' , 'che', 'avg_Position']]\n",
    "y_test_it2  = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_it2, y_train_it2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1948679881699861, 'Score (R^2)': 0.1452391861548371}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='sqrt', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_it2, X_test_it2, y_train_it2, y_test_it2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 40,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.13532993728269863}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_it3 = it_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_it3 = it_dep_train\n",
    "X_test_it3 = it_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_it3 = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_it3, y_train_it3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2030556393611383, 'Score (R^2)': 0.071902267156844}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=40, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_it3, X_test_it3, y_train_it3, y_test_it3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.2286913154582488}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_us = us_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_us = us_dep_train\n",
    "X_test_us = us_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_us = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_us, y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17934043610996833, 'Score (R^2)': 0.3188044396985018}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_us, X_test_us, y_train_us, y_test_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.200041\n",
       "Polarity            0.032033\n",
       "Acousticness        0.025230\n",
       "Subjectivity        0.024553\n",
       "Instrumentalness    0.018849\n",
       "baby                0.018661\n",
       "Tempo               0.018083\n",
       "snow                0.015545\n",
       "avg_Streams         0.012365\n",
       "little              0.011901\n",
       "like                0.010453\n",
       "girl                0.010006\n",
       "just                0.009424\n",
       "don                 0.009200\n",
       "yeah                0.009175\n",
       "dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_us.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1951059584084765}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_us2 = us_indep_train_cvec[['Energy', 'Polarity', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'baby',\n",
    "                                 'Tempo', 'snow', 'avg_Streams', 'little']]\n",
    "y_train_us2  = us_dep_train\n",
    "X_test_us2  = us_indep_test_cvec[['Energy', 'Polarity', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'baby',\n",
    "                                 'Tempo', 'snow', 'avg_Streams', 'little']]\n",
    "y_test_us2  = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_us2, y_train_us2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18772479150885646, 'Score (R^2)': 0.2536223484064851}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_us2, X_test_us2, y_train_us2, y_test_us2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 20,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.14930723728526551}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_us3 = us_indep_train_cvec[['Energy', 'Polarity', 'Acousticness']]\n",
    "y_train_us3 = us_dep_train\n",
    "X_test_us3 = us_indep_test_cvec[['Energy', 'Polarity', 'Acousticness']]\n",
    "y_test_us3 = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_us3, y_train_us3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1976759241094477, 'Score (R^2)': 0.17239535171712106}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=20, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_us3, X_test_us3, y_train_us3, y_test_us3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deutchland / Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.19856787145314805}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_de = de_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_de = de_dep_train\n",
    "X_test_de = de_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_de = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_de, y_train_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18744385533497981, 'Score (R^2)': 0.19659568557898718}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_de, X_test_de, y_train_de, y_test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.160537\n",
       "avg_Streams         0.038600\n",
       "Acousticness        0.018874\n",
       "avg_Position        0.018564\n",
       "Polarity            0.017861\n",
       "baby                0.017711\n",
       "Instrumentalness    0.017665\n",
       "Tempo               0.016726\n",
       "Subjectivity        0.015403\n",
       "oh                  0.012833\n",
       "ahh                 0.009537\n",
       "yeah                0.007708\n",
       "mal                 0.006976\n",
       "bad                 0.006930\n",
       "uh                  0.006543\n",
       "dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_de.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': False,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15865264589950268}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_de2 = de_indep_train_cvec[['Energy', 'avg_Streams', 'Acousticness', 'avg_Position', 'Polarity', 'baby',\n",
    "                                 'Instrumentalness', 'Tempo', 'Subjectivity', 'oh']]\n",
    "y_train_de2  = de_dep_train\n",
    "X_test_de2  = de_indep_test_cvec[['Energy', 'avg_Streams', 'Acousticness', 'avg_Position', 'Polarity', 'baby',\n",
    "                                 'Instrumentalness', 'Tempo', 'Subjectivity', 'oh']]\n",
    "y_test_de2  = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_de2, y_train_de2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19311413014730092, 'Score (R^2)': 0.14725369224245033}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='sqrt', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_de2, X_test_de2, y_train_de2, y_test_de2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.10534728809056754}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_de3 = de_indep_train_cvec[['Energy', 'avg_Streams', 'Acousticness']]\n",
    "y_train_de3 = de_dep_train\n",
    "X_test_de3 = de_indep_test_cvec[['Energy', 'avg_Streams', 'Acousticness']]\n",
    "y_test_de3 = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_de3, y_train_de3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19804338128448137, 'Score (R^2)': 0.10316528973537387}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_de3, X_test_de3, y_train_de3, y_test_de3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 60,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1836717879679668}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_ca = ca_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_ca = ca_dep_train\n",
    "X_test_ca = ca_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_ca = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_ca, y_train_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17539422177323977, 'Score (R^2)': 0.3273411319309155}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=60, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_ca, X_test_ca, y_train_ca, y_test_ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.161828\n",
       "Acousticness        0.044747\n",
       "Polarity            0.027854\n",
       "Instrumentalness    0.025598\n",
       "baby                0.023326\n",
       "oh                  0.018591\n",
       "Subjectivity        0.018013\n",
       "Tempo               0.017380\n",
       "avg_Position        0.012527\n",
       "avg_Streams         0.012308\n",
       "don                 0.011587\n",
       "know                0.010141\n",
       "heart               0.009652\n",
       "sing                0.009469\n",
       "christmas           0.008679\n",
       "dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_ca.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16748059839591597}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_ca2 = ca_indep_train_cvec[['Energy', 'Acousticness', 'Polarity', 'Instrumentalness', 'baby', 'oh',\n",
    "                                 'Subjectivity','Tempo' , 'avg_Position', 'avg_Streams']]\n",
    "y_train_ca2  = ca_dep_train\n",
    "X_test_ca2  = ca_indep_test_cvec[['Energy', 'Acousticness', 'Polarity', 'Instrumentalness', 'baby', 'oh',\n",
    "                                 'Subjectivity','Tempo' , 'avg_Position', 'avg_Streams']]\n",
    "y_test_ca2  = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_ca2, y_train_ca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1828956077296433, 'Score (R^2)': 0.2685732146069939}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='log2', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_ca2, X_test_ca2, y_train_ca2, y_test_ca2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.13722775315821212}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_ca3 = ca_indep_train_cvec[['Energy', 'Acousticness', 'Polarity']]\n",
    "y_train_ca3 = ca_dep_train\n",
    "X_test_ca3 = ca_indep_test_cvec[['Energy', 'Acousticness', 'Polarity']]\n",
    "y_test_ca3 = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_ca3, y_train_ca3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19174084734295438, 'Score (R^2)': 0.1961156143878502}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_ca3, X_test_ca3, y_train_ca3, y_test_ca3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Netherlands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.20775031378829542}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_nl = nl_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_nl = nl_dep_train\n",
    "X_test_nl = nl_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_nl = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_nl, y_train_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1798516475830444, 'Score (R^2)': 0.25069816123443533}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=11, max_features='auto', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_nl, X_test_nl, y_train_nl, y_test_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.226779\n",
       "Acousticness        0.063599\n",
       "Subjectivity        0.026627\n",
       "Instrumentalness    0.022419\n",
       "Polarity            0.019567\n",
       "Tempo               0.014691\n",
       "Mode                0.013898\n",
       "avg_Streams         0.012281\n",
       "oh                  0.012142\n",
       "avg_Position        0.011023\n",
       "life                0.009054\n",
       "sing                0.008623\n",
       "want                0.008090\n",
       "baby                0.007957\n",
       "bad                 0.007915\n",
       "dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_nl.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 40,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.18287113780664324}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_nl2 = nl_indep_train_cvec[['Energy', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'Polarity', 'Tempo',\n",
    "                                 'Mode', 'avg_Streams', 'oh', 'avg_Position']]\n",
    "y_train_nl2  = nl_dep_train\n",
    "X_test_nl2  = nl_indep_test_cvec[['Energy', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'Polarity', 'Tempo',\n",
    "                                 'Mode', 'avg_Streams', 'oh', 'avg_Position']]\n",
    "y_test_nl2  = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_nl2, y_train_nl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19061783107042715, 'Score (R^2)': 0.15830450182716116}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=40, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_nl2, X_test_nl2, y_train_nl2, y_test_nl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 2,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16760762715931107}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_nl3 = nl_indep_train_cvec[['Energy', 'Acousticness', 'Subjectivity']]\n",
    "y_train_nl3 = nl_dep_train\n",
    "X_test_nl3 = nl_indep_test_cvec[['Energy', 'Acousticness', 'Subjectivity']]\n",
    "y_test_nl3 = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_nl3, y_train_nl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18835322450431446, 'Score (R^2)': 0.178184977008047}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=2, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_nl3, X_test_nl3, y_train_nl3, y_test_nl3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.23200601587974196}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_au = au_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_au = au_dep_train\n",
    "X_test_au = au_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_au = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_au, y_train_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1924933401623924, 'Score (R^2)': 0.26258288149338593}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_au, X_test_au, y_train_au, y_test_au)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.181463\n",
       "Acousticness        0.048978\n",
       "Instrumentalness    0.033361\n",
       "Tempo               0.026213\n",
       "Polarity            0.024059\n",
       "Subjectivity        0.021284\n",
       "avg_Streams         0.015795\n",
       "bad                 0.012775\n",
       "come                0.010666\n",
       "snow                0.010337\n",
       "road                0.009914\n",
       "know                0.008901\n",
       "don                 0.008735\n",
       "hey                 0.008135\n",
       "avg_Position        0.008130\n",
       "dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_au.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1856167723834672}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_au2 = au_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'Polarity', 'Subjectivity',\n",
    "                                 'avg_Streams', 'bad', 'come', 'snow']]\n",
    "y_train_au2  = au_dep_train\n",
    "X_test_au2  = au_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'Polarity', 'Subjectivity',\n",
    "                                 'avg_Streams', 'bad', 'come', 'snow']]\n",
    "y_test_au2  = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_au2, y_train_au2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2038500615876285, 'Score (R^2)': 0.17300384155218806}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='log2', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_au2, X_test_au2, y_train_au2, y_test_au2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 20,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15487743199646634}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_au3 = au_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_au3 = au_dep_train\n",
    "X_test_au3 = au_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_au3 = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_au3, y_train_au3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2052699179641228, 'Score (R^2)': 0.16144333395793364}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=20, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_au3, X_test_au3, y_train_au3, y_test_au3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - CountVec + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 60,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.2272638383722506}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_fr = fr_indep_train_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_fr = fr_dep_train\n",
    "X_test_fr = fr_indep_test_cvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_fr = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_fr, y_train_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18788818278679834, 'Score (R^2)': 0.25917183970000157}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=60, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_fr, X_test_fr, y_train_fr, y_test_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.185094\n",
       "Acousticness        0.047401\n",
       "Instrumentalness    0.028265\n",
       "Tempo               0.024499\n",
       "Subjectivity        0.022239\n",
       "x2                  0.020529\n",
       "avg_Streams         0.018529\n",
       "Polarity            0.016456\n",
       "avg_Position        0.011927\n",
       "baby                0.007661\n",
       "je                  0.007049\n",
       "ai                  0.006760\n",
       "oh                  0.006593\n",
       "faire               0.006236\n",
       "know                0.005921\n",
       "dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_fr.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - CountVec + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1661687601523369}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_fr2 = fr_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'Subjectivity', 'avg_Streams',\n",
    "                                 'Polarity', 'avg_Position', 'baby', 'je']]\n",
    "y_train_fr2  = fr_dep_train\n",
    "X_test_fr2  = fr_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness', 'Tempo', 'Subjectivity', 'avg_Streams',\n",
    "                                 'Polarity', 'avg_Position', 'baby', 'je']]\n",
    "y_test_fr2  = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_fr2, y_train_fr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19373664931011902, 'Score (R^2)': 0.21233396452492503}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=8, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_fr2, X_test_fr2, y_train_fr2, y_test_fr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - CountVec + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16755451622431095}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_fr3 = fr_indep_train_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_fr3 = fr_dep_train\n",
    "X_test_fr3 = fr_indep_test_cvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_fr3 = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_fr3, y_train_fr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18987893063312286, 'Score (R^2)': 0.24338995186336407}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=8, max_features='log2', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_fr3, X_test_fr3, y_train_fr3, y_test_fr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models (RandomForestRegressor) - TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did choose RF bc that gave the best score when looking at all countries togehter.<BR />\n",
    "If the RF scores very well in one country (compared to the total score) then I might consider trying other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not have to scale a Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_hype(model, params, X_train, y_train):  \n",
    "    # Best Hyperparameters\n",
    "    rs = RandomizedSearchCV(model, params, n_iter=40)\n",
    "    \n",
    "    # fit\n",
    "    rs.fit(X_train, y_train)\n",
    "     \n",
    "    return {'best_score': rs.best_score_,'best_params': rs.best_params_} \n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # fit\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate: predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    mean_square_error = np.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # Evaluate: score\n",
    "    score = model.score(X_test, y_test)\n",
    "    \n",
    "    return {'Score (R^2)': score.mean(), 'MSE': mean_square_error}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Brittan / United Kingdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF_IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.18371888553485655}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_gb = gb_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_gb = gb_dep_train\n",
    "X_test_gb = gb_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_gb = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_gb, y_train_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20565677256544868, 'Score (R^2)': 0.284877526037732}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_gb, X_test_gb, y_train_gb, y_test_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.146436\n",
       "Acousticness        0.047077\n",
       "baby                0.029120\n",
       "avg_Streams         0.021062\n",
       "girl                0.020947\n",
       "Polarity            0.017266\n",
       "Subjectivity        0.017155\n",
       "Instrumentalness    0.016977\n",
       "Tempo               0.016976\n",
       "know                0.013420\n",
       "oh                  0.013051\n",
       "avg_Position        0.010982\n",
       "just                0.009942\n",
       "don                 0.009308\n",
       "cause               0.009205\n",
       "dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_gb.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF_IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 60,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16112876301968113}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_gb2 = gb_indep_train_tvec[['Energy', 'Acousticness', 'baby', 'avg_Streams', 'girl', 'Polarity',\n",
    "                                 'Subjectivity', 'Instrumentalness', 'Tempo', 'know']]\n",
    "y_train_gb2  = gb_dep_train\n",
    "X_test_gb2  = gb_indep_test_tvec[['Energy', 'Acousticness', 'baby', 'avg_Streams', 'girl', 'Polarity',\n",
    "                                 'Subjectivity', 'Instrumentalness', 'Tempo', 'know']]\n",
    "y_test_gb2  = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_gb2, y_train_gb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.2066262875077516, 'Score (R^2)': 0.2781191182533066}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='log2', n_estimators=60, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_gb2, X_test_gb2, y_train_gb2, y_test_gb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF_IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 30,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.14400072731396285}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_gb3 = gb_indep_train_tvec[['Energy', 'Acousticness', 'baby']]\n",
    "y_train_gb3 = gb_dep_train\n",
    "X_test_gb3 = gb_indep_test_tvec[['Energy', 'Acousticness', 'baby']]\n",
    "y_test_gb3 = gb_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_gb3, y_train_gb3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.21673851821164267, 'Score (R^2)': 0.20573286195124063}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=30, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_gb3, X_test_gb3, y_train_gb3, y_test_gb3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15197506629570712}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_it = it_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_it = it_dep_train\n",
    "X_test_it = it_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_it = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_it, y_train_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19526084449228942, 'Score (R^2)': 0.14178929497849657}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=8, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_it, X_test_it, y_train_it, y_test_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.214291\n",
       "Acousticness        0.049394\n",
       "Instrumentalness    0.041181\n",
       "oh                  0.015222\n",
       "che                 0.014432\n",
       "più                 0.012921\n",
       "Subjectivity        0.012343\n",
       "Polarity            0.011315\n",
       "avg_Streams         0.010018\n",
       "Tempo               0.009328\n",
       "baby                0.008921\n",
       "ooh                 0.008890\n",
       "know                0.008874\n",
       "ya                  0.008727\n",
       "avg_Position        0.008670\n",
       "dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_it.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-ID + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17660733430414619}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_it2 = it_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'oh', 'che', 'più',\n",
    "                                 'Subjectivity', 'Polarity', 'avg_Streams', 'Tempo']]\n",
    "y_train_it2  = it_dep_train\n",
    "X_test_it2  = it_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'oh', 'che', 'più',\n",
    "                                 'Subjectivity', 'Polarity', 'avg_Streams', 'Tempo']]\n",
    "y_test_it2  = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_it2, y_train_it2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19840961590942735, 'Score (R^2)': 0.11388715176286202}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='sqrt', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_it2, X_test_it2, y_train_it2, y_test_it2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.13569655728478214}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_it3 = it_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_it3 = it_dep_train\n",
    "X_test_it3 = it_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_it3 = it_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_it3, y_train_it3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20359551369342424, 'Score (R^2)': 0.0669605453992903}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_it3, X_test_it3, y_train_it3, y_test_it3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.2146681037937301}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_us = us_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_us = us_dep_train\n",
    "X_test_us = us_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_us = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_us, y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17917928013654794, 'Score (R^2)': 0.320028139296918}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_us, X_test_us, y_train_us, y_test_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.187557\n",
       "Polarity            0.023403\n",
       "baby                0.019677\n",
       "Acousticness        0.019296\n",
       "Subjectivity        0.017887\n",
       "Instrumentalness    0.015495\n",
       "like                0.013965\n",
       "Tempo               0.013591\n",
       "snow                0.013458\n",
       "girl                0.012747\n",
       "avg_Streams         0.011243\n",
       "hey                 0.010525\n",
       "say                 0.009002\n",
       "don                 0.008385\n",
       "just                0.008335\n",
       "dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_us.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 90,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.2207176480167608}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_us2 = us_indep_train_tvec[['Energy', 'Polarity', 'baby', 'Acousticness', 'Subjectivity', 'Instrumentalness',\n",
    "                                 'like', 'Tempo', 'snow', 'girl']]\n",
    "y_train_us2  = us_dep_train\n",
    "X_test_us2  = us_indep_test_tvec[['Energy', 'Polarity', 'baby', 'Acousticness', 'Subjectivity', 'Instrumentalness',\n",
    "                                 'like', 'Tempo', 'snow', 'girl']]\n",
    "y_test_us2  = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_us2, y_train_us2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18878375823938226, 'Score (R^2)': 0.24517787593084972}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='sqrt', n_estimators=90, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_us2, X_test_us2, y_train_us2, y_test_us2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16932017485114467}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_us3 = us_indep_train_tvec[['Energy', 'Polarity', 'baby']]\n",
    "y_train_us3 = us_dep_train\n",
    "X_test_us3 = us_indep_test_tvec[['Energy', 'Polarity', 'baby']]\n",
    "y_test_us3 = us_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_us3, y_train_us3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19990724781225308, 'Score (R^2)': 0.1536062534059779}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_us3, X_test_us3, y_train_us3, y_test_us3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deutchland / Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17188079626034436}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_de = de_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_de = de_dep_train\n",
    "X_test_de = de_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_de = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_de, y_train_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18816349770506227, 'Score (R^2)': 0.1904149159896471}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_de, X_test_de, y_train_de, y_test_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.164225\n",
       "avg_Streams         0.031034\n",
       "baby                0.024554\n",
       "oh                  0.015565\n",
       "Polarity            0.014232\n",
       "avg_Position        0.012694\n",
       "Acousticness        0.012616\n",
       "Tempo               0.011084\n",
       "Subjectivity        0.010997\n",
       "Instrumentalness    0.010641\n",
       "bad                 0.009257\n",
       "just                0.007819\n",
       "eh                  0.007666\n",
       "snow                0.007599\n",
       "got                 0.006996\n",
       "dtype: float64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_de.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16119525001110976}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_de2 = de_indep_train_tvec[['Energy', 'avg_Streams', 'baby', 'oh', 'Polarity', 'avg_Position', \n",
    "                                   'Acousticness', 'Tempo', 'Subjectivity', 'Instrumentalness']]\n",
    "y_train_de2  = de_dep_train\n",
    "X_test_de2  = de_indep_test_tvec[['Energy', 'avg_Streams', 'baby', 'oh', 'Polarity', 'avg_Position', \n",
    "                                    'Acousticness', 'Tempo', 'Subjectivity', 'Instrumentalness']]\n",
    "y_test_de2  = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_de2, y_train_de2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19130740836151128, 'Score (R^2)': 0.16313516365083858}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='sqrt', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_de2, X_test_de2, y_train_de2, y_test_de2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': False,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 40,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.12095804863368141}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_de3 = de_indep_train_tvec[['Energy', 'avg_Streams', 'baby']]\n",
    "y_train_de3 = de_dep_train\n",
    "X_test_de3 = de_indep_test_tvec[['Energy', 'avg_Streams', 'baby']]\n",
    "y_test_de3 = de_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_de3, y_train_de3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1993637539816148, 'Score (R^2)': 0.09116687308490101}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=40, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_de3, X_test_de3, y_train_de3, y_test_de3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1875516782295987}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_ca = ca_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_ca = ca_dep_train\n",
    "X_test_ca = ca_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_ca = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_ca, y_train_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17786596487448125, 'Score (R^2)': 0.3082486524139738}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_ca, X_test_ca, y_train_ca, y_test_ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.152878\n",
       "baby                0.035818\n",
       "Acousticness        0.034272\n",
       "Instrumentalness    0.024157\n",
       "Polarity            0.019430\n",
       "Subjectivity        0.016306\n",
       "oh                  0.015656\n",
       "don                 0.014247\n",
       "Tempo               0.013239\n",
       "sing                0.011653\n",
       "heart               0.010999\n",
       "girl                0.010609\n",
       "just                0.009083\n",
       "cause               0.008718\n",
       "avg_Streams         0.008622\n",
       "dtype: float64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_ca.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.1861822351861458}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_ca2 = ca_indep_train_tvec[['Energy', 'baby', 'Acousticness', 'Instrumentalness', 'Polarity', 'Subjectivity',\n",
    "                                 'oh', 'don', 'Tempo', 'sing']]\n",
    "y_train_ca2  = ca_dep_train\n",
    "X_test_ca2  = ca_indep_test_tvec[['Energy', 'baby', 'Acousticness', 'Instrumentalness', 'Polarity', 'Subjectivity',\n",
    "                                 'oh', 'don', 'Tempo', 'sing']]\n",
    "y_test_ca2  = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_ca2, y_train_ca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1859943327785615, 'Score (R^2)': 0.2435787312746738}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=8, max_features='log2', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_ca2, X_test_ca2, y_train_ca2, y_test_ca2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 5,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15350443169864744}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_ca3 = ca_indep_train_tvec[['Energy', 'baby', 'Acousticness']]\n",
    "y_train_ca3 = ca_dep_train\n",
    "X_test_ca3 = ca_indep_test_tvec[['Energy', 'baby', 'Acousticness']]\n",
    "y_test_ca3 = ca_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_ca3, y_train_ca3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18888789114451257, 'Score (R^2)': 0.21986000281487086}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=5, max_features='sqrt', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_ca3, X_test_ca3, y_train_ca3, y_test_ca3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Netherlands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.20411463579142383}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_nl = nl_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_nl = nl_dep_train\n",
    "X_test_nl = nl_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_nl = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_nl, y_train_nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.17963835086509775, 'Score (R^2)': 0.2524743901759854}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=11, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_nl, X_test_nl, y_train_nl, y_test_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.223327\n",
       "Acousticness        0.054516\n",
       "Subjectivity        0.022405\n",
       "Instrumentalness    0.017538\n",
       "Polarity            0.014851\n",
       "Tempo               0.013531\n",
       "avg_Streams         0.013209\n",
       "baby                0.012948\n",
       "know                0.012684\n",
       "want                0.011728\n",
       "avg_Position        0.010072\n",
       "oh                  0.009952\n",
       "Mode                0.009132\n",
       "away                0.008415\n",
       "song                0.007253\n",
       "dtype: float64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_nl.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 11,\n",
       "  'max_features': 'log2',\n",
       "  'n_estimators': 40,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17698124752645786}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_nl2 = nl_indep_train_tvec[['Energy', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'Polarity', 'Tempo',\n",
    "                                 'avg_Streams', 'baby', 'know', 'want']]\n",
    "y_train_nl2  = nl_dep_train\n",
    "X_test_nl2  = nl_indep_test_tvec[['Energy', 'Acousticness', 'Subjectivity', 'Instrumentalness', 'Polarity', 'Tempo',\n",
    "                                 'avg_Streams', 'baby', 'know', 'want']]\n",
    "y_test_nl2  = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_nl2, y_train_nl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.191636510979673, 'Score (R^2)': 0.14928426115479554}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=11, max_features='log2', n_estimators=40, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_nl2, X_test_nl2, y_train_nl2, y_test_nl2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 2,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.16766138209302633}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_nl3 = nl_indep_train_tvec[['Energy', 'Acousticness', 'Subjectivity']]\n",
    "y_train_nl3 = nl_dep_train\n",
    "X_test_nl3 = nl_indep_test_tvec[['Energy', 'Acousticness', 'Subjectivity']]\n",
    "y_test_nl3 = nl_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_nl3, y_train_nl3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1885238077582708, 'Score (R^2)': 0.17669573930427385}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=2, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_nl3, X_test_nl3, y_train_nl3, y_test_nl3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.22871378573224335}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_au = au_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_au = au_dep_train\n",
    "X_test_au = au_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_au = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_au, y_train_au)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19131517110382987, 'Score (R^2)': 0.2715820837463585}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_au, X_test_au, y_train_au, y_test_au)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.180291\n",
       "Acousticness        0.038735\n",
       "Instrumentalness    0.031357\n",
       "Polarity            0.023082\n",
       "Tempo               0.018245\n",
       "Subjectivity        0.016056\n",
       "snow                0.015395\n",
       "hey                 0.013942\n",
       "avg_Streams         0.013238\n",
       "end                 0.012757\n",
       "road                0.012757\n",
       "bad                 0.010009\n",
       "just                0.009554\n",
       "don                 0.009469\n",
       "know                0.009189\n",
       "dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_au.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.19665454313911662}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_au2 = au_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'Polarity', 'Tempo', 'Subjectivity',\n",
    "                                 'snow', 'hey', 'avg_Streams', 'end']]\n",
    "y_train_au2  = au_dep_train\n",
    "X_test_au2  = au_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'Polarity', 'Tempo', 'Subjectivity',\n",
    "                                 'snow', 'hey', 'avg_Streams', 'end']]\n",
    "y_test_au2  = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_au2, y_train_au2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20639120554240528, 'Score (R^2)': 0.15225707541645794}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=17, max_features='sqrt', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_au2, X_test_au2, y_train_au2, y_test_au2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 2,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 10,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15353285489934612}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_au3 = au_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_au3 = au_dep_train\n",
    "X_test_au3 = au_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_au3 = au_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_au3, y_train_au3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.20919128034745282, 'Score (R^2)': 0.12909866914319623}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=2, max_features='auto', n_estimators=10, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_au3, X_test_au3, y_train_au3, y_test_au3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF #1 - TF-IDF + all coefs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 17,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 50,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.212545002755988}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare indep and dep\n",
    "X_train_fr = fr_indep_train_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_train_fr = fr_dep_train\n",
    "X_test_fr = fr_indep_test_tvec.drop(['Track Name', 'Artist', 'ID', 'Lyrics', 'Valence'], axis=1)\n",
    "y_test_fr = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr, params, X_train_fr, y_train_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.19207918862143117, 'Score (R^2)': 0.22575363459641162}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr = RandomForestRegressor(max_depth=17, max_features='auto', n_estimators=50, verbose=0, bootstrap=True, \n",
    "                            random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr, X_train_fr, X_test_fr, y_train_fr, y_test_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy              0.167301\n",
       "Acousticness        0.041652\n",
       "Instrumentalness    0.027502\n",
       "Subjectivity        0.019713\n",
       "Tempo               0.016747\n",
       "x2                  0.015546\n",
       "Polarity            0.015252\n",
       "avg_Streams         0.013585\n",
       "avg_Position        0.011396\n",
       "baby                0.008699\n",
       "oh                  0.007446\n",
       "got                 0.007280\n",
       "suis                0.007017\n",
       "je                  0.006579\n",
       "qu                  0.006511\n",
       "dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(zip(X_train_fr.columns,rfr.feature_importances_))).abs().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #2 - TF-IDF + top 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': True,\n",
       "  'max_depth': 14,\n",
       "  'max_features': 'auto',\n",
       "  'n_estimators': 80,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.17674201382895674}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_fr2 = fr_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'Subjectivity', 'Tempo', 'Polarity',\n",
    "                                 'avg_Streams', 'avg_Position', 'baby', 'oh']]\n",
    "y_train_fr2  = fr_dep_train\n",
    "X_test_fr2  = fr_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness', 'Subjectivity', 'Tempo', 'Polarity',\n",
    "                                 'avg_Streams', 'avg_Position', 'baby', 'oh']]\n",
    "y_test_fr2  = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr2 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr2, params, X_train_fr2, y_train_fr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.1996000180024958, 'Score (R^2)': 0.1639356555487793}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr2 = RandomForestRegressor(max_depth=14, max_features='auto', n_estimators=80, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr2, X_train_fr2, X_test_fr2, y_train_fr2, y_test_fr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF #3 - TF-IDF + top 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'bootstrap': False,\n",
       "  'max_depth': 8,\n",
       "  'max_features': 'sqrt',\n",
       "  'n_estimators': 70,\n",
       "  'verbose': 0},\n",
       " 'best_score': 0.15848262661970244}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define X and y\n",
    "X_train_fr3 = fr_indep_train_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_train_fr3 = fr_dep_train\n",
    "X_test_fr3 = fr_indep_test_tvec[['Energy', 'Acousticness', 'Instrumentalness']]\n",
    "y_test_fr3 = fr_dep_test\n",
    "\n",
    "# RandomizedSearch\n",
    "params = {'n_estimators': np.arange(10, 100, 10),\n",
    "        'max_depth': np.arange(2, 20, 3),\n",
    "        'max_features' : ('auto', 'sqrt', 'log2'),\n",
    "        'bootstrap': (True, False),\n",
    "        'verbose' : np.arange(0, 1)}\n",
    "\n",
    "rfr3 = RandomForestRegressor(random_state=24)\n",
    "\n",
    "get_best_hype(rfr3, params, X_train_fr3, y_train_fr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSE': 0.18987893063312286, 'Score (R^2)': 0.24338995186336407}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chose model and use best hyperparameters (from gridsearchCV)\n",
    "rfr3 = RandomForestRegressor(max_depth=8, max_features='sqrt', n_estimators=70, verbose=0, bootstrap=True, \n",
    "                               random_state=24)\n",
    "\n",
    "# call function\n",
    "evaluate_model(rfr3, X_train_fr3, X_test_fr3, y_train_fr3, y_test_fr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMMARY (not done yet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary TF-IDF - best model/score per country**<BR />\n",
    "gb - R2 = 0.1 (all coefs)<BR />\n",
    "it - R2 = 0.2 (all coefs)<BR />\n",
    "us - R2 = 0.3 (all coefs)<BR />\n",
    "de - R2 = 0.4 (all coefs)<BR />\n",
    "ca - R2 = 0.5 (all coefs)<BR />\n",
    "nl - R2 = 0.6 (all coefs)<BR />\n",
    "au - R2 = 0.7 (all coefs)<BR />\n",
    "fr - R2 = 0.8 (all coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The score and how many varables to choose (and which ones) varies from country to country*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary over CountVec and TF-IDF**<BR />\n",
    "The best model in total for every country:<BR />\n",
    "gb - TF-IDF: R2 = 0.1 (all coefs)<BR />\n",
    "it - CountVec: R2 = 0.2 (all coefs)<BR />\n",
    "us - TF-IDF: R2 = 0.3 (all coefs)<BR />\n",
    "de - CountVec: R2 = 0.4 (top 10 coefs)<BR />\n",
    "ca - TF-IDF: R2 = 0.5 (all coefs)<BR />\n",
    "nl - TF-IDF: R2 = 0.6 (all coefs)<BR />\n",
    "au - CountVec: R2 = 0.7 (top 3 coefs)<BR />\n",
    "fr - TF-IDF: R2 = 0.8 (all coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The score and how many varables to choose (and which ones) varies from country to country. Also the choice btw TF-IDF och CountVec seem to vary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make som plots - compairing bar chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
